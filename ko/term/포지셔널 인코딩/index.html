<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>í¬ì§€ì…”ë„ ì¸ì½”ë”© (Positional Encoding) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="ì‹œí€€ìŠ¤ ë‚´ ìœ„ì¹˜ ì •ë³´ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©. Transformerê°€ ìˆœì„œë¥¼ ì´í•´í•˜ê²Œ í•¨.">
    <meta name="keywords" content="í¬ì§€ì…”ë„ ì¸ì½”ë”©, Positional Encoding, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/%ED%8F%AC%EC%A7%80%EC%85%94%EB%84%90%20%EC%9D%B8%EC%BD%94%EB%94%A9/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/%ED%8F%AC%EC%A7%80%EC%85%94%EB%84%90%20%EC%9D%B8%EC%BD%94%EB%94%A9/">
    <meta property="og:title" content="í¬ì§€ì…”ë„ ì¸ì½”ë”© (Positional Encoding) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="ì‹œí€€ìŠ¤ ë‚´ ìœ„ì¹˜ ì •ë³´ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©. Transformerê°€ ìˆœì„œë¥¼ ì´í•´í•˜ê²Œ í•¨.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="í¬ì§€ì…”ë„ ì¸ì½”ë”© (Positional Encoding) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="ì‹œí€€ìŠ¤ ë‚´ ìœ„ì¹˜ ì •ë³´ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©. Transformerê°€ ìˆœì„œë¥¼ ì´í•´í•˜ê²Œ í•¨.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "í¬ì§€ì…”ë„ ì¸ì½”ë”©",
        "description": "ì‹œí€€ìŠ¤ ë‚´ ìœ„ì¹˜ ì •ë³´ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©. Transformerê°€ ìˆœì„œë¥¼ ì´í•´í•˜ê²Œ í•¨.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }
        .term-section { background: rgba(15, 23, 42, 0.6); border: 1px solid rgba(168, 85, 247, 0.1); border-radius: 16px; padding: 2rem; margin-bottom: 1.5rem; }
        .section-title { font-size: 1.3rem; font-weight: 600; margin-bottom: 1.5rem; color: #f1f5f9; }
        .section-content { color: #cbd5e1; line-height: 1.8; }
        .section-content p { margin-bottom: 1rem; }
        .code-block { position: relative; background: #1e293b; border-radius: 12px; padding: 1.5rem; margin: 1rem 0; overflow-x: auto; }
        .code-block pre { margin: 0; color: #e2e8f0; font-family: 'JetBrains Mono', monospace; font-size: 0.9rem; line-height: 1.6; }
        .copy-btn { position: absolute; top: 0.75rem; right: 0.75rem; padding: 0.5rem 1rem; background: rgba(168, 85, 247, 0.3); border: 1px solid rgba(168, 85, 247, 0.5); border-radius: 6px; color: #e2e8f0; font-size: 0.8rem; cursor: pointer; transition: all 0.2s; }
        .copy-btn:hover { background: rgba(168, 85, 247, 0.5); }
        .spec-table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
        .spec-table th, .spec-table td { padding: 0.75rem; text-align: left; border-bottom: 1px solid rgba(168, 85, 247, 0.2); }
        .spec-table th { background: rgba(168, 85, 247, 0.1); color: #a855f7; font-weight: 600; }
        .conversation-examples { display: flex; flex-direction: column; gap: 1rem; }
        .conv-item { background: rgba(30, 41, 59, 0.5); border-radius: 12px; padding: 1.25rem; border-left: 3px solid #a855f7; }
        .conv-context { font-size: 0.85rem; color: #a855f7; margin-bottom: 0.5rem; font-weight: 500; }
        .conv-quote { color: #e2e8f0; font-style: italic; line-height: 1.6; }
        .warning-list { display: flex; flex-direction: column; gap: 1rem; }
        .warning-item { display: flex; gap: 1rem; padding: 1rem; background: rgba(30, 41, 59, 0.5); border-radius: 12px; }
        .warning-icon { font-size: 1.5rem; flex-shrink: 0; }
        .warning-content h4 { color: #f1f5f9; margin-bottom: 0.25rem; font-size: 1rem; }
        .warning-content p { color: #94a3b8; font-size: 0.9rem; margin: 0; }
        .related-terms { display: flex; flex-wrap: wrap; gap: 0.75rem; }
        .related-term-link { display: inline-block; padding: 0.5rem 1rem; background: rgba(168, 85, 247, 0.15); border: 1px solid rgba(168, 85, 247, 0.3); border-radius: 8px; color: #c4b5fd; text-decoration: none; font-size: 0.9rem; transition: all 0.2s; }
        .related-term-link:hover { background: rgba(168, 85, 247, 0.3); transform: translateY(-2px); }
        .learn-more { display: flex; flex-direction: column; gap: 0.75rem; }
        .learn-link { display: flex; align-items: center; gap: 0.75rem; color: #94a3b8; text-decoration: none; padding: 0.75rem; background: rgba(30, 41, 59, 0.3); border-radius: 8px; transition: all 0.2s; }
        .learn-link:hover { background: rgba(30, 41, 59, 0.6); color: #e2e8f0; }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css?v=20260129232035">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">í¬ì§€ì…”ë„ ì¸ì½”ë”©</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">í¬ì§€ì…”ë„ ì¸ì½”ë”©</h1>
            <p class="term-english">Positional Encoding</p>
            <div class="term-description">
                <p>ì‹œí€€ìŠ¤ ë‚´ ìœ„ì¹˜ ì •ë³´ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©. Transformerê°€ ìˆœì„œë¥¼ ì´í•´í•˜ê²Œ í•¨.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p>í¬ì§€ì…”ë„ ì¸ì½”ë”©(Positional Encoding)ì€ Transformer ì•„í‚¤í…ì²˜ì—ì„œ ì‹œí€€ìŠ¤ ë‚´ í† í°ì˜ ìˆœì„œ ì •ë³´ë¥¼ ëª¨ë¸ì— ì œê³µí•˜ëŠ” í•µì‹¬ ê¸°ë²•ì…ë‹ˆë‹¤. RNNì´ë‚˜ LSTMê³¼ ë‹¬ë¦¬ TransformerëŠ” Self-Attention ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•´ ëª¨ë“  í† í°ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì—, ë³„ë„ì˜ ìœ„ì¹˜ ì •ë³´ ì—†ì´ëŠ” "ë‚˜ëŠ” ì‚¬ê³¼ë¥¼ ë¨¹ì—ˆë‹¤"ì™€ "ì‚¬ê³¼ë¥¼ ë‚˜ëŠ” ë¨¹ì—ˆë‹¤"ë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í¬ì§€ì…”ë„ ì¸ì½”ë”©ì€ ê° í† í°ì˜ ì„ë² ë”©ì— ìœ„ì¹˜ ì •ë³´ë¥¼ ë”í•´ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.</p>

                <p>2017ë…„ "Attention Is All You Need" ë…¼ë¬¸ì—ì„œ ì²˜ìŒ ì œì•ˆëœ ì‚¬ì¸/ì½”ì‚¬ì¸ ê¸°ë°˜ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì€ ì„œë¡œ ë‹¤ë¥¸ ì£¼íŒŒìˆ˜ì˜ sinê³¼ cos í•¨ìˆ˜ë¥¼ ì¡°í•©í•´ ê° ìœ„ì¹˜ì— ê³ ìœ í•œ ë²¡í„°ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤. PE(pos, 2i) = sin(pos / 10000^(2i/d))ì™€ PE(pos, 2i+1) = cos(pos / 10000^(2i/d)) ê³µì‹ì„ ì‚¬ìš©í•˜ë©°, ì´ ë°©ì‹ì€ í•™ìŠµ ì—†ì´ë„ ì„ì˜ì˜ ê¸¸ì´ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆê³ , ìƒëŒ€ì  ìœ„ì¹˜ ê´€ê³„ë¥¼ ì„ í˜• ë³€í™˜ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.</p>

                <p>2024-2025ë…„ í˜„ì¬ ë‹¤ì–‘í•œ ë³€í˜•ì´ ë°œì „í–ˆìŠµë‹ˆë‹¤. RoPE(Rotary Position Embedding)ëŠ” LLaMA, Mistral ë“±ì—ì„œ ì‚¬ìš©ë˜ë©° ìƒëŒ€ì  ìœ„ì¹˜ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤. ALiBi(Attention with Linear Biases)ëŠ” Attention ì ìˆ˜ì— ì§ì ‘ ìœ„ì¹˜ í¸í–¥ì„ ì¶”ê°€í•´ ì™¸ì‚½(extrapolation) ì„±ëŠ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤. í•™ìŠµ ê°€ëŠ¥í•œ ìœ„ì¹˜ ì„ë² ë”©ì€ BERT, GPTì—ì„œ ì‚¬ìš©ë˜ë©° ë°ì´í„°ë¡œë¶€í„° ìµœì ì˜ ìœ„ì¹˜ í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ 100K ì´ìƒìœ¼ë¡œ í™•ì¥í•˜ê¸° ìœ„í•œ YaRN, Streaming LLM ë“±ì˜ ê¸°ë²•ë„ ë“±ì¥í–ˆìŠµë‹ˆë‹¤.</p>

                <p>ì‹¤ë¬´ì—ì„œ í¬ì§€ì…”ë„ ì¸ì½”ë”© ì„ íƒì€ ëª¨ë¸ ì„±ëŠ¥ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ê¸´ ë¬¸ì„œ ì²˜ë¦¬ê°€ í•„ìš”í•œ RAG ì‹œìŠ¤í…œì—ì„œëŠ” RoPEë‚˜ ALiBië¥¼ ì„ í˜¸í•˜ê³ , Vision Transformerì—ì„œëŠ” 2D ì¢Œí‘œë¥¼ ì¸ì½”ë”©í•˜ê¸° ìœ„í•œ ë³„ë„ì˜ ì„¤ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤. ìµœê·¼ GPT-4 Turboì™€ Claude 3 ë“±ì€ 128K ì´ìƒì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ëŠ”ë°, ì´ëŠ” íš¨ìœ¨ì ì¸ í¬ì§€ì…”ë„ ì¸ì½”ë”© ê¸°ë²•ì˜ ë°œì „ ë•ë¶„ì…ë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="section-content">
                <p>PyTorchë¥¼ ì‚¬ìš©í•œ ì‚¬ì¸/ì½”ì‚¬ì¸ í¬ì§€ì…”ë„ ì¸ì½”ë”©ê³¼ RoPE êµ¬í˜„ ì˜ˆì œì…ë‹ˆë‹¤.</p>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                    <pre><code>import torch
import torch.nn as nn
import math

class SinusoidalPositionalEncoding(nn.Module):
    """ì›ë³¸ Transformer ì‚¬ì¸/ì½”ì‚¬ì¸ í¬ì§€ì…”ë„ ì¸ì½”ë”©"""
    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.1):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        # ìœ„ì¹˜ ì¸ì½”ë”© í–‰ë ¬ ìƒì„± [max_len, d_model]
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)

        # 10000^(2i/d_model) ê³„ì‚°
        div_term = torch.exp(
            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)
        )

        # sinì€ ì§ìˆ˜ ì¸ë±ìŠ¤, così€ í™€ìˆ˜ ì¸ë±ìŠ¤
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)

        pe = pe.unsqueeze(0)  # [1, max_len, d_model]
        self.register_buffer('pe', pe)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """x: [batch_size, seq_len, d_model]"""
        x = x + self.pe[:, :x.size(1), :]
        return self.dropout(x)

class RotaryPositionalEncoding(nn.Module):
    """RoPE: Rotary Position Embedding (LLaMA, Mistral ë“±ì—ì„œ ì‚¬ìš©)"""
    def __init__(self, dim: int, max_len: int = 2048, base: int = 10000):
        super().__init__()
        self.dim = dim
        self.max_len = max_len

        # ì£¼íŒŒìˆ˜ ê³„ì‚°
        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.register_buffer('inv_freq', inv_freq)

        # ìºì‹œ ìƒì„±
        self._build_cache(max_len)

    def _build_cache(self, seq_len: int):
        t = torch.arange(seq_len, device=self.inv_freq.device)
        freqs = torch.einsum('i,j->ij', t, self.inv_freq)
        emb = torch.cat((freqs, freqs), dim=-1)
        self.register_buffer('cos_cached', emb.cos())
        self.register_buffer('sin_cached', emb.sin())

    def forward(self, q: torch.Tensor, k: torch.Tensor) -> tuple:
        """Queryì™€ Keyì— íšŒì „ ë³€í™˜ ì ìš©"""
        seq_len = q.shape[1]
        cos = self.cos_cached[:seq_len].unsqueeze(0)
        sin = self.sin_cached[:seq_len].unsqueeze(0)

        q_embed = (q * cos) + (self._rotate_half(q) * sin)
        k_embed = (k * cos) + (self._rotate_half(k) * sin)
        return q_embed, k_embed

    def _rotate_half(self, x: torch.Tensor) -> torch.Tensor:
        x1, x2 = x[..., :x.shape[-1]//2], x[..., x.shape[-1]//2:]
        return torch.cat((-x2, x1), dim=-1)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    batch_size, seq_len, d_model = 2, 128, 512

    # ì‚¬ì¸/ì½”ì‚¬ì¸ ì¸ì½”ë”©
    sinusoidal_pe = SinusoidalPositionalEncoding(d_model)
    x = torch.randn(batch_size, seq_len, d_model)
    x_with_pos = sinusoidal_pe(x)
    print(f"Sinusoidal PE ì¶œë ¥: {x_with_pos.shape}")

    # RoPE
    rope = RotaryPositionalEncoding(dim=64)  # head_dim
    q = torch.randn(batch_size, seq_len, 8, 64)  # 8 heads
    k = torch.randn(batch_size, seq_len, 8, 64)
    q_rope, k_rope = rope(q, k)
    print(f"RoPE ì ìš© í›„ Q: {q_rope.shape}, K: {k_rope.shape}")</code></pre>
                </div>
            </div>
        </section>

        <!-- ì„±ëŠ¥ ë¹„êµ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“Š í¬ì§€ì…”ë„ ì¸ì½”ë”© ë°©ì‹ ë¹„êµ</h2>
            <div class="section-content">
                <table class="spec-table">
                    <tr>
                        <th>ë°©ì‹</th>
                        <th>ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸</th>
                        <th>ì™¸ì‚½ ì„±ëŠ¥</th>
                        <th>ì‚¬ìš© ëª¨ë¸</th>
                    </tr>
                    <tr>
                        <td>Sinusoidal (Absolute)</td>
                        <td>í•™ìŠµ ì‹œ ê¸¸ì´</td>
                        <td>ë³´í†µ</td>
                        <td>ì›ë³¸ Transformer</td>
                    </tr>
                    <tr>
                        <td>Learned Embedding</td>
                        <td>í•™ìŠµ ì‹œ ê¸¸ì´</td>
                        <td>ë‚®ìŒ</td>
                        <td>BERT, GPT-2</td>
                    </tr>
                    <tr>
                        <td>RoPE</td>
                        <td>8K~128K+</td>
                        <td>ìš°ìˆ˜</td>
                        <td>LLaMA, Mistral, Qwen</td>
                    </tr>
                    <tr>
                        <td>ALiBi</td>
                        <td>ë¬´ì œí•œ</td>
                        <td>ë§¤ìš° ìš°ìˆ˜</td>
                        <td>BLOOM, MPT</td>
                    </tr>
                    <tr>
                        <td>YaRN (RoPE í™•ì¥)</td>
                        <td>128K+</td>
                        <td>ìš°ìˆ˜</td>
                        <td>LLaMA 2 Long</td>
                    </tr>
                </table>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”</h2>
            <div class="section-content">
                <div class="conversation-examples">
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ íšŒì˜ì—ì„œ</div>
                        <div class="conv-quote">"ê¸´ ë¬¸ì„œ RAGì—ì„œ ê²€ìƒ‰ í’ˆì§ˆì´ ë–¨ì–´ì§€ëŠ” ê±´ í¬ì§€ì…”ë„ ì¸ì½”ë”© í•œê³„ ë•Œë¬¸ì¼ ìˆ˜ ìˆì–´ìš”. í˜„ì¬ 4K ì»¨í…ìŠ¤íŠ¸ ëª¨ë¸ì„ RoPE ê¸°ë°˜ì˜ 128K ëª¨ë¸ë¡œ êµì²´í•˜ë©´ ì²­í¬ ë¶„í•  ì—†ì´ ì „ì²´ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."</div>
                    </div>
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ ë©´ì ‘ì—ì„œ</div>
                        <div class="conv-quote">"Transformerì—ì„œ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì´ í•„ìš”í•œ ì´ìœ ëŠ” Self-Attentionì´ ìˆœì„œì— ë¬´ê´€í•œ(permutation invariant) ì—°ì‚°ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. sin/cos í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ í•™ìŠµ ì—†ì´ë„ ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ì„ í˜• ë³€í™˜ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆì–´ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤."</div>
                    </div>
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ ê¸°ìˆ  í† ë¡ ì—ì„œ</div>
                        <div class="conv-quote">"RoPEê°€ ì™¸ì‚½ ì„±ëŠ¥ì´ ì¢‹ì€ ê±´ Query-Key ë‚´ì ì—ì„œ ìƒëŒ€ ìœ„ì¹˜ë§Œ ë°˜ì˜ë˜ê¸° ë•Œë¬¸ì´ì—ìš”. ALiBiëŠ” ì•„ì˜ˆ Attention ì ìˆ˜ì— ì„ í˜• í˜ë„í‹°ë¥¼ ì£¼ëŠ” ë°©ì‹ì´ë¼ ì»¨í…ìŠ¤íŠ¸ í™•ì¥ì— ë” ìœ ì—°í•˜ì§€ë§Œ, í•™ìŠµ ì‹œ ë³´ì§€ ëª»í•œ íŒ¨í„´ì—ì„œëŠ” RoPEê°€ ë” ë‚˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."</div>
                    </div>
                </div>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­</h2>
            <div class="section-content">
                <div class="warning-list">
                    <div class="warning-item">
                        <div class="warning-icon">âŒ</div>
                        <div class="warning-content">
                            <h4>í•™ìŠµ ì‹œ ìµœëŒ€ ê¸¸ì´ë¥¼ ë„˜ì–´ì„œ ì¶”ë¡ í•˜ê¸°</h4>
                            <p>Learned Positional Embeddingì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸(BERT, GPT-2)ì€ í•™ìŠµ ì‹œ max_lengthë¥¼ ì´ˆê³¼í•˜ë©´ ìœ„ì¹˜ ì„ë² ë”©ì´ ì—†ì–´ ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ì €í•˜ë©ë‹ˆë‹¤. ë°˜ë“œì‹œ ëª¨ë¸ì˜ ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ í™•ì¸í•˜ì„¸ìš”.</p>
                        </div>
                    </div>
                    <div class="warning-item">
                        <div class="warning-icon">âŒ</div>
                        <div class="warning-content">
                            <h4>í¬ì§€ì…”ë„ ì¸ì½”ë”©ê³¼ í† í° ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜</h4>
                            <p>í¬ì§€ì…”ë„ ì¸ì½”ë”©ì˜ ì°¨ì›ì€ í† í° ì„ë² ë”© ì°¨ì›(d_model)ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ë”í•˜ê¸° ì—°ì‚°ì´ ë¶ˆê°€ëŠ¥í•˜ë©´ ëŸ°íƒ€ì„ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.</p>
                        </div>
                    </div>
                    <div class="warning-item">
                        <div class="warning-icon">âœ…</div>
                        <div class="warning-content">
                            <h4>ê¸´ ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”í•˜ë©´ RoPE/ALiBi ëª¨ë¸ ì„ íƒ</h4>
                            <p>ë¬¸ì„œ QA, ì½”ë“œ ë¶„ì„ ë“± ê¸´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ê°€ í•„ìš”í•˜ë©´ ì²˜ìŒë¶€í„° RoPE ê¸°ë°˜ ëª¨ë¸(LLaMA 3, Mistral, Claude)ì„ ì„ íƒí•˜ì„¸ìš”. ë‚˜ì¤‘ì— ì»¨í…ìŠ¤íŠ¸ë¥¼ í™•ì¥í•˜ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ì•ˆì •ì ì…ë‹ˆë‹¤.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="section-content">
                <div class="related-terms">
                    <a href="/ko/term/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8/" class="related-term-link">Transformer</a>
                    <a href="/ko/term/%EC%85%80%ED%94%84%20%EC%96%B4%ED%85%90%EC%85%98/" class="related-term-link">Self-Attention</a>
                    <a href="/ko/term/%EC%9E%84%EB%B2%A0%EB%94%A9/" class="related-term-link">ì„ë² ë”©</a>
                    <a href="/ko/term/%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80/" class="related-term-link">í† í¬ë‚˜ì´ì €</a>
                    <a href="/ko/term/%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%9C%88%EB%8F%84%EC%9A%B0/" class="related-term-link">ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°</a>
                </div>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="section-content">
                <div class="learn-more">
                    <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener" class="learn-link">
                        <span>ğŸ“„</span> Attention Is All You Need (ì›ë³¸ ë…¼ë¬¸)
                    </a>
                    <a href="https://arxiv.org/abs/2104.09864" target="_blank" rel="noopener" class="learn-link">
                        <span>ğŸ“„</span> RoFormer: Enhanced Transformer with Rotary Position Embedding
                    </a>
                    <a href="https://arxiv.org/abs/2108.12409" target="_blank" rel="noopener" class="learn-link">
                        <span>ğŸ“„</span> Train Short, Test Long: ALiBi Paper
                    </a>
                </div>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }
    </script>
<script src="/glossary/js/term-sections.js?v=20260129231616"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>