<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>T5 (Text-to-Text Transfer Transformer) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="ëª¨ë“  NLP ì‘ì—…ì„ í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í†µì¼í•œ Googleì˜ í˜ì‹ ì ì¸ Transformer ëª¨ë¸.">
    <meta name="keywords" content="T5, Text-to-Text Transfer Transformer, Google T5, NLP, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/T5/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/T5/">
    <meta property="og:title" content="T5 (Text-to-Text Transfer Transformer) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="ëª¨ë“  NLP ì‘ì—…ì„ í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í†µì¼í•œ Googleì˜ í˜ì‹ ì ì¸ Transformer ëª¨ë¸.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="T5 (Text-to-Text Transfer Transformer) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="ëª¨ë“  NLP ì‘ì—…ì„ í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í†µì¼í•œ Googleì˜ í˜ì‹ ì ì¸ Transformer ëª¨ë¸.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "T5",
        "description": "ëª¨ë“  NLP ì‘ì—…ì„ í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í†µì¼í•œ Googleì˜ í˜ì‹ ì ì¸ Transformer ëª¨ë¸.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        /* Term Section Styles */
        .term-section {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 1.5rem;
        }
        .section-title {
            font-size: 1.4rem;
            font-weight: 600;
            color: #f1f5f9;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .section-content {
            color: #cbd5e1;
            line-height: 1.8;
        }
        .section-content p {
            margin-bottom: 1rem;
        }
        .section-content p:last-child {
            margin-bottom: 0;
        }

        /* Spec Table */
        .spec-table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        .spec-table th, .spec-table td {
            padding: 0.75rem 1rem;
            text-align: left;
            border-bottom: 1px solid rgba(168, 85, 247, 0.2);
        }
        .spec-table th {
            background: rgba(168, 85, 247, 0.1);
            color: #a855f7;
            font-weight: 600;
        }
        .spec-table td {
            color: #e2e8f0;
        }
        .spec-table tr:hover td {
            background: rgba(168, 85, 247, 0.05);
        }

        /* Code Block Styles */
        .code-block {
            background: #1e293b;
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            position: relative;
            overflow-x: auto;
        }
        .code-block pre {
            margin: 0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }
        .code-block code {
            color: #e2e8f0;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            background: rgba(168, 85, 247, 0.3);
            border: 1px solid rgba(168, 85, 247, 0.5);
            color: #e2e8f0;
            padding: 0.4rem 0.8rem;
            border-radius: 6px;
            font-size: 0.8rem;
            cursor: pointer;
            transition: all 0.2s;
        }
        .copy-btn:hover {
            background: rgba(168, 85, 247, 0.5);
        }

        /* Conversation Examples */
        .conversation-examples {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        .conv-item {
            background: rgba(30, 41, 59, 0.5);
            border-radius: 12px;
            padding: 1.25rem;
            border-left: 3px solid #a855f7;
        }
        .conv-context {
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 0.5rem;
            font-weight: 500;
        }
        .conv-quote {
            color: #e2e8f0;
            font-style: italic;
            line-height: 1.6;
        }

        /* Warning List */
        .warning-list {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        .warning-item {
            display: flex;
            gap: 0.75rem;
            padding: 1rem;
            background: rgba(30, 41, 59, 0.5);
            border-radius: 8px;
        }
        .warning-icon {
            font-size: 1.2rem;
            flex-shrink: 0;
        }
        .warning-content {
            color: #cbd5e1;
            line-height: 1.6;
        }

        /* Related Terms */
        .related-terms {
            display: flex;
            flex-wrap: wrap;
            gap: 0.75rem;
        }
        .related-term-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.1);
            border: 1px solid rgba(168, 85, 247, 0.3);
            border-radius: 20px;
            color: #a855f7;
            text-decoration: none;
            font-size: 0.9rem;
            transition: all 0.2s;
        }
        .related-term-link:hover {
            background: rgba(168, 85, 247, 0.2);
            transform: translateY(-2px);
        }

        /* Learn More */
        .learn-more {
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
        }
        .learn-link {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            padding: 0.75rem 1rem;
            background: rgba(30, 41, 59, 0.5);
            border-radius: 8px;
            color: #e2e8f0;
            text-decoration: none;
            transition: all 0.2s;
        }
        .learn-link:hover {
            background: rgba(30, 41, 59, 0.8);
            transform: translateX(5px);
        }
        .learn-link-icon {
            font-size: 1.2rem;
        }

        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
            .term-section { padding: 1.5rem; }
            .spec-table { font-size: 0.85rem; }
            .spec-table th, .spec-table td { padding: 0.5rem; }
        }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">T5</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">T5</h1>
            <p class="term-english">Text-to-Text Transfer Transformer</p>
            <div class="term-description">
                <p>ëª¨ë“  NLP ì‘ì—…ì„ "í…ìŠ¤íŠ¸ ì…ë ¥ -> í…ìŠ¤íŠ¸ ì¶œë ¥" í˜•ì‹ìœ¼ë¡œ í†µì¼í•œ Googleì˜ í˜ì‹ ì ì¸ Transformer ëª¨ë¸. ë²ˆì—­, ìš”ì•½, QA, ë¶„ë¥˜ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë‹¨ì¼ í”„ë ˆì„ì›Œí¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p><strong>T5(Text-to-Text Transfer Transformer)</strong>ëŠ” Google Researchê°€ 2019ë…„ ë°œí‘œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. T5ì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ëª¨ë“  NLP ì‘ì—…ì„ í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í†µì¼í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë²ˆì—­ì€ "translate English to German: Hello" -> "Hallo", ê°ì • ë¶„ì„ì€ "sentiment: This movie is great" -> "positive"ì²˜ëŸ¼ í‘œí˜„í•©ë‹ˆë‹¤. ì´ í†µì¼ëœ ì ‘ê·¼ë²•ìœ¼ë¡œ í•˜ë‚˜ì˜ ëª¨ë¸ì´ ìˆ˜ì‹­ ê°€ì§€ NLP ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

                <p>T5ëŠ” "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer" ë…¼ë¬¸ì—ì„œ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤. Google ì—°êµ¬íŒ€ì€ C4(Colossal Clean Crawled Corpus)ë¼ëŠ” 750GB ê·œëª¨ì˜ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê³ , ë‹¤ì–‘í•œ ì‚¬ì „ í•™ìŠµ ë°©ë²•, ëª¨ë¸ í¬ê¸°, í•™ìŠµ ì „ëµì„ ì²´ê³„ì ìœ¼ë¡œ ë¹„êµ ì‹¤í—˜í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” NLP ë¶„ì•¼ì˜ ì „ì´ í•™ìŠµ ë°œì „ì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í–ˆìŠµë‹ˆë‹¤.</p>

                <p>T5ëŠ” ì¸ì½”ë”-ë””ì½”ë” Transformer ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” ì¸ì½”ë”ì—ì„œ ì²˜ë¦¬ë˜ê³ , ë””ì½”ë”ê°€ ì¶œë ¥ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµì€ span corruption ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤ - ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ êµ¬ê°„ì„ ë§ˆìŠ¤í‚¹í•˜ê³  ëª¨ë¸ì´ ì´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤. ëª¨ë¸ í¬ê¸°ëŠ” Small(60M)ë¶€í„° 11B íŒŒë¼ë¯¸í„°ê¹Œì§€ ë‹¤ì–‘í•˜ë©°, í¬ê¸°ì— ë”°ë¼ ì„±ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤.</p>

                <p>T5ëŠ” LLM ì—°êµ¬ì˜ ì¤‘ìš”í•œ ì´ì •í‘œì…ë‹ˆë‹¤. ì´í›„ ë“±ì¥í•œ FLAN-T5, UL2, PaLM ë“±ì´ T5ì˜ ì•„ì´ë””ì–´ë¥¼ ë°œì „ì‹œì¼°ìŠµë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œ T5ëŠ” ìš”ì•½, ë²ˆì—­, QA ì‹œìŠ¤í…œì— ë„ë¦¬ ì‚¬ìš©ë˜ë©°, Hugging Faceì—ì„œ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ íŒŒì¸íŠœë‹ íš¨ìœ¨ì´ ì¢‹ì•„ íŠ¹ì • ë„ë©”ì¸ ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="section-content">
                <p>Hugging Face Transformersë¥¼ ì‚¬ìš©í•œ T5 í™œìš© ì˜ˆì œì…ë‹ˆë‹¤.</p>

                <div class="code-block" data-lang="python">
                
                    <pre><code class="language-python"># T5 ëª¨ë¸ í™œìš© ì˜ˆì œ
from transformers import T5Tokenizer, T5ForConditionalGeneration
import torch

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ (t5-small, t5-base, t5-large, t5-3b, t5-11b)
model_name = "t5-base"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)

def generate_text(input_text: str, max_length: int = 128) -> str:
    """T5ë¡œ í…ìŠ¤íŠ¸ ìƒì„±"""
    input_ids = tokenizer.encode(input_text, return_tensors="pt")

    outputs = model.generate(
        input_ids,
        max_length=max_length,
        num_beams=4,
        early_stopping=True,
        no_repeat_ngram_size=2
    )

    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ===== 1. ë²ˆì—­ (Translation) =====
print("=" * 50)
print("1. ë²ˆì—­ (Translation)")
print("=" * 50)

en_to_de = "translate English to German: The house is wonderful."
de_result = generate_text(en_to_de)
print(f"ì…ë ¥: {en_to_de}")
print(f"ì¶œë ¥: {de_result}")

en_to_fr = "translate English to French: Machine learning is fascinating."
fr_result = generate_text(en_to_fr)
print(f"\nì…ë ¥: {en_to_fr}")
print(f"ì¶œë ¥: {fr_result}")

# ===== 2. ìš”ì•½ (Summarization) =====
print("\n" + "=" * 50)
print("2. ìš”ì•½ (Summarization)")
print("=" * 50)

article = """
summarize: The Amazon rainforest produces about 20% of the world's oxygen
and contains 10% of all species on Earth. Climate change and deforestation
pose serious threats to this vital ecosystem. Scientists warn that losing
the Amazon could accelerate global warming significantly. Conservation
efforts are critical for the planet's future.
"""
summary = generate_text(article, max_length=64)
print(f"ì›ë¬¸: {article.strip()}")
print(f"ìš”ì•½: {summary}")

# ===== 3. ë¬¸ë²• êµì • (Grammar Correction) =====
print("\n" + "=" * 50)
print("3. ë¬¸ë²• êµì • (Grammar Correction)")
print("=" * 50)

# FLAN-T5 ë˜ëŠ” íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì—ì„œ ë” ì¢‹ì€ ê²°ê³¼
grammar_input = "cola sentence: He don't knows nothing about it."
corrected = generate_text(grammar_input)
print(f"ì…ë ¥: {grammar_input}")
print(f"ì¶œë ¥: {corrected}")

# ===== 4. ì§ˆë¬¸ ë‹µë³€ (Question Answering) =====
print("\n" + "=" * 50)
print("4. ì§ˆë¬¸ ë‹µë³€ (Question Answering)")
print("=" * 50)

qa_input = """
question: What is the capital of France?
context: France is a country in Western Europe. Its capital city is Paris,
which is known for the Eiffel Tower and the Louvre Museum.
"""
answer = generate_text(qa_input, max_length=32)
print(f"ì§ˆë¬¸ & ì»¨í…ìŠ¤íŠ¸: {qa_input.strip()}")
print(f"ë‹µë³€: {answer}")

# ===== 5. FLAN-T5 (í–¥ìƒëœ ë²„ì „) =====
print("\n" + "=" * 50)
print("5. FLAN-T5 (Instruction-tuned)")
print("=" * 50)

# FLAN-T5ëŠ” instruction followingì´ ë” ì¢‹ìŒ
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

flan_model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
flan_tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")

def flan_generate(prompt: str) -> str:
    inputs = flan_tokenizer(prompt, return_tensors="pt")
    outputs = flan_model.generate(**inputs, max_length=100)
    return flan_tokenizer.decode(outputs[0], skip_special_tokens=True)

instruction = "Explain what machine learning is in simple terms."
response = flan_generate(instruction)
print(f"ì§ˆë¬¸: {instruction}")
print(f"ë‹µë³€: {response}")</code></pre>
                    <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                </div>
            </div>
        </section>

        <!-- ì„±ëŠ¥ & ë¹„ìš© ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“Š ì„±ëŠ¥ & ë¹„ìš©</h2>
            <div class="section-content">
                <p><strong>T5 ëª¨ë¸ í¬ê¸°ë³„ ìŠ¤í™</strong></p>
                <table class="spec-table">
                    <tr>
                        <th>ëª¨ë¸</th>
                        <th>íŒŒë¼ë¯¸í„°</th>
                        <th>ì¸ì½”ë”/ë””ì½”ë”</th>
                        <th>VRAM ìš”êµ¬ëŸ‰</th>
                        <th>ì£¼ìš” ìš©ë„</th>
                    </tr>
                    <tr>
                        <td>T5-Small</td>
                        <td>60M</td>
                        <td>6/6 ë ˆì´ì–´</td>
                        <td>~1GB</td>
                        <td>ì‹¤í—˜, ì—£ì§€ ë””ë°”ì´ìŠ¤</td>
                    </tr>
                    <tr>
                        <td>T5-Base</td>
                        <td>220M</td>
                        <td>12/12 ë ˆì´ì–´</td>
                        <td>~2GB</td>
                        <td>ë²”ìš©, ë¹ ë¥¸ ì¶”ë¡ </td>
                    </tr>
                    <tr>
                        <td>T5-Large</td>
                        <td>770M</td>
                        <td>24/24 ë ˆì´ì–´</td>
                        <td>~4GB</td>
                        <td>ê³ í’ˆì§ˆ ìš”ì•½/ë²ˆì—­</td>
                    </tr>
                    <tr>
                        <td>T5-3B</td>
                        <td>3B</td>
                        <td>24/24 ë ˆì´ì–´</td>
                        <td>~12GB</td>
                        <td>í”„ë¡œë•ì…˜ NLP</td>
                    </tr>
                    <tr>
                        <td>T5-11B</td>
                        <td>11B</td>
                        <td>24/24 ë ˆì´ì–´</td>
                        <td>~45GB</td>
                        <td>ì—°êµ¬/ìµœê³  ì„±ëŠ¥</td>
                    </tr>
                </table>
                <p style="font-size: 0.9rem; color: #94a3b8; margin-top: 1rem;">
                    * FLAN-T5: Instruction íŠœë‹ëœ ë²„ì „, ë™ì¼ í¬ê¸°ì—ì„œ ë” ì¢‹ì€ zero-shot ì„±ëŠ¥<br>
                    * Hugging Faceì—ì„œ ë¬´ë£Œ ì‚¬ìš© ê°€ëŠ¥, ìƒìš© API ì—†ìŒ (ìì²´ í˜¸ìŠ¤íŒ… í•„ìš”)
                </p>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ëŒ€í™” ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”</h2>
            <div class="section-content">
                <div class="conversation-examples">
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ íšŒì˜ì—ì„œ</div>
                        <div class="conv-quote">"ìš”ì•½ ëª¨ë¸ ë„ì…ì„ ê²€í†  ì¤‘ì¸ë°, T5-baseë¡œ ì‹œì‘í•˜ë©´ ì¢‹ê² ì–´ìš”. íŒŒë¼ë¯¸í„°ê°€ 220Mìœ¼ë¡œ ê°€ë³ê³ , í•œêµ­ì–´ëŠ” mT5 ì¨ì•¼ í•˜ëŠ”ë° í’ˆì§ˆì´ ì˜ì–´ë³´ë‹¤ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. FLAN-T5ê°€ instruction followingì´ ë” ì¢‹ìœ¼ë‹ˆ ë¹„êµí•´ë³´ì£ ."</div>
                    </div>
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ ë©´ì ‘ì—ì„œ</div>
                        <div class="conv-quote">"T5ì˜ í•µì‹¬ í˜ì‹ ì€ text-to-text í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë¶„ë¥˜, ìƒì„±, QA ëª¨ë‘ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ë‹ˆê¹Œ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµì´ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤. GPTëŠ” ë””ì½”ë”ë§Œ ì“°ì§€ë§Œ, T5ëŠ” ì¸ì½”ë”-ë””ì½”ë”ë¼ì„œ ì¡°ê±´ë¶€ ìƒì„± ì‘ì—…ì— ë” ì í•©í•´ìš”."</div>
                    </div>
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ ê¸°ìˆ  í† ë¡ ì—ì„œ</div>
                        <div class="conv-quote">"T5 íŒŒì¸íŠœë‹í•  ë•Œ prefix ë°©ì‹ ì¨ë³´ì„¸ìš”. 'summarize:', 'translate English to Korean:' ì²˜ëŸ¼ task prefixë¥¼ ë¶™ì´ë©´ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì—¬ëŸ¬ ì‘ì—… ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LoRA ì ìš©í•˜ë©´ ë©”ëª¨ë¦¬ë„ ì ˆì•½ë˜ê³ ìš”."</div>
                    </div>
                </div>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­</h2>
            <div class="section-content">
                <div class="warning-list">
                    <div class="warning-item">
                        <span class="warning-icon">âŒ</span>
                        <div class="warning-content">
                            <strong>í•œêµ­ì–´ì— T5 ì‚¬ìš©</strong><br>
                            ê¸°ë³¸ T5ëŠ” ì˜ì–´ ì¤‘ì‹¬ í•™ìŠµë˜ì–´ í•œêµ­ì–´ ì„±ëŠ¥ì´ ë‚®ìŠµë‹ˆë‹¤. í•œêµ­ì–´ ì‘ì—…ì—ëŠ” mT5(multilingual) ë˜ëŠ” KE-T5(í•œêµ­ì–´ íŠ¹í™”) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.
                        </div>
                    </div>
                    <div class="warning-item">
                        <span class="warning-icon">âŒ</span>
                        <div class="warning-content">
                            <strong>T5ë¥¼ ì±„íŒ…/ëŒ€í™”ì— ì‚¬ìš©</strong><br>
                            T5ëŠ” ë‹¨ì¼ í„´ ì‘ì—…ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë©€í‹°í„´ ëŒ€í™”ë‚˜ ê¸´ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ê°€ í•„ìš”í•˜ë©´ GPT ê³„ì—´ì´ë‚˜ LLaMAê°€ ë” ì í•©í•©ë‹ˆë‹¤.
                        </div>
                    </div>
                    <div class="warning-item">
                        <span class="warning-icon">âœ…</span>
                        <div class="warning-content">
                            <strong>ì˜¬ë°”ë¥¸ ì ‘ê·¼ë²•</strong><br>
                            1) ìš”ì•½/ë²ˆì—­/QAì²˜ëŸ¼ ëª…í™•í•œ ì…ì¶œë ¥ ì‘ì—…ì— T5 í™œìš©, 2) FLAN-T5ë¡œ zero-shot ì„±ëŠ¥ í™•ë³´, 3) ë„ë©”ì¸ íŠ¹í™” ì‹œ íŒŒì¸íŠœë‹, 4) í° ëª¨ë¸ í•„ìš”ì‹œ ì–‘ìí™”(INT8) ì ìš©.
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="section-content">
                <div class="related-terms">
                    <a href="/ko/term/Transformer/" class="related-term-link">Transformer</a>
                    <a href="/ko/term/BERT/" class="related-term-link">BERT</a>
                    <a href="/ko/term/GPT/" class="related-term-link">GPT</a>
                    <a href="/ko/term/Fine-tuning/" class="related-term-link">Fine-tuning</a>
                    <a href="/ko/term/Transfer%20Learning/" class="related-term-link">Transfer Learning</a>
                    <a href="/ko/term/Encoder-Decoder/" class="related-term-link">Encoder-Decoder</a>
                </div>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="section-content">
                <div class="learn-more">
                    <a href="https://arxiv.org/abs/1910.10683" target="_blank" class="learn-link">
                        <span class="learn-link-icon">ğŸ“</span>
                        <span>T5 ì›ë³¸ ë…¼ë¬¸ (arXiv)</span>
                    </a>
                    <a href="https://huggingface.co/docs/transformers/model_doc/t5" target="_blank" class="learn-link">
                        <span class="learn-link-icon">ğŸ“„</span>
                        <span>Hugging Face T5 ë¬¸ì„œ</span>
                    </a>
                    <a href="https://github.com/google-research/text-to-text-transfer-transformer" target="_blank" class="learn-link">
                        <span class="learn-link-icon">ğŸ“</span>
                        <span>Google T5 GitHub ì €ì¥ì†Œ</span>
                    </a>
                </div>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }
    </script>
<script src="/glossary/js/term-sections.js"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>
