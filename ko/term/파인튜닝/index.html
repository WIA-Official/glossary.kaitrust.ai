<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>íŒŒì¸íŠœë‹ (Fine-tuning) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµ. ì ì€ ë°ì´í„°ë¡œ ë†’ì€ ì„±ëŠ¥. LoRAë¡œ íš¨ìœ¨í™”.">
    <meta name="keywords" content="íŒŒì¸íŠœë‹, Fine-tuning, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D/">
    <meta property="og:title" content="íŒŒì¸íŠœë‹ (Fine-tuning) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµ. ì ì€ ë°ì´í„°ë¡œ ë†’ì€ ì„±ëŠ¥. LoRAë¡œ íš¨ìœ¨í™”.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="íŒŒì¸íŠœë‹ (Fine-tuning) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµ. ì ì€ ë°ì´í„°ë¡œ ë†’ì€ ì„±ëŠ¥. LoRAë¡œ íš¨ìœ¨í™”.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "íŒŒì¸íŠœë‹",
        "description": "ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµ. ì ì€ ë°ì´í„°ë¡œ ë†’ì€ ì„±ëŠ¥. LoRAë¡œ íš¨ìœ¨í™”.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }
        .term-section { background: rgba(15, 23, 42, 0.6); border: 1px solid rgba(168, 85, 247, 0.1); border-radius: 16px; padding: 2rem; margin-bottom: 1.5rem; }
        .section-title { font-size: 1.3rem; font-weight: 600; margin-bottom: 1.5rem; color: #f1f5f9; }
        .section-content { color: #cbd5e1; line-height: 1.8; }
        .section-content p { margin-bottom: 1rem; }
        .code-block { position: relative; background: #1e293b; border-radius: 12px; padding: 1.5rem; margin: 1rem 0; overflow-x: auto; }
        .code-block pre { margin: 0; color: #e2e8f0; font-family: 'JetBrains Mono', monospace; font-size: 0.9rem; line-height: 1.6; }
        .copy-btn { position: absolute; top: 0.75rem; right: 0.75rem; padding: 0.5rem 1rem; background: rgba(168, 85, 247, 0.3); border: 1px solid rgba(168, 85, 247, 0.5); border-radius: 6px; color: #e2e8f0; font-size: 0.8rem; cursor: pointer; transition: all 0.2s; }
        .copy-btn:hover { background: rgba(168, 85, 247, 0.5); }
        .spec-table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
        .spec-table th, .spec-table td { padding: 0.75rem; text-align: left; border-bottom: 1px solid rgba(168, 85, 247, 0.2); }
        .spec-table th { background: rgba(168, 85, 247, 0.1); color: #a855f7; font-weight: 600; }
        .conversation-examples { display: flex; flex-direction: column; gap: 1rem; }
        .conv-item { background: rgba(30, 41, 59, 0.5); border-radius: 12px; padding: 1.25rem; border-left: 3px solid #a855f7; }
        .conv-context { font-size: 0.85rem; color: #a855f7; margin-bottom: 0.5rem; font-weight: 500; }
        .conv-quote { color: #e2e8f0; font-style: italic; line-height: 1.6; }
        .warning-list { display: flex; flex-direction: column; gap: 1rem; }
        .warning-item { display: flex; gap: 1rem; padding: 1rem; background: rgba(30, 41, 59, 0.5); border-radius: 12px; }
        .warning-icon { font-size: 1.5rem; flex-shrink: 0; }
        .warning-content h4 { color: #f1f5f9; margin-bottom: 0.25rem; font-size: 1rem; }
        .warning-content p { color: #94a3b8; font-size: 0.9rem; margin: 0; }
        .related-terms { display: flex; flex-wrap: wrap; gap: 0.75rem; }
        .related-term-link { display: inline-block; padding: 0.5rem 1rem; background: rgba(168, 85, 247, 0.15); border: 1px solid rgba(168, 85, 247, 0.3); border-radius: 8px; color: #c4b5fd; text-decoration: none; font-size: 0.9rem; transition: all 0.2s; }
        .related-term-link:hover { background: rgba(168, 85, 247, 0.3); transform: translateY(-2px); }
        .learn-more { display: flex; flex-direction: column; gap: 0.75rem; }
        .learn-link { display: flex; align-items: center; gap: 0.75rem; color: #94a3b8; text-decoration: none; padding: 0.75rem; background: rgba(30, 41, 59, 0.3); border-radius: 8px; transition: all 0.2s; }
        .learn-link:hover { background: rgba(30, 41, 59, 0.6); color: #e2e8f0; }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css?v=20260129233538">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">íŒŒì¸íŠœë‹</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">íŒŒì¸íŠœë‹</h1>
            <p class="term-english">Fine-tuning</p>
            <div class="term-description">
                <p>ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµ. ì ì€ ë°ì´í„°ë¡œ ë†’ì€ ì„±ëŠ¥. LoRAë¡œ íš¨ìœ¨í™”.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p>íŒŒì¸íŠœë‹(Fine-tuning)ì€ ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸(Pre-trained Model)ì„ íŠ¹ì • ë„ë©”ì¸ì´ë‚˜ ì‘ì—…ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì²˜ìŒë¶€í„° í•™ìŠµí•˜ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ì ì€ ë°ì´í„°ì™€ ì‹œê°„ìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë°˜ ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ ì–¸ì–´/ë¹„ì „ ì´í•´ ëŠ¥ë ¥ì„ ìœ ì§€í•˜ë©´ì„œ íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ì„±ì„ ë”í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p>

                <p>íŒŒì¸íŠœë‹ì˜ ê°œë…ì€ 2018ë…„ BERTì˜ ë“±ì¥ê³¼ í•¨ê»˜ ëŒ€ì¤‘í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì „ì—ë„ ì „ì´í•™ìŠµ(Transfer Learning)ì´ ìˆì—ˆì§€ë§Œ, Transformer ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ë“±ì¥í•˜ë©´ì„œ íŒŒì¸íŠœë‹ì˜ íš¨ê³¼ê°€ ê·¹ì ìœ¼ë¡œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. 2023ë…„ ì´í›„ LLM ì‹œëŒ€ì—ëŠ” Instruction Tuning, RLHF(ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ), LoRA ê°™ì€ íš¨ìœ¨ì ì¸ íŒŒì¸íŠœë‹ ê¸°ë²•ì´ ë°œì „í•˜ì—¬, ìˆ˜ì‹­ì–µ íŒŒë¼ë¯¸í„° ëª¨ë¸ë„ ì†Œê·œëª¨ GPUì—ì„œ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</p>

                <p>íŒŒì¸íŠœë‹ ë°©ë²•ì€ í¬ê²Œ ì„¸ ê°€ì§€ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. Full Fine-tuningì€ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì „í†µì  ë°©ì‹ì…ë‹ˆë‹¤. PEFT(Parameter-Efficient Fine-Tuning)ëŠ” LoRA, QLoRA, Adapters ë“±ì„ ì‚¬ìš©í•´ ì†Œìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµí•˜ì—¬ ë©”ëª¨ë¦¬ì™€ ì‹œê°„ì„ ì ˆì•½í•©ë‹ˆë‹¤. Instruction Tuningì€ ëª…ë ¹-ì‘ë‹µ ìŒìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ì§€ì‹œë¥¼ ë” ì˜ ë”°ë¥´ê²Œ í•©ë‹ˆë‹¤. 2024-2025ë…„ì—ëŠ” QLoRAì™€ Unsloth ê°™ì€ ë„êµ¬ë¡œ ì†Œë¹„ììš© GPUì—ì„œë„ 7B-70B ëª¨ë¸ íŒŒì¸íŠœë‹ì´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤.</p>

                <p>ì‹¤ë¬´ì—ì„œ íŒŒì¸íŠœë‹ì€ RAGë¡œ í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ë„ë©”ì¸ íŠ¹í™” ì‘ì—…ì— ì ìš©ë©ë‹ˆë‹¤. ì˜ë£Œ, ë²•ë¥ , ê¸ˆìœµ ë“± ì „ë¬¸ ìš©ì–´ì™€ ë§¥ë½ì´ ì¤‘ìš”í•œ ë¶„ì•¼, íŠ¹ì • ì¶œë ¥ í˜•ì‹ì´ë‚˜ ìŠ¤íƒ€ì¼ì´ í•„ìš”í•œ ê²½ìš°, ì‘ë‹µ ì†ë„ê°€ ì¤‘ìš”í•˜ì—¬ ì™¸ë¶€ ê²€ìƒ‰ì„ ì¤„ì—¬ì•¼ í•˜ëŠ” ê²½ìš°ì— íš¨ê³¼ì ì…ë‹ˆë‹¤. ë‹¤ë§Œ ìµœì‹  ì •ë³´ ë°˜ì˜ì´ í•„ìš”í•˜ë©´ RAGê°€, ë„ë©”ì¸ ì§€ì‹ ë‚´ì¬í™”ê°€ í•„ìš”í•˜ë©´ íŒŒì¸íŠœë‹ì´ ì í•©í•©ë‹ˆë‹¤. ë§ì€ ê²½ìš° ë‘ ê¸°ë²•ì„ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ì´ ìµœì„ ì…ë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="section-content">
                <p>Hugging Faceì™€ PEFTë¥¼ ì‚¬ìš©í•œ LoRA íŒŒì¸íŠœë‹ ì˜ˆì œì…ë‹ˆë‹¤.</p>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                    <pre><code># LoRA íŒŒì¸íŠœë‹ ì˜ˆì œ
# pip install transformers peft datasets accelerate bitsandbytes

from transformers import (
    AutoModelForCausalLM, AutoTokenizer,
    TrainingArguments, Trainer, DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from datasets import load_dataset
import torch

# 4ë¹„íŠ¸ ì–‘ìí™”ë¡œ ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½)
model_name = "meta-llama/Llama-2-7b-hf"
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,
    device_map="auto",
    torch_dtype=torch.float16,
)

# LoRA ì„¤ì •
lora_config = LoraConfig(
    r=16,                    # LoRA rank
    lora_alpha=32,           # ìŠ¤ì¼€ì¼ë§ íŒŒë¼ë¯¸í„°
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],  # ì ìš© ë ˆì´ì–´
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# PEFT ëª¨ë¸ ìƒì„±
model = prepare_model_for_kbit_training(model)
model = get_peft_model(model, lora_config)

# í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
total_params = sum(p.numel() for p in model.parameters())
print(f"í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,} / {total_params:,} ({100 * trainable_params / total_params:.2f}%)")

# ë°ì´í„°ì…‹ ì¤€ë¹„ (ì˜ˆ: í•œêµ­ì–´ ì§€ì‹œ ë°ì´í„°)
def preprocess(example):
    prompt = f"### ì§ˆë¬¸: {example['instruction']}\n\n### ë‹µë³€: {example['output']}"
    return tokenizer(prompt, truncation=True, max_length=512)

dataset = load_dataset("your_dataset", split="train")
tokenized_dataset = dataset.map(preprocess, remove_columns=dataset.column_names)

# í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./lora-output",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_steps=100,
)

# í•™ìŠµ ì‹¤í–‰
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),
)
trainer.train()

# ì–´ëŒ‘í„° ì €ì¥
model.save_pretrained("./lora-adapter")</code></pre>
                </div>

                <p>OpenAI APIë¥¼ í†µí•œ GPT íŒŒì¸íŠœë‹ ì˜ˆì œì…ë‹ˆë‹¤.</p>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                    <pre><code># OpenAI íŒŒì¸íŠœë‹ API
# pip install openai

from openai import OpenAI
import json

client = OpenAI()

# 1. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (JSONL í˜•ì‹)
training_data = [
    {
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ìƒë‹´ì›ì…ë‹ˆë‹¤."},
            {"role": "user", "content": "ë°°ì†¡ì´ ì–¸ì œ ì˜¤ë‚˜ìš”?"},
            {"role": "assistant", "content": "ì£¼ë¬¸ ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë°°ì†¡ í˜„í™©ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."}
        ]
    },
    # ... ë” ë§ì€ ì˜ˆì‹œ
]

# JSONL íŒŒì¼ë¡œ ì €ì¥
with open("training_data.jsonl", "w", encoding="utf-8") as f:
    for item in training_data:
        f.write(json.dumps(item, ensure_ascii=False) + "\n")

# 2. íŒŒì¼ ì—…ë¡œë“œ
file = client.files.create(
    file=open("training_data.jsonl", "rb"),
    purpose="fine-tune"
)
print(f"íŒŒì¼ ID: {file.id}")

# 3. íŒŒì¸íŠœë‹ ì‘ì—… ìƒì„±
fine_tune_job = client.fine_tuning.jobs.create(
    training_file=file.id,
    model="gpt-4o-mini-2024-07-18",  # ë˜ëŠ” gpt-3.5-turbo
    hyperparameters={
        "n_epochs": 3,
        "learning_rate_multiplier": 1.0,
    }
)
print(f"ì‘ì—… ID: {fine_tune_job.id}")

# 4. ì‘ì—… ìƒíƒœ í™•ì¸
job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)
print(f"ìƒíƒœ: {job.status}")

# 5. ì™„ë£Œ í›„ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš©
# fine_tuned_model = "ft:gpt-4o-mini:your-org::xxxx"
# response = client.chat.completions.create(
#     model=fine_tuned_model,
#     messages=[{"role": "user", "content": "ë°°ì†¡ ë¬¸ì˜ë“œë¦½ë‹ˆë‹¤"}]
# )</code></pre>
                </div>
            </div>
        </section>

        <!-- ì„±ëŠ¥ & ë¹„ìš© ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“Š ì„±ëŠ¥ & ë¹„ìš©</h2>
            <div class="section-content">
                <p>2025ë…„ 1ì›” ê¸°ì¤€ íŒŒì¸íŠœë‹ ë°©ë²•ë³„ ë¹„êµì…ë‹ˆë‹¤.</p>
                <table class="spec-table">
                    <tr>
                        <th>ë°©ë²•</th>
                        <th>ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰</th>
                        <th>í•™ìŠµ ì†ë„</th>
                        <th>ì„±ëŠ¥</th>
                        <th>ì ìš© ëª¨ë¸</th>
                    </tr>
                    <tr>
                        <td>Full Fine-tuning</td>
                        <td>ë§¤ìš° ë†’ìŒ (80GB+)</td>
                        <td>ëŠë¦¼</td>
                        <td>ìµœê³ </td>
                        <td>7B ì´í•˜</td>
                    </tr>
                    <tr>
                        <td>LoRA</td>
                        <td>ì¤‘ê°„ (24GB)</td>
                        <td>ë¹ ë¦„</td>
                        <td>ë†’ìŒ</td>
                        <td>70B ì´í•˜</td>
                    </tr>
                    <tr>
                        <td>QLoRA (4bit)</td>
                        <td>ë‚®ìŒ (8-16GB)</td>
                        <td>ë¹ ë¦„</td>
                        <td>ë†’ìŒ</td>
                        <td>70B ì´í•˜</td>
                    </tr>
                    <tr>
                        <td>Adapters</td>
                        <td>ë‚®ìŒ</td>
                        <td>ë¹ ë¦„</td>
                        <td>ì¤‘ê°„</td>
                        <td>ëª¨ë“  í¬ê¸°</td>
                    </tr>
                </table>

                <p>í´ë¼ìš°ë“œ íŒŒì¸íŠœë‹ ì„œë¹„ìŠ¤ ê°€ê²© (2025ë…„ 1ì›”):</p>
                <table class="spec-table">
                    <tr>
                        <th>ì„œë¹„ìŠ¤</th>
                        <th>í•™ìŠµ ë¹„ìš©</th>
                        <th>ì¶”ë¡  ë¹„ìš©</th>
                        <th>íŠ¹ì§•</th>
                    </tr>
                    <tr>
                        <td>OpenAI GPT-4o-mini</td>
                        <td>$3.00/1M í† í°</td>
                        <td>$0.15/1M ì…ë ¥</td>
                        <td>ê°€ì¥ ì‰¬ìš´ ì‹œì‘</td>
                    </tr>
                    <tr>
                        <td>Together AI</td>
                        <td>$3.00/ì‹œê°„</td>
                        <td>$0.20/1M í† í°</td>
                        <td>ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì§€ì›</td>
                    </tr>
                    <tr>
                        <td>AWS Bedrock</td>
                        <td>ëª¨ë¸ë³„ ìƒì´</td>
                        <td>ëª¨ë¸ë³„ ìƒì´</td>
                        <td>ì—”í„°í”„ë¼ì´ì¦ˆ í†µí•©</td>
                    </tr>
                </table>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”</h2>
            <div class="section-content">
                <div class="conversation-examples">
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ íšŒì˜ì—ì„œ</div>
                        <div class="conv-quote">"RAGë¡œ í•´ê²° ì•ˆ ë˜ëŠ” ì˜ë£Œ ìš©ì–´ ë¬¸ì œëŠ” íŒŒì¸íŠœë‹ì´ ë‹µì…ë‹ˆë‹¤. 5,000ê°œ ì˜ë£Œ Q&A ìŒìœ¼ë¡œ QLoRA íŒŒì¸íŠœë‹í–ˆë”ë‹ˆ ì „ë¬¸ ìš©ì–´ ì •í™•ë„ê°€ 60%ì—ì„œ 92%ë¡œ í–¥ìƒëê³ , ì‘ë‹µ ì‹œê°„ë„ RAG ê²€ìƒ‰ ì—†ì´ ë¹¨ë¼ì¡ŒìŠµë‹ˆë‹¤."</div>
                    </div>
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ ë©´ì ‘ì—ì„œ</div>
                        <div class="conv-quote">"LoRAì™€ Full Fine-tuningì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•˜ë©´, LoRAëŠ” ì €ì°¨ì› í–‰ë ¬ ë¶„í•´ë¡œ ì›ë³¸ ê°€ì¤‘ì¹˜ëŠ” ë™ê²°í•˜ê³  ì‘ì€ ì–´ëŒ‘í„°ë§Œ í•™ìŠµí•©ë‹ˆë‹¤. 7B ëª¨ë¸ ê¸°ì¤€ í•™ìŠµ íŒŒë¼ë¯¸í„°ê°€ 0.1% ìˆ˜ì¤€ì´ë¼ 8GB GPUì—ì„œë„ ê°€ëŠ¥í•˜ë©´ì„œ ì„±ëŠ¥ ì†ì‹¤ì€ 5% ë¯¸ë§Œì…ë‹ˆë‹¤."</div>
                    </div>
                    <div class="conv-item">
                        <div class="conv-context">ğŸ’¬ ê¸°ìˆ  í† ë¡ ì—ì„œ</div>
                        <div class="conv-quote">"íŒŒì¸íŠœë‹ vs RAG ì„ íƒ ê¸°ì¤€ì€ ëª…í™•í•´ìš”. ë„ë©”ì¸ ì§€ì‹ì„ ë‚´ì¬í™”í•´ì•¼ í•˜ë©´ íŒŒì¸íŠœë‹, ìµœì‹  ì •ë³´ê°€ ê³„ì† ë°”ë€Œë©´ RAGì…ë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì€ ë‘˜ ë‹¤ í•„ìš”í•´ì„œ, ê¸°ë³¸ ì§€ì‹ì€ íŒŒì¸íŠœë‹í•˜ê³  ì‹¤ì‹œê°„ ì •ë³´ëŠ” RAGë¡œ ë³´ê°•í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."</div>
                    </div>
                </div>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­</h2>
            <div class="section-content">
                <div class="warning-list">
                    <div class="warning-item">
                        <div class="warning-icon">âŒ</div>
                        <div class="warning-content">
                            <h4>ê³¼ì í•©(Overfitting) ë¬´ì‹œ</h4>
                            <p>ì ì€ ë°ì´í„°ë¡œ ì˜¤ë˜ í•™ìŠµí•˜ë©´ ê³¼ì í•©ì´ ë°œìƒí•©ë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ì—ì„œë§Œ ì˜ ë™ì‘í•˜ê³  ìƒˆë¡œìš´ ì…ë ¥ì—ëŠ” ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. ê²€ì¦ ì…‹ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  early stoppingì„ ì ìš©í•˜ì„¸ìš”.</p>
                        </div>
                    </div>
                    <div class="warning-item">
                        <div class="warning-icon">âŒ</div>
                        <div class="warning-content">
                            <h4>ì¹˜ëª…ì  ë§ê°(Catastrophic Forgetting)</h4>
                            <p>íŠ¹ì • ë„ë©”ì¸ì— ê³¼í•˜ê²Œ íŒŒì¸íŠœë‹í•˜ë©´ ê¸°ì¡´ì— í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ìŠì–´ë²„ë¦½ë‹ˆë‹¤. í•™ìŠµë¥ ì„ ë‚®ê²Œ ìœ ì§€í•˜ê³ , ì¼ë°˜ ë°ì´í„°ë¥¼ ì„ì–´ì„œ í•™ìŠµí•˜ì„¸ìš”.</p>
                        </div>
                    </div>
                    <div class="warning-item">
                        <div class="warning-icon">âœ…</div>
                        <div class="warning-content">
                            <h4>ì˜¬ë°”ë¥¸ ì ‘ê·¼ë²•</h4>
                            <p>ìµœì†Œ 1,000ê°œ ì´ìƒì˜ ê³ í’ˆì§ˆ ì˜ˆì‹œë¡œ ì‹œì‘í•˜ì„¸ìš”. í•™ìŠµë¥ ì€ ê¸°ë³¸ê°’ì˜ 0.1-0.5ë°°ë¡œ ë‚®ì¶”ê³ , ì—í­ì€ 1-3íšŒë¡œ ì œí•œí•˜ì„¸ìš”. LoRA rankëŠ” 8-32ì—ì„œ ì‹œì‘í•˜ê³  ì„±ëŠ¥ì— ë”°ë¼ ì¡°ì •í•˜ì„¸ìš”.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="section-content">
                <div class="related-terms">
                    <a href="/ko/term/Transfer%20Learning/" class="related-term-link">ì „ì´í•™ìŠµ (Transfer Learning)</a>
                    <a href="/ko/term/LLM/" class="related-term-link">LLM (ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)</a>
                    <a href="/ko/term/RAG/" class="related-term-link">RAG</a>
                    <a href="/ko/term/LoRA/" class="related-term-link">LoRA</a>
                    <a href="/ko/term/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95/" class="related-term-link">ê²½ì‚¬í•˜ê°•ë²•</a>
                </div>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="section-content">
                <div class="learn-more">
                    <a href="https://huggingface.co/docs/peft" target="_blank" class="learn-link">
                        ğŸ“„ Hugging Face PEFT - íš¨ìœ¨ì  íŒŒì¸íŠœë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
                    </a>
                    <a href="https://platform.openai.com/docs/guides/fine-tuning" target="_blank" class="learn-link">
                        ğŸ“„ OpenAI Fine-tuning ê°€ì´ë“œ
                    </a>
                    <a href="https://arxiv.org/abs/2106.09685" target="_blank" class="learn-link">
                        ğŸ“ LoRA ë…¼ë¬¸ - Low-Rank Adaptation
                    </a>
                </div>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }
    </script>
<script src="/glossary/js/term-sections.js?v=20260129233538"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>