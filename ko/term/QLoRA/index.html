<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QLoRA (Quantized LoRA) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="ì–‘ìí™”ì™€ LoRAë¥¼ ê²°í•©í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŒŒì¸íŠœë‹ ê¸°ë²•.">
    <meta name="keywords" content="QLoRA, Quantized LoRA, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/QLoRA/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/QLoRA/">
    <meta property="og:title" content="QLoRA (Quantized LoRA) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="ì–‘ìí™”ì™€ LoRAë¥¼ ê²°í•©í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŒŒì¸íŠœë‹ ê¸°ë²•.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="QLoRA (Quantized LoRA) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="ì–‘ìí™”ì™€ LoRAë¥¼ ê²°í•©í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŒŒì¸íŠœë‹ ê¸°ë²•.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "QLoRA",
        "description": "ì–‘ìí™”ì™€ LoRAë¥¼ ê²°í•©í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŒŒì¸íŠœë‹ ê¸°ë²•.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        /* Term Section Styles */
        .term-section {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 2rem;
            margin-bottom: 1.5rem;
        }
        .section-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: #f1f5f9;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .section-content {
            color: #cbd5e1;
            line-height: 1.8;
        }
        .section-content p {
            margin-bottom: 1rem;
        }
        .section-content p:last-child {
            margin-bottom: 0;
        }
        /* Code Block */
        .code-block-wrapper {
            position: relative;
            margin: 1rem 0;
        }
        .code-block {
            background: #1e293b;
            border-radius: 12px;
            padding: 1.5rem;
            overflow-x: auto;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            color: #e2e8f0;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            background: rgba(168, 85, 247, 0.3);
            border: 1px solid rgba(168, 85, 247, 0.5);
            color: #e2e8f0;
            padding: 0.4rem 0.8rem;
            border-radius: 6px;
            font-size: 0.75rem;
            cursor: pointer;
            transition: all 0.2s;
        }
        .copy-btn:hover {
            background: rgba(168, 85, 247, 0.5);
        }
        /* Conversation Examples */
        .conversation-item {
            background: rgba(30, 41, 59, 0.5);
            border-radius: 12px;
            padding: 1.25rem;
            margin-bottom: 1rem;
        }
        .conversation-item:last-child {
            margin-bottom: 0;
        }
        .conversation-context {
            color: #a855f7;
            font-weight: 600;
            margin-bottom: 0.5rem;
            font-size: 0.9rem;
        }
        .conversation-text {
            color: #e2e8f0;
            font-style: italic;
        }
        /* Warning Items */
        .warning-item {
            display: flex;
            gap: 0.75rem;
            padding: 1rem;
            background: rgba(30, 41, 59, 0.5);
            border-radius: 8px;
            margin-bottom: 0.75rem;
        }
        .warning-item:last-child {
            margin-bottom: 0;
        }
        .warning-icon {
            font-size: 1.2rem;
            flex-shrink: 0;
        }
        .warning-content strong {
            color: #f1f5f9;
        }
        /* Related Terms */
        .related-terms-grid {
            display: flex;
            flex-wrap: wrap;
            gap: 0.75rem;
        }
        .related-term-link {
            display: inline-block;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.1);
            border: 1px solid rgba(168, 85, 247, 0.3);
            border-radius: 20px;
            color: #c4b5fd;
            text-decoration: none;
            font-size: 0.9rem;
            transition: all 0.2s;
        }
        .related-term-link:hover {
            background: rgba(168, 85, 247, 0.2);
            border-color: rgba(168, 85, 247, 0.5);
        }
        /* Learn More */
        .learn-more-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }
        .learn-more-list li {
            margin-bottom: 0.75rem;
        }
        .learn-more-list a {
            color: #67e8f9;
            text-decoration: none;
        }
        .learn-more-list a:hover {
            text-decoration: underline;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }
    </style>
</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
    <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">QLoRA</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">QLoRA</h1>
            <p class="term-english">Quantized LoRA</p>
            <div class="term-description">
                <p>ì–‘ìí™”ì™€ LoRAë¥¼ ê²°í•©í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŒŒì¸íŠœë‹ ê¸°ë²•.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p>QLoRA(Quantized Low-Rank Adaptation)ëŠ” 2023ë…„ ì›Œì‹±í„´ ëŒ€í•™êµ Tim Dettmers íŒ€ì´ ë°œí‘œí•œ í˜ì‹ ì ì¸ íŒŒì¸íŠœë‹ ê¸°ë²•ì…ë‹ˆë‹¤. 65B íŒŒë¼ë¯¸í„°ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ë‹¨ì¼ 48GB GPUì—ì„œ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆê²Œ í•´ì£¼ì–´, ê¸°ì¡´ì— ìˆ˜ë°± GBì˜ ë©”ëª¨ë¦¬ê°€ í•„ìš”í–ˆë˜ LLM ë§ì¶¤í™”ë¥¼ ì¼ë°˜ ê°œë°œìë„ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ê¸°ë³¸ ëª¨ë¸ì„ 4-bitë¡œ ì–‘ìí™”í•˜ê³ , í•™ìŠµ ê°€ëŠ¥í•œ LoRA ì–´ëŒ‘í„°ë§Œ 16-bitë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>

                <p>QLoRAì˜ ì„¸ ê°€ì§€ í•µì‹¬ í˜ì‹ ì´ ìˆìŠµë‹ˆë‹¤. ì²«ì§¸, NF4(NormalFloat 4-bit) ì–‘ìí™”ì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ INT4ì™€ ë‹¬ë¦¬ ì •ê·œë¶„í¬ì— ìµœì í™”ëœ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ, ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ì˜ ë¶„í¬ íŠ¹ì„±ì— ë§ì¶° ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ë‘˜ì§¸, Double Quantizationìœ¼ë¡œ ì–‘ìí™” ìƒìˆ˜(scale factor) ìì²´ë„ ì–‘ìí™”í•˜ì—¬ ì¶”ê°€ë¡œ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í•©ë‹ˆë‹¤. ì…‹ì§¸, Paged Optimizersë¡œ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ CPU RAMìœ¼ë¡œ ìë™ ìŠ¤ì™‘í•˜ì—¬ OOM(Out of Memory) ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.</p>

                <p>QLoRAì˜ ì„±ëŠ¥ì€ ë†€ëìŠµë‹ˆë‹¤. ì› ë…¼ë¬¸ì—ì„œ Guanaco-65B ëª¨ë¸ì€ ë‹¨ 24ì‹œê°„ì˜ íŒŒì¸íŠœë‹ìœ¼ë¡œ ChatGPT ëŒ€ë¹„ 99.3% ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ Full Fine-tuning ëŒ€ë¹„ ì•½ 75% ê°ì†Œí•˜ë©´ì„œë„, í’ˆì§ˆ ì €í•˜ëŠ” ë¯¸ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ê¸°ë³¸ ëª¨ë¸ì˜ ì§€ì‹ì„ ì–‘ìí™”ëœ í˜•íƒœë¡œ ë³´ì¡´í•˜ë©´ì„œ, íƒœìŠ¤í¬ íŠ¹í™” ì§€ì‹ì€ LoRA ì–´ëŒ‘í„°ê°€ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¶”ë¡  ì‹œì—ë„ ì–‘ìí™”ëœ ë² ì´ìŠ¤ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì•½ê°„ì˜ ì„±ëŠ¥ ì €í•˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

                <p>ì‹¤ë¬´ì—ì„œ QLoRAëŠ” Hugging Faceì˜ PEFT, bitsandbytes ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Llama, Mistral, Qwen ë“± ì£¼ìš” ì˜¤í”ˆì†ŒìŠ¤ LLM ëŒ€ë¶€ë¶„ì´ QLoRA íŒŒì¸íŠœë‹ì„ ì§€ì›í•©ë‹ˆë‹¤. íŠ¹íˆ ë„ë©”ì¸ íŠ¹í™” ì±—ë´‡, ì»¤ìŠ¤í…€ ì–´ì‹œìŠ¤í„´íŠ¸ ê°œë°œì— ë„ë¦¬ í™œìš©ë˜ë©°, ê°œì¸ PC(RTX 3090/4090)ì—ì„œ 7B~13B ëª¨ë¸ì„, A100 80GBì—ì„œ 70Bê¸‰ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Axolotl, LLaMA-Factory ê°™ì€ íŒŒì¸íŠœë‹ í”„ë ˆì„ì›Œí¬ì—ì„œ ê¸°ë³¸ ì§€ì›ë©ë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="section-content">
                <p>Hugging Face PEFTì™€ bitsandbytesë¥¼ ì‚¬ìš©í•œ QLoRA íŒŒì¸íŠœë‹ ì˜ˆì œì…ë‹ˆë‹¤:</p>
                <div class="code-block-wrapper">
                    <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                    <pre class="code-block"><code>import torch
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    TrainingArguments
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from trl import SFTTrainer
from datasets import load_dataset

# 1. 4-bit ì–‘ìí™” ì„¤ì • (QLoRA í•µì‹¬)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,                    # 4-bit ì–‘ìí™” í™œì„±í™”
    bnb_4bit_quant_type="nf4",            # NormalFloat4 (QLoRA ê¶Œì¥)
    bnb_4bit_compute_dtype=torch.bfloat16, # ì—°ì‚°ì€ bfloat16ìœ¼ë¡œ
    bnb_4bit_use_double_quant=True        # Double Quantization
)

# 2. ì–‘ìí™”ëœ ëª¨ë¸ ë¡œë“œ
model_name = "mistralai/Mistral-7B-v0.1"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

# 3. LoRA ì„¤ì •
lora_config = LoraConfig(
    r=64,                          # LoRA rank (ë†’ì„ìˆ˜ë¡ í‘œí˜„ë ¥ ì¦ê°€)
    lora_alpha=16,                 # ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜
    target_modules=[               # ì–´ëŒ‘í„° ì ìš© ë ˆì´ì–´
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"
    ],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# 4. ëª¨ë¸ì— LoRA ì ìš©
model = prepare_model_for_kbit_training(model)
model = get_peft_model(model, lora_config)

# í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸
model.print_trainable_parameters()
# ì¶œë ¥: trainable params: 83,886,080 || all params: 7,242,M || 1.16%

# 5. ë°ì´í„°ì…‹ ì¤€ë¹„ (ì˜ˆ: Alpaca í˜•ì‹)
dataset = load_dataset("tatsu-lab/alpaca", split="train[:1000]")

def format_prompt(example):
    return f"""### Instruction:
{example['instruction']}

### Input:
{example['input']}

### Response:
{example['output']}"""

# 6. í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./qlora-output",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    optim="paged_adamw_8bit"        # Paged Optimizer (OOM ë°©ì§€)
)

# 7. SFTTrainerë¡œ í•™ìŠµ
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    formatting_func=format_prompt,
    max_seq_length=512,
    tokenizer=tokenizer,
    args=training_args
)

trainer.train()

# 8. LoRA ì–´ëŒ‘í„° ì €ì¥ (ìš©ëŸ‰ ë§¤ìš° ì‘ìŒ: ~100-500MB)
model.save_pretrained("./qlora-adapter")

# 9. ì¶”ë¡ : ì–´ëŒ‘í„° ë¡œë“œí•˜ì—¬ ì‚¬ìš©
from peft import PeftModel
base_model = AutoModelForCausalLM.from_pretrained(
    model_name, quantization_config=bnb_config, device_map="auto"
)
model = PeftModel.from_pretrained(base_model, "./qlora-adapter")</code></pre>
                </div>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”</h2>
            <div class="section-content">
                <div class="conversation-item">
                    <div class="conversation-context">ğŸ’¼ íšŒì˜ì—ì„œ</div>
                    <p class="conversation-text">"ì €í¬ ì˜ˆì‚°ìœ¼ë¡œ A100 ì—¬ëŸ¬ ì¥ì€ ë¬´ë¦¬ê³ , ë‹¨ì¼ RTX 4090ìœ¼ë¡œ Mistral 7B QLoRA íŒŒì¸íŠœë‹í•˜ë©´ ë„ë©”ì¸ íŠ¹í™” ì±—ë´‡ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•™ìŠµ ì‹œê°„ì€ ì•½ 6-8ì‹œê°„ ì˜ˆìƒë©ë‹ˆë‹¤."</p>
                </div>
                <div class="conversation-item">
                    <div class="conversation-context">ğŸ‘” ë©´ì ‘ì—ì„œ</div>
                    <p class="conversation-text">"QLoRAì˜ í•µì‹¬ì€ NF4 ì–‘ìí™”ì…ë‹ˆë‹¤. ì¼ë°˜ INT4ì™€ ë‹¬ë¦¬ ì •ê·œë¶„í¬ì— ìµœì í™”ë˜ì–´ ìˆì–´ì„œ, ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ì˜ ë¶„í¬ íŠ¹ì„±ì— ë§ì¶° ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ëŠ” 75% ì ˆê°í•˜ë©´ì„œ ì„±ëŠ¥ ì €í•˜ëŠ” 1-2% ìˆ˜ì¤€ì…ë‹ˆë‹¤."</p>
                </div>
                <div class="conversation-item">
                    <div class="conversation-context">ğŸ”§ ê¸°ìˆ  í† ë¡ ì—ì„œ</div>
                    <p class="conversation-text">"QLoRAë¡œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ ë°°í¬í•  ë•Œ ì„ íƒì§€ê°€ ë‘ ê°€ì§€ì˜ˆìš”. ì–‘ìí™”ëœ ë² ì´ìŠ¤ + LoRA ì–´ëŒ‘í„° ê·¸ëŒ€ë¡œ ì„œë¹™í•˜ê±°ë‚˜, ì–´ëŒ‘í„°ë¥¼ mergeí•´ì„œ ì „ì²´ ê°€ì¤‘ì¹˜ ëª¨ë¸ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í›„ìê°€ ì¶”ë¡  ì†ë„ëŠ” ë” ë¹ ë¥´ê³ ìš”."</p>
                </div>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­</h2>
            <div class="section-content">
                <div class="warning-item">
                    <span class="warning-icon">âŒ</span>
                    <div class="warning-content">
                        <strong>ë„ˆë¬´ ë‚®ì€ rank ì„¤ì •:</strong> r=8 ê°™ì€ ë‚®ì€ rankëŠ” ê°„ë‹¨í•œ íƒœìŠ¤í¬ì—ëŠ” ì¶©ë¶„í•˜ì§€ë§Œ, ë³µì¡í•œ ë„ë©”ì¸ ì§€ì‹ í•™ìŠµì—ëŠ” r=32~64 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. rankê°€ ë‚®ìœ¼ë©´ í•™ìŠµ ìš©ëŸ‰ì´ ë¶€ì¡±í•´ underfittingë©ë‹ˆë‹¤.
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">âŒ</span>
                    <div class="warning-content">
                        <strong>bitsandbytes ë²„ì „ ë¯¸ìŠ¤ë§¤ì¹˜:</strong> CUDA ë²„ì „ê³¼ bitsandbytes ë²„ì „ì´ ë§ì§€ ì•Šìœ¼ë©´ 4-bit ì–‘ìí™”ê°€ ì‹¤íŒ¨í•©ë‹ˆë‹¤. CUDA 11.8 ì´ìƒê³¼ ìµœì‹  bitsandbytes(0.41+)ë¥¼ ì‚¬ìš©í•˜ê³ , pip install bitsandbytes --upgradeë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">âœ…</span>
                    <div class="warning-content">
                        <strong>Best Practice:</strong> target_modulesì— attention ë ˆì´ì–´(q_proj, k_proj, v_proj, o_proj)ë¿ ì•„ë‹ˆë¼ MLP ë ˆì´ì–´(gate_proj, up_proj, down_proj)ë„ í¬í•¨í•˜ë©´ ì„±ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤. gradient_checkpointing=Trueë¡œ ì¶”ê°€ ë©”ëª¨ë¦¬ ì ˆê°ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                    </div>
                </div>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="section-content">
                <div class="related-terms-grid">
                    <a href="/ko/term/LoRA/" class="related-term-link">LoRA</a>
                    <a href="/ko/term/Quantization/" class="related-term-link">Quantization</a>
                    <a href="/ko/term/Fine-tuning/" class="related-term-link">Fine-tuning</a>
                    <a href="/ko/term/LLM/" class="related-term-link">LLM</a>
                    <a href="/ko/term/Hugging%20Face/" class="related-term-link">Hugging Face</a>
                    <a href="/ko/term/Prefix%20Tuning/" class="related-term-link">Prefix Tuning</a>
                </div>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="section-content">
                <ul class="learn-more-list">
                    <li>ğŸ“„ ì› ë…¼ë¬¸: <a href="https://arxiv.org/abs/2305.14314" target="_blank" rel="noopener">QLoRA: Efficient Finetuning of Quantized LLMs</a></li>
                    <li>ğŸ“˜ PEFT ê³µì‹ ë¬¸ì„œ: <a href="https://huggingface.co/docs/peft" target="_blank" rel="noopener">Hugging Face PEFT Documentation</a></li>
                    <li>ğŸ› ï¸ bitsandbytes: <a href="https://github.com/TimDettmers/bitsandbytes" target="_blank" rel="noopener">GitHub Repository</a></li>
                    <li>ğŸ“– ì‹¤ì „ ê°€ì´ë“œ: <a href="https://huggingface.co/blog/4bit-transformers-bitsandbytes" target="_blank" rel="noopener">Making LLMs even more accessible with bitsandbytes</a></li>
                    <li>ğŸ“ Axolotl í”„ë ˆì„ì›Œí¬: <a href="https://github.com/OpenAccess-AI-Collective/axolotl" target="_blank" rel="noopener">ê°„í¸í•œ QLoRA íŒŒì¸íŠœë‹ ë„êµ¬</a></li>
                </ul>
            </div>
        </section>
    </main>

    <!-- Footer -->
    <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script>
    function copyCode(button) {
        const codeBlock = button.nextElementSibling.querySelector('code');
        const text = codeBlock.textContent;
        navigator.clipboard.writeText(text).then(() => {
            button.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => { button.textContent = 'ğŸ“‹ ë³µì‚¬'; }, 2000);
        });
    }
    </script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
</body>
</html>
