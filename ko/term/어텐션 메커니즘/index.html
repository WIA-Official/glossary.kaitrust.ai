<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ (Attention Mechanism) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="ì…ë ¥ì˜ ê° ë¶€ë¶„ì— ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜. Transformerì˜ í•µì‹¬.">
    <meta name="keywords" content="ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜, Attention Mechanism, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/%EC%96%B4%ED%85%90%EC%85%98%20%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/%EC%96%B4%ED%85%90%EC%85%98%20%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98/">
    <meta property="og:title" content="ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ (Attention Mechanism) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="ì…ë ¥ì˜ ê° ë¶€ë¶„ì— ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜. Transformerì˜ í•µì‹¬.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ (Attention Mechanism) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="ì…ë ¥ì˜ ê° ë¶€ë¶„ì— ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜. Transformerì˜ í•µì‹¬.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜",
        "description": "ì…ë ¥ì˜ ê° ë¶€ë¶„ì— ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜. Transformerì˜ í•µì‹¬.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }
        .term-section { background: rgba(15, 23, 42, 0.6); border: 1px solid rgba(168, 85, 247, 0.1); border-radius: 16px; padding: 2rem; margin-bottom: 1.5rem; }
        .section-title { font-size: 1.3rem; font-weight: 600; margin-bottom: 1.5rem; color: #f1f5f9; }
        .section-content { color: #cbd5e1; line-height: 1.8; }
        .code-block { position: relative; background: #1e293b; border-radius: 12px; padding: 1.5rem; margin: 1rem 0; overflow-x: auto; }
        .code-block pre { margin: 0; color: #e2e8f0; font-family: 'JetBrains Mono', monospace; font-size: 0.9rem; line-height: 1.6; }
        .copy-btn { position: absolute; top: 0.75rem; right: 0.75rem; padding: 0.5rem 1rem; background: rgba(168, 85, 247, 0.3); border: 1px solid rgba(168, 85, 247, 0.5); border-radius: 6px; color: #e2e8f0; font-size: 0.8rem; cursor: pointer; transition: all 0.2s; }
        .copy-btn:hover { background: rgba(168, 85, 247, 0.5); }
        .spec-table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
        .spec-table th, .spec-table td { padding: 0.75rem; text-align: left; border-bottom: 1px solid rgba(168, 85, 247, 0.2); }
        .spec-table th { background: rgba(168, 85, 247, 0.1); color: #a855f7; font-weight: 600; }
        .spec-table tr:hover { background: rgba(168, 85, 247, 0.05); }
        .conversation-examples { display: flex; flex-direction: column; gap: 1.5rem; }
        .conv-item { background: rgba(0, 0, 0, 0.2); border-radius: 12px; padding: 1.25rem; }
        .conv-context { font-size: 0.9rem; color: #a855f7; font-weight: 500; margin-bottom: 0.75rem; }
        .conv-quote { color: #e2e8f0; font-style: italic; line-height: 1.7; margin: 0; padding-left: 1rem; border-left: 3px solid #a855f7; }
        .warning-list { display: flex; flex-direction: column; gap: 1rem; }
        .warning-item { display: flex; gap: 1rem; padding: 1rem; background: rgba(0, 0, 0, 0.2); border-radius: 10px; }
        .warning-icon { font-size: 1.5rem; }
        .warning-item strong { color: #f1f5f9; display: block; margin-bottom: 0.25rem; }
        .warning-item p { color: #94a3b8; margin: 0; font-size: 0.95rem; }
        .related-terms { display: flex; flex-wrap: wrap; gap: 0.75rem; }
        .related-term-link { padding: 0.5rem 1rem; background: rgba(168, 85, 247, 0.1); border: 1px solid rgba(168, 85, 247, 0.3); border-radius: 20px; color: #a855f7; text-decoration: none; font-size: 0.9rem; transition: all 0.2s; }
        .related-term-link:hover { background: rgba(168, 85, 247, 0.2); transform: translateY(-2px); }
        .learn-more { display: flex; flex-direction: column; gap: 0.75rem; }
        .learn-link { display: flex; align-items: center; gap: 0.75rem; padding: 1rem; background: rgba(0, 0, 0, 0.2); border-radius: 10px; color: #00f5ff; text-decoration: none; transition: all 0.2s; }
        .learn-link:hover { background: rgba(0, 0, 0, 0.3); transform: translateX(5px); }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css?v=20260129233538">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜</h1>
            <p class="term-english">Attention Mechanism</p>
            <div class="term-description">
                <p>ì…ë ¥ì˜ ê° ë¶€ë¶„ì— ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜. Transformerì˜ í•µì‹¬.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p>ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜(Attention Mechanism)ì€ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê° ë¶€ë¶„ì— ì„œë¡œ ë‹¤ë¥¸ ì¤‘ìš”ë„(ê°€ì¤‘ì¹˜)ë¥¼ ë¶€ì—¬í•˜ì—¬, ëª¨ë¸ì´ ê´€ë ¨ì„± ë†’ì€ ì •ë³´ì— "ì£¼ëª©(attention)"í•˜ë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì‚¬ëŒì´ ê¸´ ë¬¸ì¥ì„ ì½ì„ ë•Œ ëª¨ë“  ë‹¨ì–´ì— ë™ì¼í•œ ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ì§€ ì•Šê³  í•µì‹¬ ë‹¨ì–´ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì²˜ëŸ¼, AIë„ ì¤‘ìš”í•œ ë¶€ë¶„ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.</p>

                <p>2017ë…„ êµ¬ê¸€ì˜ "Attention Is All You Need" ë…¼ë¬¸ì—ì„œ ì†Œê°œëœ Self-Attentionì€ Transformer ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ìœ¼ë¡œ, ì‹œí€€ìŠ¤ ë‚´ ëª¨ë“  ìœ„ì¹˜ ê°„ì˜ ê´€ê³„ë¥¼ ë³‘ë ¬ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤. ê° í† í°ì€ Query(Q), Key(K), Value(V) ë²¡í„°ë¡œ ë³€í™˜ë˜ë©°, Qì™€ Kì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ ì–´í…ì…˜ ì ìˆ˜ë¥¼ êµ¬í•˜ê³ , ì´ë¥¼ Vì— ì ìš©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜ì˜í•œ ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.</p>

                <p>Multi-Head Attentionì€ ì—¬ëŸ¬ ê°œì˜ ì–´í…ì…˜ ì—°ì‚°ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ê´€ê³„ë¥¼ í¬ì°©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í•œ í—¤ë“œëŠ” ë¬¸ë²•ì  ê´€ê³„ë¥¼, ë‹¤ë¥¸ í—¤ë“œëŠ” ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. GPT-4ëŠ” ìˆ˜ì‹­ ê°œì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ì–¸ì–´ íŒ¨í„´ì„ ì´í•´í•©ë‹ˆë‹¤.</p>

                <p>ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ë“±ì¥ìœ¼ë¡œ RNN/LSTMì˜ ìˆœì°¨ ì²˜ë¦¬ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ê¸´ ì‹œí€€ìŠ¤ì—ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ ì¥ê±°ë¦¬ ì˜ì¡´ì„±ì„ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ GPT, BERT, Claude ë“± ê±°ì˜ ëª¨ë“  ìµœì‹  ì–¸ì–´ ëª¨ë¸ê³¼ Vision Transformer(ViT) ê°™ì€ ë¹„ì „ ëª¨ë¸ì—ì„œë„ í•µì‹¬ êµ¬ì„±ìš”ì†Œë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="section-content">
                <p>PyTorchë¡œ êµ¬í˜„í•œ Scaled Dot-Product Attentionê³¼ Multi-Head Attention ì˜ˆì œì…ë‹ˆë‹¤.</p>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                    <pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
import math

# Scaled Dot-Product Attention
def scaled_dot_product_attention(Q, K, V, mask=None):
    """
    Q, K, V: (batch, seq_len, d_k)
    """
    d_k = Q.size(-1)
    # Attention Score: Qì™€ Kì˜ ë‚´ì  í›„ ìŠ¤ì¼€ì¼ë§
    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)

    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)

    # Softmaxë¡œ ê°€ì¤‘ì¹˜ ì •ê·œí™”
    attention_weights = F.softmax(scores, dim=-1)

    # Vì— ê°€ì¤‘ì¹˜ ì ìš©
    output = torch.matmul(attention_weights, V)
    return output, attention_weights

# Multi-Head Attention í´ë˜ìŠ¤
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model=512, num_heads=8):
        super().__init__()
        self.num_heads = num_heads
        self.d_k = d_model // num_heads

        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)

    def forward(self, Q, K, V, mask=None):
        batch_size = Q.size(0)

        # Linear projection + reshape to heads
        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)

        # Attention ì ìš©
        x, attn = scaled_dot_product_attention(Q, K, V, mask)

        # Concat heads + final linear
        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)
        return self.W_o(x)

# ì‚¬ìš© ì˜ˆì‹œ
mha = MultiHeadAttention(d_model=512, num_heads=8)
x = torch.randn(2, 10, 512)  # (batch=2, seq_len=10, d_model=512)
output = mha(x, x, x)  # Self-Attention
print(f"Output shape: {output.shape}")  # (2, 10, 512)</code></pre>
                </div>
            </div>
        </section>

        <!-- ì„±ëŠ¥ & ë¹„ìš© -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“Š ì–´í…ì…˜ ë³€í˜•ë³„ ë¹„êµ</h2>
            <div class="section-content">
                <table class="spec-table">
                    <thead>
                        <tr>
                            <th>ì–´í…ì…˜ ìœ í˜•</th>
                            <th>ì‹œê°„ ë³µì¡ë„</th>
                            <th>íŠ¹ì§•</th>
                            <th>ì ìš© ëª¨ë¸</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Full Attention</td>
                            <td>O(nÂ²)</td>
                            <td>ëª¨ë“  í† í° ê°„ ê´€ê³„ ê³„ì‚°</td>
                            <td>BERT, GPT-3</td>
                        </tr>
                        <tr>
                            <td>Sparse Attention</td>
                            <td>O(nâˆšn)</td>
                            <td>ì¼ë¶€ íŒ¨í„´ë§Œ ê³„ì‚°</td>
                            <td>GPT-3 (ì¼ë¶€)</td>
                        </tr>
                        <tr>
                            <td>Flash Attention</td>
                            <td>O(nÂ²) ë©”ëª¨ë¦¬ íš¨ìœ¨</td>
                            <td>IO ìµœì í™”, ë©”ëª¨ë¦¬ ì ˆê°</td>
                            <td>LLaMA, Mistral</td>
                        </tr>
                        <tr>
                            <td>Linear Attention</td>
                            <td>O(n)</td>
                            <td>ì»¤ë„ ê·¼ì‚¬ ì‚¬ìš©</td>
                            <td>Performer</td>
                        </tr>
                        <tr>
                            <td>Multi-Query Attention</td>
                            <td>O(nÂ²) KV ì ˆê°</td>
                            <td>K,V í—¤ë“œ ê³µìœ </td>
                            <td>PaLM, Falcon</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ì˜ˆì‹œ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”</h2>
            <div class="conversation-examples">
                <div class="conv-item">
                    <div class="conv-context">ëª¨ë¸ ì•„í‚¤í…ì²˜ ë…¼ì˜ ì‹œ</div>
                    <p class="conv-quote">"128K í† í°ì„ ì²˜ë¦¬í•˜ë ¤ë©´ ì¼ë°˜ ì–´í…ì…˜ìœ¼ë¡  ë©”ëª¨ë¦¬ê°€ í„°ì§‘ë‹ˆë‹¤. Flash Attention 2ë‚˜ Sliding Window Attentionì„ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤."</p>
                </div>
                <div class="conv-item">
                    <div class="conv-context">ë””ë²„ê¹…/ë¶„ì„ ì‹œ</div>
                    <p class="conv-quote">"ì–´í…ì…˜ ë§µì„ ì‹œê°í™”í•´ë³´ë‹ˆ ëª¨ë¸ì´ 'not'ì´ë¼ëŠ” ë¶€ì •ì–´ë¥¼ ë¬´ì‹œí•˜ê³  ìˆë„¤ìš”. í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•´ë´…ì‹œë‹¤."</p>
                </div>
                <div class="conv-item">
                    <div class="conv-context">ì„±ëŠ¥ ìµœì í™” íšŒì˜ì—ì„œ</div>
                    <p class="conv-quote">"ì¶”ë¡  ì†ë„ê°€ ëŠë¦° ì´ìœ ê°€ ì–´í…ì…˜ ì—°ì‚° ë•Œë¬¸ì…ë‹ˆë‹¤. KV ìºì‹œë¥¼ ì ìš©í•˜ê³  Multi-Query Attentionìœ¼ë¡œ ì „í™˜í•˜ë©´ 30% ë¹¨ë¼ì§‘ë‹ˆë‹¤."</p>
                </div>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­</h2>
            <div class="warning-list">
                <div class="warning-item">
                    <span class="warning-icon">ğŸ’¾</span>
                    <div>
                        <strong>ë©”ëª¨ë¦¬ í­ë°œ (OOM)</strong>
                        <p>ì–´í…ì…˜ì€ O(nÂ²) ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸´ ì‹œí€€ìŠ¤ì—ì„œëŠ” Flash Attentionì´ë‚˜ gradient checkpointingì„ ì ìš©í•˜ì„¸ìš”.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">ğŸ”¢</span>
                    <div>
                        <strong>ìŠ¤ì¼€ì¼ë§ ëˆ„ë½</strong>
                        <p>âˆšd_kë¡œ ë‚˜ëˆ„ì§€ ì•Šìœ¼ë©´ ì†Œí”„íŠ¸ë§¥ìŠ¤ê°€ ê·¹ë‹¨ê°’ìœ¼ë¡œ ìˆ˜ë ´í•©ë‹ˆë‹¤. í•­ìƒ Scaled Dot-Productë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">ğŸ­</span>
                    <div>
                        <strong>ë§ˆìŠ¤í‚¹ ì‹¤ìˆ˜</strong>
                        <p>Decoderì—ì„œ ë¯¸ë˜ í† í°ì„ ë³´ë©´ í•™ìŠµì´ ë§ê°€ì§‘ë‹ˆë‹¤. Causal maskë¥¼ ë°˜ë“œì‹œ ì ìš©í•˜ì„¸ìš”.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">ğŸ“Š</span>
                    <div>
                        <strong>í—¤ë“œ ìˆ˜ ê³¼ë‹¤</strong>
                        <p>í—¤ë“œê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ê° í—¤ë“œì˜ ì°¨ì›(d_k)ì´ ì¤„ì–´ í‘œí˜„ë ¥ì´ ê°ì†Œí•©ë‹ˆë‹¤. d_model/num_headsê°€ ìµœì†Œ 64 ì´ìƒ ìœ ì§€í•˜ì„¸ìš”.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="related-terms">
                <a href="/ko/term/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8/" class="related-term-link">íŠ¸ëœìŠ¤í¬ë¨¸</a>
                <a href="/ko/term/%EB%A9%80%ED%8B%B0%ED%97%A4%EB%93%9C%20%EC%96%B4%ED%85%90%EC%85%98/" class="related-term-link">ë©€í‹°í—¤ë“œ ì–´í…ì…˜</a>
                <a href="/ko/term/%EC%9E%84%EB%B2%A0%EB%94%A9/" class="related-term-link">ì„ë² ë”©</a>
                <a href="/ko/term/%ED%86%A0%ED%81%B0/" class="related-term-link">í† í°</a>
                <a href="/ko/term/%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%9C%88%EB%8F%84%EC%9A%B0/" class="related-term-link">ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°</a>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="learn-more">
                <a href="https://arxiv.org/abs/1706.03762" target="_blank" class="learn-link">
                    ğŸ“„ Attention Is All You Need - Transformer ì›ë³¸ ë…¼ë¬¸
                </a>
                <a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" class="learn-link">
                    ğŸ¨ The Illustrated Transformer - ì‹œê°ì  ì„¤ëª… (Jay Alammar)
                </a>
                <a href="https://arxiv.org/abs/2205.14135" target="_blank" class="learn-link">
                    âš¡ FlashAttention ë…¼ë¬¸ - íš¨ìœ¨ì ì¸ ì–´í…ì…˜ êµ¬í˜„
                </a>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }
    </script>
<script src="/glossary/js/term-sections.js?v=20260129233538"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>