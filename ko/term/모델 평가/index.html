<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ëª¨ë¸ í‰ê°€ (Model Evaluation) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="AI ëª¨ë¸ì˜ ì„±ëŠ¥, ì•ˆì „ì„±, í¸í–¥ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” í”„ë¡œì„¸ìŠ¤.">
    <meta name="keywords" content="ëª¨ë¸ í‰ê°€, Model Evaluation, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI ê·œì œ/ìœ¤ë¦¬">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/%EB%AA%A8%EB%8D%B8%20%ED%8F%89%EA%B0%80/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/%EB%AA%A8%EB%8D%B8%20%ED%8F%89%EA%B0%80/">
    <meta property="og:title" content="ëª¨ë¸ í‰ê°€ (Model Evaluation) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="AI ëª¨ë¸ì˜ ì„±ëŠ¥, ì•ˆì „ì„±, í¸í–¥ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” í”„ë¡œì„¸ìŠ¤.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="ëª¨ë¸ í‰ê°€ (Model Evaluation) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="AI ëª¨ë¸ì˜ ì„±ëŠ¥, ì•ˆì „ì„±, í¸í–¥ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” í”„ë¡œì„¸ìŠ¤.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "ëª¨ë¸ í‰ê°€",
        "description": "AI ëª¨ë¸ì˜ ì„±ëŠ¥, ì•ˆì „ì„±, í¸í–¥ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” í”„ë¡œì„¸ìŠ¤.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">
    <link rel="stylesheet" href="/glossary/css/term-sections.css?v=20260129233538">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }
    </style>
</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#regulation">AI ê·œì œ/ìœ¤ë¦¬</a>
            <span>â€º</span>
            <span class="current">ëª¨ë¸ í‰ê°€</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>âš–ï¸</span>
                <span>AI ê·œì œ/ìœ¤ë¦¬</span>
            </div>
            <h1 class="term-title">ëª¨ë¸ í‰ê°€</h1>
            <p class="term-english">Model Evaluation</p>
            <div class="term-description">
                <p>AI ëª¨ë¸ì˜ ì„±ëŠ¥, ì•ˆì „ì„±, í¸í–¥ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” í”„ë¡œì„¸ìŠ¤.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#regulation" class="term-action-btn btn-secondary">
                    âš–ï¸ AI ê·œì œ/ìœ¤ë¦¬ ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… ì„¹ì…˜ -->
        <section class="term-section" aria-labelledby="detail-title">
            <h2 id="detail-title" class="section-title">ìƒì„¸ ì„¤ëª…</h2>
            <div class="detail-content">
                <p>ëª¨ë¸ í‰ê°€(Model Evaluation)ëŠ” AI ëª¨ë¸ì˜ ì„±ëŠ¥, ì•ˆì „ì„±, í¸í–¥, ê²¬ê³ ì„± ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ê²€ì¦í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤. EU AI Act ì œ9ì¡°ì—ì„œ ê³ ìœ„í—˜ AI ì‹œìŠ¤í…œì— ëŒ€í•´ ìœ„í—˜ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì¼ë¶€ë¡œ í…ŒìŠ¤íŠ¸ ë° í‰ê°€ë¥¼ ìš”êµ¬í•˜ë©°, ì œ15ì¡°ì—ì„œëŠ” ì •í™•ì„±, ê²¬ê³ ì„±, ì‚¬ì´ë²„ë³´ì•ˆ ìš”ê±´ì„ ëª…ì‹œí•©ë‹ˆë‹¤.</p>
                <p>ì „í†µì ì¸ ML ëª¨ë¸ í‰ê°€ëŠ” ì •í™•ë„(Accuracy), ì •ë°€ë„(Precision), ì¬í˜„ìœ¨(Recall), F1 ì ìˆ˜ ë“± ì„±ëŠ¥ ì§€í‘œì— ì§‘ì¤‘í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ AI ê·œì œ ì‹œëŒ€ì—ëŠ” ê³µì •ì„±(Fairness) ì§€í‘œ, ì„¤ëª… ê°€ëŠ¥ì„±(Explainability), ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ê²¬ê³ ì„±(Robustness)ì´ í•„ìˆ˜ì ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤.</p>
                <p>EU AI Act ì¤€ìˆ˜ë¥¼ ìœ„í•œ í‰ê°€ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤: ê¸°ìˆ ì  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸, ë³´í˜¸ ê·¸ë£¹ë³„ ê³µì •ì„± ë¶„ì„, ë ˆë“œíŒ€ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ì•ˆì „ì„± ê²€ì¦, ë‹¤ì–‘í•œ ì¡°ê±´ì—ì„œì˜ ê²¬ê³ ì„± í…ŒìŠ¤íŠ¸, í•´ì„ ê°€ëŠ¥ì„± ê²€ì¦. ì´ ê²°ê³¼ëŠ” ê¸°ìˆ  ë¬¸ì„œì— í¬í•¨ë˜ì–´ ì í•©ì„± í‰ê°€ì˜ ê·¼ê±°ê°€ ë©ë‹ˆë‹¤.</p>
                <p>ìƒì„±í˜• AIì˜ ê²½ìš° í‰ê°€ê°€ ë” ë³µì¡í•©ë‹ˆë‹¤. ì¶œë ¥ì˜ í’ˆì§ˆì„ ì •ëŸ‰í™”í•˜ê¸° ì–´ë µê³ , ìœ í•´ ì½˜í…ì¸  ìƒì„± ê°€ëŠ¥ì„±, í—ˆìœ„ ì •ë³´(Hallucination) ë¹ˆë„, ì €ì‘ê¶Œ ì¹¨í•´ ìœ„í—˜ ë“± ìƒˆë¡œìš´ í‰ê°€ ì°¨ì›ì´ í•„ìš”í•©ë‹ˆë‹¤. HELM, MMLU, TruthfulQA ë“±ì˜ ë²¤ì¹˜ë§ˆí¬ê°€ í™œìš©ë©ë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ ì„¹ì…˜ -->
        <section class="term-section" aria-labelledby="code-title">
            <h2 id="code-title" class="section-title">ì½”ë“œ ì˜ˆì œ</h2>
            <div class="code-block" data-lang="python">
                <button class="copy-btn">ë³µì‚¬</button>
                <pre><code># EU AI Act ì¤€ìˆ˜ë¥¼ ìœ„í•œ ì¢…í•© ëª¨ë¸ í‰ê°€ í”„ë ˆì„ì›Œí¬
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Callable
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import numpy as np

@dataclass
class EvaluationResult:
    """í‰ê°€ ê²°ê³¼"""
    metric_name: str
    value: float
    threshold: float
    passed: bool
    details: Dict = field(default_factory=dict)

class AIActModelEvaluator:
    """EU AI Act ì¤€ìˆ˜ë¥¼ ìœ„í•œ ëª¨ë¸ í‰ê°€ í”„ë ˆì„ì›Œí¬"""

    def __init__(self, model_name: str, model_version: str):
        self.model_name = model_name
        self.model_version = model_version
        self.results: List[EvaluationResult] = []

    def evaluate_performance(self, y_true: np.ndarray, y_pred: np.ndarray,
                              accuracy_threshold: float = 0.85) -> EvaluationResult:
        """ì œ15ì¡°: ì •í™•ì„± í‰ê°€"""
        accuracy = accuracy_score(y_true, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_true, y_pred, average='weighted'
        )

        result = EvaluationResult(
            metric_name="performance",
            value=accuracy,
            threshold=accuracy_threshold,
            passed=accuracy >= accuracy_threshold,
            details={
                "accuracy": round(accuracy, 4),
                "precision": round(precision, 4),
                "recall": round(recall, 4),
                "f1_score": round(f1, 4)
            }
        )
        self.results.append(result)
        return result

    def evaluate_fairness(self, y_true: np.ndarray, y_pred: np.ndarray,
                          protected_attribute: np.ndarray,
                          disparity_threshold: float = 0.2) -> EvaluationResult:
        """ê³µì •ì„± í‰ê°€ (ë³´í˜¸ ê·¸ë£¹ ê°„ ì„±ëŠ¥ ê²©ì°¨)"""
        groups = np.unique(protected_attribute)
        group_metrics = {}

        for group in groups:
            mask = protected_attribute == group
            if mask.sum() > 0:
                group_acc = accuracy_score(y_true[mask], y_pred[mask])
                group_metrics[str(group)] = round(group_acc, 4)

        # ê·¸ë£¹ ê°„ ìµœëŒ€ ê²©ì°¨
        if len(group_metrics) >= 2:
            max_disparity = max(group_metrics.values()) - min(group_metrics.values())
        else:
            max_disparity = 0

        result = EvaluationResult(
            metric_name="fairness",
            value=max_disparity,
            threshold=disparity_threshold,
            passed=max_disparity <= disparity_threshold,
            details={
                "group_accuracy": group_metrics,
                "max_disparity": round(max_disparity, 4),
                "disparate_impact_ratio": round(
                    min(group_metrics.values()) / max(group_metrics.values()), 4
                ) if max(group_metrics.values()) > 0 else 1.0
            }
        )
        self.results.append(result)
        return result

    def evaluate_robustness(self, model_fn: Callable,
                            test_inputs: np.ndarray,
                            noise_level: float = 0.1,
                            stability_threshold: float = 0.9) -> EvaluationResult:
        """ì œ15ì¡°: ê²¬ê³ ì„± í‰ê°€ (ë…¸ì´ì¦ˆì— ëŒ€í•œ ì•ˆì •ì„±)"""
        original_outputs = model_fn(test_inputs)

        # ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = np.random.normal(0, noise_level, test_inputs.shape)
        noisy_inputs = test_inputs + noise
        noisy_outputs = model_fn(noisy_inputs)

        # ì¶œë ¥ ì¼ê´€ì„± ì¸¡ì •
        if hasattr(original_outputs, 'shape') and len(original_outputs.shape) > 1:
            # ë¶„ë¥˜ ëª¨ë¸: ì˜ˆì¸¡ í´ë˜ìŠ¤ ì¼ì¹˜ìœ¨
            stability = np.mean(
                np.argmax(original_outputs, axis=1) == np.argmax(noisy_outputs, axis=1)
            )
        else:
            # íšŒê·€ ëª¨ë¸: ì¶œë ¥ ë³€í™”ìœ¨
            stability = 1 - np.mean(np.abs(original_outputs - noisy_outputs) /
                                    (np.abs(original_outputs) + 1e-10))

        result = EvaluationResult(
            metric_name="robustness",
            value=stability,
            threshold=stability_threshold,
            passed=stability >= stability_threshold,
            details={
                "noise_level": noise_level,
                "prediction_stability": round(stability, 4)
            }
        )
        self.results.append(result)
        return result

    def evaluate_explainability(self, model_has_explanations: bool,
                                 explanation_coverage: float) -> EvaluationResult:
        """ì„¤ëª… ê°€ëŠ¥ì„± í‰ê°€"""
        result = EvaluationResult(
            metric_name="explainability",
            value=explanation_coverage if model_has_explanations else 0,
            threshold=0.8,
            passed=model_has_explanations and explanation_coverage >= 0.8,
            details={
                "has_explanation_capability": model_has_explanations,
                "explanation_coverage": explanation_coverage,
                "methods_available": ["SHAP", "LIME", "Feature Importance"]
            }
        )
        self.results.append(result)
        return result

    def generate_technical_documentation(self) -> Dict:
        """EU AI Act ê¸°ìˆ  ë¬¸ì„œìš© í‰ê°€ ë³´ê³ ì„œ"""
        passed_all = all(r.passed for r in self.results)

        return {
            "document_type": "EU_AI_Act_Technical_Documentation_Annex_IV",
            "model_info": {
                "name": self.model_name,
                "version": self.model_version,
                "evaluation_date": datetime.now().isoformat()
            },
            "evaluation_summary": {
                "total_tests": len(self.results),
                "passed": sum(1 for r in self.results if r.passed),
                "failed": sum(1 for r in self.results if not r.passed),
                "overall_compliance": passed_all
            },
            "detailed_results": [
                {
                    "metric": r.metric_name,
                    "value": r.value,
                    "threshold": r.threshold,
                    "passed": r.passed,
                    "details": r.details
                } for r in self.results
            ],
            "recommendations": self._generate_recommendations()
        }

    def _generate_recommendations(self) -> List[str]:
        """ê°œì„  ê¶Œê³ ì‚¬í•­"""
        recommendations = []
        for r in self.results:
            if not r.passed:
                if r.metric_name == "fairness":
                    recommendations.append(
                        "ê³µì •ì„± ê¸°ì¤€ ë¯¸ë‹¬: ë³´í˜¸ ê·¸ë£¹ë³„ ì¬í•™ìŠµ ë˜ëŠ” í¸í–¥ ì™„í™” ê¸°ë²• ì ìš© í•„ìš”"
                    )
                elif r.metric_name == "robustness":
                    recommendations.append(
                        "ê²¬ê³ ì„± ê¸°ì¤€ ë¯¸ë‹¬: ì ëŒ€ì  í•™ìŠµ ë˜ëŠ” ë°ì´í„° ì¦ê°• ê²€í† "
                    )
        return recommendations

# ì‚¬ìš© ì˜ˆì‹œ
evaluator = AIActModelEvaluator("CreditScoreModel", "v2.1.0")

# ê°€ìƒ ë°ì´í„°
y_true = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 1])
y_pred = np.array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1])
protected = np.array(['M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F'])

evaluator.evaluate_performance(y_true, y_pred)
evaluator.evaluate_fairness(y_true, y_pred, protected)
evaluator.evaluate_explainability(True, 0.85)

report = evaluator.generate_technical_documentation()
print(f"ì „ì²´ ì¤€ìˆ˜ ì—¬ë¶€: {report['evaluation_summary']['overall_compliance']}")</code></pre>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ëŒ€í™” ì„¹ì…˜ -->
        <section class="term-section" aria-labelledby="conversation-title">
            <h2 id="conversation-title" class="section-title">ì‹¤ë¬´ ëŒ€í™”</h2>
            <div class="conv-tabs">
                <button class="conv-tab active" data-target="meeting10">íšŒì˜</button>
                <button class="conv-tab" data-target="interview10">ë©´ì ‘</button>
                <button class="conv-tab" data-target="review10">ì½”ë“œë¦¬ë·°</button>
            </div>
            <div class="conv-content active" id="meeting10" data-label="íšŒì˜">
                <p><strong class="role-pm">PM:</strong> ëª¨ë¸ í‰ê°€ ì²´ê³„ë¥¼ EU AI Actì— ë§ê²Œ ì—…ê·¸ë ˆì´ë“œí•´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ ë­ê°€ ë¶€ì¡±í•œê°€ìš”?</p>
                <p><strong class="role-junior">MLì—”ì§€ë‹ˆì–´:</strong> ì •í™•ë„ ìœ„ì£¼ë¡œë§Œ í‰ê°€í•˜ê³  ìˆì–´ìš”. ê³µì •ì„±ì´ë‚˜ ê²¬ê³ ì„± í‰ê°€ëŠ” ì•ˆ í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>
                <p><strong class="role-senior">ì‹œë‹ˆì–´:</strong> ì œ15ì¡°ì—ì„œ ì •í™•ì„±, ê²¬ê³ ì„±, ì‚¬ì´ë²„ë³´ì•ˆì„ ëª¨ë‘ ìš”êµ¬í•©ë‹ˆë‹¤. ê³µì •ì„± í‰ê°€ë„ ì°¨ë³„ ê¸ˆì§€ ì›ì¹™ìƒ í•„ìˆ˜ì˜ˆìš”. í‰ê°€ í”„ë ˆì„ì›Œí¬ ì „ë©´ ê°œí¸ì´ í•„ìš”í•©ë‹ˆë‹¤.</p>
            </div>
            <div class="conv-content" id="interview10" data-label="ë©´ì ‘">
                <p><strong class="role-interviewer">ë©´ì ‘ê´€:</strong> EU AI Act ì¤€ìˆ˜ë¥¼ ìœ„í•œ ëª¨ë¸ í‰ê°€ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?</p>
                <p><strong class="role-candidate">ì§€ì›ì:</strong> ì„±ëŠ¥ë¿ ì•„ë‹ˆë¼ ê³µì •ì„±, ê²¬ê³ ì„±, ì„¤ëª… ê°€ëŠ¥ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ ë³´í˜¸ ì†ì„±(ì„±ë³„, ì¸ì¢…, ë‚˜ì´ ë“±)ë³„ë¡œ ëª¨ë¸ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ì¸¡ì •í•˜ê³ , ì ëŒ€ì  ì…ë ¥ì— ëŒ€í•œ ì•ˆì •ì„±ì„ í…ŒìŠ¤íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤. í‰ê°€ ê²°ê³¼ëŠ” ê¸°ìˆ  ë¬¸ì„œì— í¬í•¨ë˜ì–´ì•¼ í•˜ë¯€ë¡œ ì¬í˜„ ê°€ëŠ¥í•˜ê³  ê°ì‚¬ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ê¸°ë¡í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤.</p>
            </div>
            <div class="conv-content" id="review10" data-label="ì½”ë“œë¦¬ë·°">
                <p><strong class="role-senior">ì‹œë‹ˆì–´:</strong> ëª¨ë¸ í‰ê°€ ì½”ë“œê°€ accuracyë§Œ ì¸¡ì •í•˜ê³  ìˆë„¤ìš”.</p>
                <p><strong class="role-junior">ì£¼ë‹ˆì–´:</strong> ë‹¤ë¥¸ ì§€í‘œë„ ì¶”ê°€í•´ì•¼ í•˜ë‚˜ìš”?</p>
                <p><strong class="role-senior">ì‹œë‹ˆì–´:</strong> ë„¤, fairness_metrics í•¨ìˆ˜ë¥¼ ì¶”ê°€í•´ì„œ ë³´í˜¸ ê·¸ë£¹ë³„ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ì¸¡ì •í•˜ì„¸ìš”. ê·¸ë¦¬ê³  robustness_testë„ í•„ìš”í•´ìš”. ê²°ê³¼ëŠ” JSONìœ¼ë¡œ ì €ì¥í•´ì„œ ê¸°ìˆ  ë¬¸ì„œì— í¬í•¨í•  ìˆ˜ ìˆê²Œ í•˜ì„¸ìš”.</p>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ ì„¹ì…˜ -->
        <section class="term-section" aria-labelledby="warning-title">
            <h2 id="warning-title" class="section-title">ì£¼ì˜ì‚¬í•­</h2>
            <ul class="warning-list">
                <li class="critical">EU AI Act ì œ15ì¡°ëŠ” ê³ ìœ„í—˜ AIì— ëŒ€í•´ ì •í™•ì„±, ê²¬ê³ ì„±, ì‚¬ì´ë²„ë³´ì•ˆ ìš”ê±´ì„ ëª…ì‹œí•©ë‹ˆë‹¤. ì„±ëŠ¥ë§Œ í‰ê°€í•˜ê³  ì¶œì‹œí•˜ë©´ ìœ„ë°˜ì…ë‹ˆë‹¤.</li>
                <li>í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì€ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì„ ëŒ€í‘œí•´ì•¼ í•©ë‹ˆë‹¤. í¸í–¥ëœ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ í‰ê°€í•˜ë©´ ë°°í¬ í›„ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.</li>
                <li class="info">ìƒì„±í˜• AIëŠ” ì „í†µì ì¸ ì§€í‘œë¡œ í‰ê°€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. HELM, MMLU ë“± LLM ì „ìš© ë²¤ì¹˜ë§ˆí¬ì™€ ì¸ê°„ í‰ê°€ë¥¼ ë³‘í–‰í•˜ì„¸ìš”.</li>
            </ul>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ ì„¹ì…˜ -->
        <section class="term-section" aria-labelledby="related-title">
            <h2 id="related-title" class="section-title">ê´€ë ¨ ìš©ì–´</h2>
            <div class="related-grid">
                <a href="/ko/term/%EB%A0%88%EB%93%9C%ED%8C%80%20%ED%85%8C%EC%8A%A4%ED%8A%B8/" class="related-link">ë ˆë“œíŒ€ í…ŒìŠ¤íŠ¸</a>
                <a href="/ko/term/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%ED%92%88%EC%A7%88/" class="related-link">ë°ì´í„° í’ˆì§ˆ</a>
                <a href="/ko/term/%EC%82%AC%ED%9B%84%20%EC%8B%9C%EC%9E%A5%20%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/" class="related-link">ì‚¬í›„ ì‹œì¥ ëª¨ë‹ˆí„°ë§</a>
                <a href="/ko/term/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EC%98%81%ED%96%A5%ED%8F%89%EA%B0%80/" class="related-link">ì•Œê³ ë¦¬ì¦˜ ì˜í–¥í‰ê°€</a>
                <a href="/ko/term/%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%A0%81%20%EC%9C%84%ED%97%98/" class="related-link">ì‹œìŠ¤í…œì  ìœ„í—˜</a>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° ì„¹ì…˜ -->
        <section class="term-section" aria-labelledby="learn-title">
            <h2 id="learn-title" class="section-title">ë” ë°°ìš°ê¸°</h2>
            <ul class="resource-list">
                <li><span class="type-tool"></span><a href="https://crfm.stanford.edu/helm/" target="_blank" rel="noopener">Stanford HELM - LLM í‰ê°€ ë²¤ì¹˜ë§ˆí¬</a><span class="resource-meta">ë²¤ì¹˜ë§ˆí¬</span></li>
                <li><span class="type-tool"></span><a href="https://fairlearn.org/" target="_blank" rel="noopener">Fairlearn - ê³µì •ì„± í‰ê°€ ë„êµ¬</a><span class="resource-meta">ë„êµ¬</span></li>
                <li><span class="type-official"></span><a href="https://ai.google.dev/responsible" target="_blank" rel="noopener">Google Responsible AI - í‰ê°€ ê°€ì´ë“œ</a><span class="resource-meta">ê°€ì´ë“œ</span></li>
            </ul>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script src="/glossary/js/term-sections.js?v=20260129233538"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>