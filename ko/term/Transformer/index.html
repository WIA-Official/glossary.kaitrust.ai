<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer (Transformer Architecture) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="ì…€í”„ ì–´í…ì…˜ ê¸°ë°˜ ì‹ ê²½ë§ êµ¬ì¡°. GPT, BERT, Claudeì˜ ê¸°ë°˜. 2017ë…„ 'Attention Is All You Need'ë¡œ ì œì•ˆ.">
    <meta name="keywords" content="Transformer, Transformer Architecture, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/Transformer/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/Transformer/">
    <meta property="og:title" content="Transformer (Transformer Architecture) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="ì…€í”„ ì–´í…ì…˜ ê¸°ë°˜ ì‹ ê²½ë§ êµ¬ì¡°. GPT, BERT, Claudeì˜ ê¸°ë°˜. 2017ë…„ 'Attention Is All You Need'ë¡œ ì œì•ˆ.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Transformer (Transformer Architecture) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="ì…€í”„ ì–´í…ì…˜ ê¸°ë°˜ ì‹ ê²½ë§ êµ¬ì¡°. GPT, BERT, Claudeì˜ ê¸°ë°˜. 2017ë…„ 'Attention Is All You Need'ë¡œ ì œì•ˆ.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "Transformer",
        "description": "ì…€í”„ ì–´í…ì…˜ ê¸°ë°˜ ì‹ ê²½ë§ êµ¬ì¡°. GPT, BERT, Claudeì˜ ê¸°ë°˜. 2017ë…„ 'Attention Is All You Need'ë¡œ ì œì•ˆ.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }

        /* ê³ ë„í™” ì„¹ì…˜ ìŠ¤íƒ€ì¼ */
        .term-section {
            background: rgba(15, 23, 42, 0.6);
            border: 1px solid rgba(168, 85, 247, 0.1);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 1.5rem;
        }
        .section-title {
            font-size: 1.4rem;
            font-weight: 600;
            color: #f1f5f9;
            margin-bottom: 1.5rem;
            padding-bottom: 0.75rem;
            border-bottom: 1px solid rgba(168, 85, 247, 0.2);
        }
        .section-content p {
            color: #cbd5e1;
            line-height: 1.8;
            margin-bottom: 1rem;
        }
        .section-content p:last-child { margin-bottom: 0; }

        /* ì½”ë“œ ë¸”ë¡ */
        .code-tabs {
            display: flex;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }
        .code-tab {
            padding: 0.5rem 1rem;
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 8px;
            color: #94a3b8;
            cursor: pointer;
            transition: all 0.2s;
        }
        .code-tab.active {
            background: rgba(168, 85, 247, 0.2);
            border-color: #a855f7;
            color: #a855f7;
        }
        .code-block {
            position: relative;
            background: #0f172a;
            border-radius: 12px;
            overflow: hidden;
        }
        .code-block pre {
            padding: 1.5rem;
            margin: 0;
            overflow-x: auto;
        }
        .code-block code {
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            color: #e2e8f0;
            line-height: 1.6;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.3);
            border: none;
            border-radius: 6px;
            color: #e2e8f0;
            cursor: pointer;
            font-size: 0.85rem;
            transition: all 0.2s;
        }
        .copy-btn:hover { background: rgba(168, 85, 247, 0.5); }

        /* ëŒ€í™” ì˜ˆì‹œ */
        .conversation-examples { display: flex; flex-direction: column; gap: 1.5rem; }
        .conv-item {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 12px;
            padding: 1.25rem;
        }
        .conv-context {
            font-size: 0.9rem;
            color: #a855f7;
            font-weight: 500;
            margin-bottom: 0.75rem;
        }
        .conv-quote {
            color: #e2e8f0;
            font-style: italic;
            line-height: 1.7;
            margin: 0;
            padding-left: 1rem;
            border-left: 3px solid #a855f7;
        }

        /* ì£¼ì˜ì‚¬í•­ */
        .warning-list { display: flex; flex-direction: column; gap: 1rem; }
        .warning-item {
            display: flex;
            gap: 1rem;
            padding: 1rem;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
        }
        .warning-icon { font-size: 1.5rem; }
        .warning-item strong { color: #f1f5f9; display: block; margin-bottom: 0.25rem; }
        .warning-item p { color: #94a3b8; margin: 0; font-size: 0.95rem; }

        /* ê´€ë ¨ ìš©ì–´ */
        .related-terms { display: flex; flex-wrap: wrap; gap: 0.75rem; }
        .related-term-link {
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.1);
            border: 1px solid rgba(168, 85, 247, 0.3);
            border-radius: 20px;
            color: #a855f7;
            text-decoration: none;
            font-size: 0.9rem;
            transition: all 0.2s;
        }
        .related-term-link:hover {
            background: rgba(168, 85, 247, 0.2);
            transform: translateY(-2px);
        }

        /* ë” ë°°ìš°ê¸° */
        .learn-more { display: flex; flex-direction: column; gap: 0.75rem; }
        .learn-link {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            padding: 1rem;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            color: #00f5ff;
            text-decoration: none;
            transition: all 0.2s;
        }
        .learn-link:hover { background: rgba(0, 0, 0, 0.3); transform: translateX(5px); }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">Transformer</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">Transformer</h1>
            <p class="term-english">Transformer Architecture</p>
            <div class="term-description">
                <p>ì…€í”„ ì–´í…ì…˜ ê¸°ë°˜ ì‹ ê²½ë§ êµ¬ì¡°. GPT, BERT, Claudeì˜ ê¸°ë°˜. 2017ë…„ "Attention Is All You Need"ë¡œ ì œì•ˆ.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p>TransformerëŠ” 2017ë…„ Googleì˜ "Attention Is All You Need" ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ë¡œ, í˜„ëŒ€ AIì˜ ê·¼ê°„ì„ ì´ë£¨ëŠ” í•µì‹¬ êµ¬ì¡°ì…ë‹ˆë‹¤. RNNì´ë‚˜ CNN ì—†ì´ ì˜¤ì§ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ë§Œìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë³‘ë ¬ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ê³ , ì¥ê±°ë¦¬ ì˜ì¡´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•©ë‹ˆë‹¤.</p>
                <p>í•µì‹¬ êµ¬ì„± ìš”ì†ŒëŠ” Self-Attention(ì…ë ¥ ì‹œí€€ìŠ¤ ë‚´ ëª¨ë“  ìœ„ì¹˜ ê°„ ê´€ê³„ í•™ìŠµ), Multi-Head Attention(ë‹¤ì–‘í•œ ê´€ì ì˜ ì–´í…ì…˜ ë™ì‹œ ìˆ˜í–‰), Positional Encoding(ìˆœì„œ ì •ë³´ ì£¼ì…), Feed-Forward Network(ë¹„ì„ í˜• ë³€í™˜)ì…ë‹ˆë‹¤. ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ê°€ ì›í˜•ì´ì§€ë§Œ, BERT(ì¸ì½”ë”ë§Œ), GPT(ë””ì½”ë”ë§Œ) ë“± ë³€í˜•ì´ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>
                <p>Transformerì˜ ë“±ì¥ìœ¼ë¡œ NLPëŠ” ë¬¼ë¡  ì»´í“¨í„° ë¹„ì „(ViT), ìŒì„±(Whisper), ë©€í‹°ëª¨ë‹¬(CLIP) ë“± ëª¨ë“  ë¶„ì•¼ì—ì„œ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì´ ì¼ì–´ë‚¬ìŠµë‹ˆë‹¤. GPT-4, Claude, Gemini ë“± ìµœì‹  LLMì€ ëª¨ë‘ Transformer ê¸°ë°˜ì´ë©°, ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì— ë”°ë¼ ëª¨ë¸ í¬ê¸°ì™€ ë°ì´í„°ë¥¼ ëŠ˜ë¦´ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” íŠ¹ì„±ì´ ìˆìŠµë‹ˆë‹¤.</p>
                <p>ì‹¤ë¬´ì—ì„œ Transformerë¥¼ ì§ì ‘ êµ¬í˜„í•˜ëŠ” ê²½ìš°ëŠ” ë“œë¬¼ì§€ë§Œ, êµ¬ì¡°ë¥¼ ì´í•´í•˜ë©´ ëª¨ë¸ ì„ íƒ, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ì„±ëŠ¥ ìµœì í™”ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤. íŠ¹íˆ ì–´í…ì…˜ ë³µì¡ë„(O(nÂ²))ë¡œ ì¸í•œ ê¸´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ í•œê³„ì™€ ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ê¸°ë²•ë“¤(Flash Attention, Sparse Attention ë“±)ì„ ì•Œì•„ë‘ë©´ ì¢‹ìŠµë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="code-tabs">
                <button class="code-tab active" data-lang="python">Python</button>
            </div>
            <div class="code-block" data-lang="python">
                <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                <pre><code># Transformer í•µì‹¬ êµ¬ì¡° ì´í•´ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ Self-Attention êµ¬í˜„
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

class SelfAttention(nn.Module):
    """Scaled Dot-Product Self-Attention"""
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.d_model = d_model
        self.n_heads = n_heads
        self.d_k = d_model // n_heads

        # Query, Key, Value ì„ í˜• ë³€í™˜
        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)

    def forward(self, x, mask=None):
        batch_size, seq_len, _ = x.shape

        # Q, K, V ê³„ì‚° ë° í—¤ë“œ ë¶„ë¦¬
        Q = self.W_q(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)
        K = self.W_k(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)
        V = self.W_v(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)

        # Scaled Dot-Product Attention
        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)

        if mask is not None:
            scores = scores.masked_fill(mask == 0, float('-inf'))

        attn_weights = F.softmax(scores, dim=-1)
        context = torch.matmul(attn_weights, V)

        # í—¤ë“œ ê²°í•© ë° ì¶œë ¥ ë³€í™˜
        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)
        return self.W_o(context)

# ì‚¬ìš© ì˜ˆì‹œ
d_model, n_heads, seq_len, batch_size = 512, 8, 100, 32
attention = SelfAttention(d_model, n_heads)
x = torch.randn(batch_size, seq_len, d_model)
output = attention(x)  # [32, 100, 512]
print(f"Input: {x.shape} â†’ Output: {output.shape}")</code></pre>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ</h2>
            <div class="conversation-examples">
                <div class="conv-item">
                    <div class="conv-context">AI í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜ ë…¼ì˜ì—ì„œ</div>
                    <p class="conv-quote">"Transformer ê¸°ë°˜ ëª¨ë¸ì„ ì“¸ ê±´ë°, ì…ë ¥ì´ 10K í† í°ê¹Œì§€ ê°ˆ ìˆ˜ ìˆì–´ìš”. ê¸°ë³¸ ì–´í…ì…˜ì€ O(nÂ²)ì´ë¼ ë©”ëª¨ë¦¬ê°€ í„°ì§€ë‹ˆê¹Œ Flash Attentionì´ë‚˜ Longformer ê°™ì€ íš¨ìœ¨ì ì¸ êµ¬í˜„ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. A100 80GB ê¸°ì¤€ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ê°€ì ¸ê°ˆ ìˆ˜ ìˆëŠ”ì§€ í”„ë¡œíŒŒì¼ë§ë¶€í„° í•´ë´ì•¼ í•  ê²ƒ ê°™ì•„ìš”."</p>
                </div>
                <div class="conv-item">
                    <div class="conv-context">ê¸°ìˆ  ë©´ì ‘ì—ì„œ</div>
                    <p class="conv-quote">"Transformerê°€ RNNì„ ëŒ€ì²´í•œ í•µì‹¬ ì´ìœ ëŠ” ë³‘ë ¬í™”ì…ë‹ˆë‹¤. RNNì€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼ í•˜ì§€ë§Œ, Transformerì˜ Self-Attentionì€ ëª¨ë“  ìœ„ì¹˜ë¥¼ ë™ì‹œì— ê³„ì‚°í•  ìˆ˜ ìˆì–´ìš”. ë˜í•œ ì¥ê±°ë¦¬ ì˜ì¡´ì„±ì„ í•œ ë²ˆì˜ ì–´í…ì…˜ìœ¼ë¡œ ì§ì ‘ ì—°ê²°í•´ì„œ gradient vanishing ë¬¸ì œë„ ì™„í™”ë©ë‹ˆë‹¤."</p>
                </div>
                <div class="conv-item">
                    <div class="conv-context">LLM íŠœë‹ íšŒì˜ì—ì„œ</div>
                    <p class="conv-quote">"GPTëŠ” Transformerì˜ ë””ì½”ë”ë§Œ ì‚¬ìš©í•˜ê³ , BERTëŠ” ì¸ì½”ë”ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ìƒì„± íƒœìŠ¤í¬ì—ëŠ” ë””ì½”ë” ê¸°ë°˜ì´, ì´í•´ íƒœìŠ¤í¬ì—ëŠ” ì¸ì½”ë” ê¸°ë°˜ì´ ìœ ë¦¬í•´ìš”. ìš°ë¦¬ íƒœìŠ¤í¬ëŠ” ë¶„ë¥˜ë‹ˆê¹Œ BERT ê³„ì—´ë¡œ ê°€ê³ , ë‚˜ì¤‘ì— ìš”ì•½ ê¸°ëŠ¥ ì¶”ê°€í•˜ë©´ T5ì²˜ëŸ¼ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ë¥¼ ê²€í† í•˜ì£ ."</p>
                </div>
            </div>
        </section>

        <!-- ì•„í‚¤í…ì²˜ ë¹„êµ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“Š Transformer ë³€í˜• ë¹„êµ</h2>
            <div class="section-content">
                <table style="width:100%; border-collapse: collapse; margin: 1rem 0;">
                    <thead>
                        <tr style="border-bottom: 2px solid rgba(168, 85, 247, 0.3);">
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">êµ¬ì¡°</th>
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">ëŒ€í‘œ ëª¨ë¸</th>
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">íŠ¹ì§•</th>
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">ì í•© íƒœìŠ¤í¬</th>
                        </tr>
                    </thead>
                    <tbody style="color: #cbd5e1;">
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 0.75rem;"><strong>ì¸ì½”ë” ì „ìš©</strong></td>
                            <td style="padding: 0.75rem;">BERT, RoBERTa</td>
                            <td style="padding: 0.75rem;">ì–‘ë°©í–¥ ë¬¸ë§¥</td>
                            <td style="padding: 0.75rem;">ë¶„ë¥˜, NER, QA</td>
                        </tr>
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 0.75rem;"><strong>ë””ì½”ë” ì „ìš©</strong></td>
                            <td style="padding: 0.75rem;">GPT, Claude, Llama</td>
                            <td style="padding: 0.75rem;">ìê¸°íšŒê·€ ìƒì„±</td>
                            <td style="padding: 0.75rem;">í…ìŠ¤íŠ¸ ìƒì„±, ëŒ€í™”</td>
                        </tr>
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 0.75rem;"><strong>ì¸ì½”ë”-ë””ì½”ë”</strong></td>
                            <td style="padding: 0.75rem;">T5, BART</td>
                            <td style="padding: 0.75rem;">seq2seq</td>
                            <td style="padding: 0.75rem;">ë²ˆì—­, ìš”ì•½</td>
                        </tr>
                    </tbody>
                </table>
                <p style="font-size: 0.9rem; color: #94a3b8;">
                    ğŸ’¡ <strong>ì‹¤ë¬´ íŒ:</strong> ìµœì‹  LLMì€ ëŒ€ë¶€ë¶„ ë””ì½”ë” ì „ìš© êµ¬ì¡°.
                    GPT-4, Claude, Gemini ëª¨ë‘ ì´ ê³„ì—´ì…ë‹ˆë‹¤.
                    ì´í•´ íƒœìŠ¤í¬ë„ í”„ë¡¬í”„íŒ…ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•˜ì—¬ ì‹¤ë¬´ì—ì„œëŠ” ë””ì½”ë” ê¸°ë°˜ì´ ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
                </p>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ ì£¼ì˜ì‚¬í•­</h2>
            <div class="warning-list">
                <div class="warning-item">
                    <span class="warning-icon">1</span>
                    <div>
                        <strong>O(nÂ²) ë©”ëª¨ë¦¬ ë³µì¡ë„</strong>
                        <p>í‘œì¤€ Self-Attentionì€ ì‹œí€€ìŠ¤ ê¸¸ì´ì˜ ì œê³±ì— ë¹„ë¡€í•˜ëŠ” ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸´ ë¬¸ì„œ ì²˜ë¦¬ ì‹œ Flash Attention, Sparse Attention ë“± íš¨ìœ¨ì ì¸ êµ¬í˜„ì„ ì‚¬ìš©í•˜ê±°ë‚˜ Longformer, BigBird ê°™ì€ ì„ í˜• ë³µì¡ë„ ëª¨ë¸ì„ ê³ ë ¤í•˜ì„¸ìš”.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">2</span>
                    <div>
                        <strong>Positional Encoding í•œê³„</strong>
                        <p>í•™ìŠµëœ ìœ„ì¹˜ ì„ë² ë”©ì€ í•™ìŠµ ì‹œ ë³¸ ê¸¸ì´ë¥¼ ë„˜ì–´ì„œë©´ ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ì €í•˜ë©ë‹ˆë‹¤. RoPE, ALiBi ê°™ì€ ìƒëŒ€ì  ìœ„ì¹˜ ì¸ì½”ë”©ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆì§€ë§Œ, ì—¬ì „íˆ ê¸¸ì´ ì¼ë°˜í™”ëŠ” Transformerì˜ ì£¼ìš” ì—°êµ¬ ê³¼ì œì…ë‹ˆë‹¤.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">3</span>
                    <div>
                        <strong>KV ìºì‹œ ë©”ëª¨ë¦¬</strong>
                        <p>ì¶”ë¡  ì‹œ KV ìºì‹œê°€ ë°°ì¹˜ í¬ê¸°ì™€ ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¦ê°€í•©ë‹ˆë‹¤. ëŒ€ê·œëª¨ ì„œë¹™ì—ì„œëŠ” Grouped Query Attention(GQA)ì´ë‚˜ Multi-Query Attention(MQA)ìœ¼ë¡œ ìºì‹œ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="related-terms">
                <a href="/ko/term/%EC%96%B4%ED%85%90%EC%85%98/" class="related-term-link">ì–´í…ì…˜</a>
                <a href="/ko/term/BERT/" class="related-term-link">BERT</a>
                <a href="/ko/term/GPT/" class="related-term-link">GPT</a>
                <a href="/ko/term/LLM/" class="related-term-link">LLM</a>
                <a href="/ko/term/Self-Attention/" class="related-term-link">Self-Attention</a>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="learn-more">
                <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener" class="learn-link">
                    <span>Attention Is All You Need - ì›ë…¼ë¬¸</span>
                </a>
                <a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener" class="learn-link">
                    <span>The Illustrated Transformer - ì‹œê°ì  ì„¤ëª…</span>
                </a>
                <a href="https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html" target="_blank" rel="noopener" class="learn-link">
                    <span>PyTorch - Transformer ê³µì‹ ë¬¸ì„œ</span>
                </a>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "78px", fabRight: "170px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    // ì½”ë“œ ë³µì‚¬ ê¸°ëŠ¥
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }

    // ì½”ë“œ íƒ­ ì „í™˜
    document.querySelectorAll('.code-tab').forEach(tab => {
        tab.addEventListener('click', function() {
            const lang = this.dataset.lang;
            const section = this.closest('.term-section');

            section.querySelectorAll('.code-tab').forEach(t => t.classList.remove('active'));
            this.classList.add('active');

            section.querySelectorAll('.code-block').forEach(block => {
                block.style.display = block.dataset.lang === lang ? 'block' : 'none';
            });
        });
    });
    </script>
<script src="/glossary/js/term-sections.js"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js?v=20260130002"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>
