<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TensorRT-LLM | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="NVIDIAì˜ LLM ì¶”ë¡  ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬. GPUì—ì„œ ìµœê³  ì„±ëŠ¥ì˜ LLM ì¶”ë¡ ì„ ìœ„í•œ ì–‘ìí™”, ë°°ì¹˜ ì²˜ë¦¬, KV ìºì‹œ ìµœì í™” ê¸°ëŠ¥ ì œê³µ.">
    <meta name="keywords" content="TensorRT-LLM, TensorRT, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML, LLM ì¶”ë¡ , NVIDIA">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/TensorRT-LLM/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/TensorRT-LLM/">
    <meta property="og:title" content="TensorRT-LLM | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="NVIDIAì˜ LLM ì¶”ë¡  ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬. GPUì—ì„œ ìµœê³  ì„±ëŠ¥ì˜ LLM ì¶”ë¡  ì œê³µ.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="TensorRT-LLM | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="NVIDIAì˜ LLM ì¶”ë¡  ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬. GPUì—ì„œ ìµœê³  ì„±ëŠ¥ì˜ LLM ì¶”ë¡  ì œê³µ.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "TensorRT-LLM",
        "description": "NVIDIAì˜ LLM ì¶”ë¡  ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬. GPUì—ì„œ ìµœê³  ì„±ëŠ¥ì˜ LLM ì¶”ë¡  ì œê³µ.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .term-section {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.8), rgba(30, 41, 59, 0.5));
            border: 1px solid rgba(168, 85, 247, 0.15);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 1.5rem;
        }
        .term-section h2 {
            font-size: 1.4rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        .term-section p {
            color: #cbd5e1;
            line-height: 1.8;
            margin-bottom: 1rem;
        }
        .term-section ul, .term-section ol {
            color: #cbd5e1;
            padding-left: 1.5rem;
            margin-bottom: 1rem;
        }
        .term-section li {
            margin-bottom: 0.5rem;
            line-height: 1.7;
        }
        .code-block {
            position: relative;
            background: #1e293b;
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            overflow-x: auto;
        }
        .code-block pre {
            margin: 0;
            color: #e2e8f0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            padding: 0.4rem 0.8rem;
            background: rgba(168, 85, 247, 0.3);
            border: none;
            border-radius: 6px;
            color: #e2e8f0;
            font-size: 0.8rem;
            cursor: pointer;
            transition: background 0.2s;
        }
        .copy-btn:hover {
            background: rgba(168, 85, 247, 0.5);
        }
        .spec-table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        .spec-table th, .spec-table td {
            padding: 0.75rem 1rem;
            text-align: left;
            border-bottom: 1px solid rgba(148, 163, 184, 0.2);
            color: #cbd5e1;
        }
        .spec-table th {
            background: rgba(168, 85, 247, 0.1);
            color: #f1f5f9;
            font-weight: 600;
        }
        .spec-table tr:hover {
            background: rgba(168, 85, 247, 0.05);
        }
        .conversation-box {
            background: rgba(34, 197, 94, 0.1);
            border-left: 4px solid #22c55e;
            padding: 1rem 1.5rem;
            margin: 1rem 0;
            border-radius: 0 8px 8px 0;
        }
        .warning-box {
            background: rgba(251, 191, 36, 0.1);
            border-left: 4px solid #fbbf24;
            padding: 1rem 1.5rem;
            margin: 1rem 0;
            border-radius: 0 8px 8px 0;
        }
        .related-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.75rem;
            margin-top: 1rem;
        }
        .related-tag {
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.15);
            border-radius: 20px;
            color: #c4b5fd;
            text-decoration: none;
            font-size: 0.9rem;
            transition: all 0.2s;
        }
        .related-tag:hover {
            background: rgba(168, 85, 247, 0.3);
        }
        .resource-list {
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
        }
        .resource-item {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            padding: 0.75rem 1rem;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 8px;
            color: #94a3b8;
            text-decoration: none;
            transition: all 0.2s;
        }
        .resource-item:hover {
            background: rgba(168, 85, 247, 0.1);
            color: #c4b5fd;
        }
        .highlight-box {
            background: rgba(99, 102, 241, 0.1);
            border-left: 4px solid #6366f1;
            padding: 1rem 1.5rem;
            margin: 1rem 0;
            border-radius: 0 8px 8px 0;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
            .term-section { padding: 1.5rem; }
            .spec-table { font-size: 0.85rem; }
            .spec-table th, .spec-table td { padding: 0.5rem; }
        }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">TensorRT-LLM</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">TensorRT-LLM</h1>
            <p class="term-english">TensorRT for Large Language Models</p>
            <div class="term-description">
                <p>NVIDIAê°€ ê°œë°œí•œ LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸) ì¶”ë¡  ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. GPUì—ì„œ ìµœê³  ì„±ëŠ¥ì˜ ì¶”ë¡  ì†ë„ë¥¼ ì œê³µí•˜ë©°, In-flight Batching, KV ìºì‹œ ìµœì í™”, FP8/INT8 ì–‘ìí™” ë“± ì²¨ë‹¨ ê¸°ìˆ ì„ ì§€ì›í•©ë‹ˆë‹¤.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… -->
        <section class="term-section">
            <h2>ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <p>TensorRT-LLMì€ NVIDIAì˜ TensorRT ë”¥ëŸ¬ë‹ ì¶”ë¡  ì—”ì§„ì„ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— íŠ¹í™”ì‹œí‚¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ê¸°ì¡´ TensorRTì˜ ê·¸ë˜í”„ ìµœì í™”, ì»¤ë„ ìë™ íŠœë‹, ì •ë°€ë„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê¸°ëŠ¥ì— ë”í•´, LLM íŠ¹ìœ ì˜ ìê¸°íšŒê·€(autoregressive) ìƒì„± íŒ¨í„´ì— ìµœì í™”ëœ ê¸°ëŠ¥ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤. 2025ë…„ í˜„ì¬ ê°€ì¥ ë¹ ë¥¸ LLM ì¶”ë¡  ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ì†”ë£¨ì…˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.</p>

            <p>í•µì‹¬ ê¸°ëŠ¥ì¸ In-flight Batching(ì—°ì† ë°°ì¹­)ì€ ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ìš”ì²­ë“¤ì„ ë™ì ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ì •ì  ë°°ì¹­ì€ ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ì™„ë£Œë¥¼ ê¸°ë‹¤ë ¤ì•¼ í–ˆì§€ë§Œ, In-flight Batchingì€ ì™„ë£Œëœ ìš”ì²­ì„ ì¦‰ì‹œ ë°˜í™˜í•˜ê³  ìƒˆ ìš”ì²­ì„ íˆ¬ì…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì²˜ë¦¬ëŸ‰ì´ ìµœëŒ€ 4-8ë°° í–¥ìƒë©ë‹ˆë‹¤. Paged KV CacheëŠ” GPU ë©”ëª¨ë¦¬ë¥¼ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ê´€ë¦¬í•˜ì—¬ ë” ë§ì€ ë™ì‹œ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.</p>

            <p>TensorRT-LLMì€ FP16, BF16, INT8, INT4, FP8 ë“± ë‹¤ì–‘í•œ ì •ë°€ë„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. íŠ¹íˆ H100 GPUì˜ FP8 Tensor Coreë¥¼ í™œìš©í•˜ë©´ FP16 ëŒ€ë¹„ 2ë°° ê°€ê¹Œìš´ ì²˜ë¦¬ëŸ‰ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. GPTQ, AWQ, SmoothQuant ë“± ë‹¤ì–‘í•œ ì–‘ìí™” ê¸°ë²•ê³¼ í˜¸í™˜ë˜ì–´, í’ˆì§ˆ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ ì¶”ë¡  ì†ë„ë¥¼ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

            <p>ì§€ì› ëª¨ë¸ì€ LLaMA, Mistral, GPT-J, Falcon, Gemma, Qwen ë“± ì£¼ìš” ì˜¤í”ˆì†ŒìŠ¤ LLMì„ í¬í•¨í•©ë‹ˆë‹¤. Triton Inference Serverì™€ í†µí•©ë˜ì–´ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ëª¨ë¸ ì•™ìƒë¸”, A/B í…ŒìŠ¤íŠ¸, ë™ì  ë°°ì¹­ ë“±ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Multi-Instance GPU(MIG)ì™€ ë©€í‹° ë…¸ë“œ Tensor Parallelismì„ ì§€ì›í•˜ì—¬ ëŒ€í˜• ëª¨ë¸ì˜ ë¶„ì‚° ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ -->
        <section class="term-section">
            <h2>ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <p>TensorRT-LLMì„ ì‚¬ìš©í•œ LLaMA ëª¨ë¸ ì¶”ë¡  ì˜ˆì œì…ë‹ˆë‹¤.</p>

            <div class="code-block">
                <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                <pre><code># TensorRT-LLM ì„¤ì¹˜ ë° ëª¨ë¸ ë³€í™˜
# pip install tensorrt-llm

from tensorrt_llm import LLM, SamplingParams
from tensorrt_llm.hlapi import BuildConfig
import torch

# 1. ê°„ë‹¨í•œ ì‚¬ìš©ë²• (High-Level API)
# Hugging Face ëª¨ë¸ ì§ì ‘ ë¡œë“œ ë° ìµœì í™”
llm = LLM(
    model="meta-llama/Llama-2-7b-chat-hf",
    tensor_parallel_size=1,  # GPU ìˆ˜
    dtype="float16"
)

# ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° ì„¤ì •
sampling_params = SamplingParams(
    temperature=0.7,
    top_p=0.9,
    max_tokens=256
)

# ì¶”ë¡  ì‹¤í–‰
prompts = [
    "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
    "Pythonìœ¼ë¡œ í€µì†ŒíŠ¸ ì•Œê³ ë¦¬ì¦˜ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."
]

outputs = llm.generate(prompts, sampling_params)
for output in outputs:
    print(f"ì…ë ¥: {output.prompt}")
    print(f"ì¶œë ¥: {output.outputs[0].text}")
    print("-" * 50)


# 2. ê³ ê¸‰ ì‚¬ìš©ë²• - ì—”ì§„ ë¹Œë“œ ë° ìµœì í™”
from tensorrt_llm.builder import Builder
from tensorrt_llm.models import LLaMAForCausalLM

# ë¹Œë“œ ì„¤ì • (INT8 ì–‘ìí™” í¬í•¨)
build_config = BuildConfig(
    max_batch_size=64,
    max_input_len=2048,
    max_output_len=512,
    max_beam_width=1,
    strongly_typed=True,
    builder_opt_level=5,  # ìµœëŒ€ ìµœì í™”
)

# INT8 ì–‘ìí™” ì„¤ì •
build_config.plugin_config.update({
    "use_paged_context_fmha": True,
    "use_fp8_context_fmha": False,  # H100ì—ì„œ True
    "gemm_plugin": "auto",
    "gpt_attention_plugin": "auto"
})

# ì—”ì§„ ë¹Œë“œ
builder = Builder()
engine = builder.build_engine(
    model_dir="./llama-7b-hf",
    build_config=build_config,
    output_dir="./llama-7b-engine"
)

print("TensorRT-LLM ì—”ì§„ ë¹Œë“œ ì™„ë£Œ!")


# 3. Triton Inference Server ë°°í¬ ì„¤ì •
triton_config = """
name: "llama_tensorrt_llm"
backend: "tensorrtllm"
max_batch_size: 64

model_transaction_policy {
  decoupled: True
}

input [
  {
    name: "text_input"
    data_type: TYPE_STRING
    dims: [ 1 ]
  },
  {
    name: "max_tokens"
    data_type: TYPE_INT32
    dims: [ 1 ]
  }
]

output [
  {
    name: "text_output"
    data_type: TYPE_STRING
    dims: [ -1 ]
  }
]

instance_group [
  {
    count: 1
    kind: KIND_GPU
  }
]
"""
print(triton_config)</code></pre>
            </div>
        </section>

        <!-- ì„±ëŠ¥ & ë¹„ìš© -->
        <section class="term-section">
            <h2>ğŸ“Š ì„±ëŠ¥ & ë¹„ìš©</h2>
            <p>TensorRT-LLM ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (2025ë…„ 1ì›” ê¸°ì¤€) - LLaMA 2 70B ëª¨ë¸ ê¸°ì¤€ì…ë‹ˆë‹¤.</p>

            <h3 style="color: #f1f5f9; margin: 1.5rem 0 1rem;">GPUë³„ ì¶”ë¡  ì„±ëŠ¥</h3>
            <table class="spec-table">
                <thead>
                    <tr>
                        <th>GPU</th>
                        <th>ì²˜ë¦¬ëŸ‰ (tokens/s)</th>
                        <th>ì§€ì—°ì‹œê°„ (ms/token)</th>
                        <th>ë™ì‹œ ìš”ì²­ ìˆ˜</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>H100 80GB (FP8)</td>
                        <td>~10,000+</td>
                        <td>~5-8</td>
                        <td>256+</td>
                    </tr>
                    <tr>
                        <td>H100 80GB (FP16)</td>
                        <td>~6,000</td>
                        <td>~8-12</td>
                        <td>128+</td>
                    </tr>
                    <tr>
                        <td>A100 80GB (FP16)</td>
                        <td>~2,200</td>
                        <td>~15-20</td>
                        <td>64+</td>
                    </tr>
                    <tr>
                        <td>A100 40GB (INT8)</td>
                        <td>~1,800</td>
                        <td>~18-25</td>
                        <td>32+</td>
                    </tr>
                    <tr>
                        <td>RTX 4090 (INT4)</td>
                        <td>~800</td>
                        <td>~30-40</td>
                        <td>8+</td>
                    </tr>
                </tbody>
            </table>

            <div class="highlight-box">
                <p><strong>ì„±ëŠ¥ í–¥ìƒ ìˆ˜ì¹˜</strong></p>
                <ul style="margin-top: 0.5rem; margin-bottom: 0;">
                    <li>H100 FP8 vs A100 FP16: ìµœëŒ€ <strong>4.6ë°°</strong> ë†’ì€ ì²˜ë¦¬ëŸ‰</li>
                    <li>In-flight Batching ì ìš© ì‹œ: ìµœëŒ€ <strong>8ë°°</strong> ì²˜ë¦¬ëŸ‰ í–¥ìƒ</li>
                    <li>ê¸°ì¡´ PyTorch/HuggingFace ëŒ€ë¹„: <strong>ìµœëŒ€ 8ë°°</strong> ë¹ ë¥¸ ì¶”ë¡ </li>
                </ul>
            </div>

            <h3 style="color: #f1f5f9; margin: 1.5rem 0 1rem;">ë‹¤ë¥¸ ì¶”ë¡  ì—”ì§„ê³¼ ë¹„êµ</h3>
            <table class="spec-table">
                <thead>
                    <tr>
                        <th>íŠ¹ì„±</th>
                        <th>TensorRT-LLM</th>
                        <th>vLLM</th>
                        <th>llama.cpp</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>ëŒ€ìƒ í•˜ë“œì›¨ì–´</td>
                        <td>NVIDIA GPU</td>
                        <td>NVIDIA GPU</td>
                        <td>CPU/ë‹¤ì–‘í•œ GPU</td>
                    </tr>
                    <tr>
                        <td>ìµœëŒ€ ì„±ëŠ¥</td>
                        <td>ìµœê³ </td>
                        <td>ìƒ</td>
                        <td>ì¤‘</td>
                    </tr>
                    <tr>
                        <td>ì„¤ì • ë³µì¡ë„</td>
                        <td>ë†’ìŒ</td>
                        <td>ë‚®ìŒ</td>
                        <td>ë‚®ìŒ</td>
                    </tr>
                    <tr>
                        <td>Paged Attention</td>
                        <td>ì§€ì›</td>
                        <td>ì§€ì›</td>
                        <td>ë¯¸ì§€ì›</td>
                    </tr>
                    <tr>
                        <td>í”„ë¡œë•ì…˜ ë°°í¬</td>
                        <td>Triton ì—°ë™</td>
                        <td>ìì²´ ì„œë²„</td>
                        <td>ìˆ˜ë™ ì„¤ì •</td>
                    </tr>
                </tbody>
            </table>
            <p style="margin-top: 1rem; font-size: 0.9rem; color: #94a3b8;">TensorRT-LLMì€ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ë¬´ë£Œ ì‚¬ìš© ê°€ëŠ¥. NVIDIA GPU í•„ìˆ˜</p>
        </section>

        <!-- ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš” -->
        <section class="term-section">
            <h2>ğŸ—£ï¸ ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”</h2>

            <div class="conversation-box">
                <p><strong>"í…ì„œì•Œí‹° LLMìœ¼ë¡œ ì—”ì§„ ë¹Œë“œí•˜ê³  ë‚˜ë‹ˆê¹Œ vLLMë³´ë‹¤ 30% ì •ë„ ë” ë¹¨ë¼ì¡Œì–´ìš”"</strong></p>
                <p style="font-size: 0.9rem; color: #94a3b8; margin-top: 0.5rem;">â†’ TensorRT-LLMì˜ ê·¸ë˜í”„ ìµœì í™”ê°€ ì ìš©ëœ í›„ ì„±ëŠ¥ í–¥ìƒ ì²´ê° í‘œí˜„</p>
            </div>

            <div class="conversation-box">
                <p><strong>"ì¸í”Œë¼ì´íŠ¸ ë°°ì¹­ ì ìš©í•˜ë‹ˆê¹Œ ë™ì‹œ ì²˜ë¦¬ëŸ‰ì´ ê±°ì˜ 5ë°° ë›°ì—ˆì–´ìš”"</strong></p>
                <p style="font-size: 0.9rem; color: #94a3b8; margin-top: 0.5rem;">â†’ In-flight Batching(ì—°ì† ë°°ì¹­) ê¸°ëŠ¥ìœ¼ë¡œ ì¸í•œ ì²˜ë¦¬ëŸ‰ í–¥ìƒ</p>
            </div>

            <div class="conversation-box">
                <p><strong>"H100ì—ì„œ FP8ë¡œ ëŒë¦¬ë©´ A100 ëŒ€ë¹„ í† í° ì²˜ë¦¬ ì†ë„ê°€ 4ë°° ì´ìƒ ë‚˜ì™€ìš”"</strong></p>
                <p style="font-size: 0.9rem; color: #94a3b8; margin-top: 0.5rem;">â†’ H100ì˜ FP8 Tensor Coreë¥¼ í™œìš©í•œ ì„±ëŠ¥ í–¥ìƒ ì„¤ëª…</p>
            </div>
        </section>

        <!-- í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­ -->
        <section class="term-section">
            <h2>âš ï¸ í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­</h2>

            <div class="warning-box">
                <p><strong>ì—”ì§„ ë¹Œë“œ ì‹œê°„ ê³¼ì†Œí‰ê°€</strong></p>
                <p style="font-size: 0.9rem; margin-top: 0.5rem;">TensorRT-LLM ì—”ì§„ ë¹Œë“œëŠ” ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ìˆ˜ì‹­ ë¶„~ìˆ˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤. í”„ë¡œë•ì…˜ ë°°í¬ ì¼ì •ì— ë¹Œë“œ ì‹œê°„ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.</p>
            </div>

            <div class="warning-box">
                <p><strong>max_batch_size ê³¼ë‹¤ ì„¤ì •</strong></p>
                <p style="font-size: 0.9rem; margin-top: 0.5rem;">ì—”ì§„ ë¹Œë“œ ì‹œ max_batch_sizeë¥¼ ë„ˆë¬´ í¬ê²Œ ì„¤ì •í•˜ë©´ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ ë°œìƒí•©ë‹ˆë‹¤. ì‹¤ì œ ì›Œí¬ë¡œë“œì— ë§ê²Œ ì„¤ì •í•˜ì„¸ìš”.</p>
            </div>

            <div class="warning-box">
                <p><strong>GPU ì•„í‚¤í…ì²˜ í˜¸í™˜ì„±</strong></p>
                <p style="font-size: 0.9rem; margin-top: 0.5rem;">ë¹Œë“œí•œ ì—”ì§„ì€ íŠ¹ì • GPU ì•„í‚¤í…ì²˜ì— ì¢…ì†ë©ë‹ˆë‹¤. A100ìš© ì—”ì§„ì€ H100ì—ì„œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê° GPU íƒ€ì…ë³„ë¡œ ë³„ë„ ë¹Œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.</p>
            </div>

            <div class="warning-box">
                <p><strong>ì–‘ìí™” í’ˆì§ˆ ê²€ì¦ ëˆ„ë½</strong></p>
                <p style="font-size: 0.9rem; margin-top: 0.5rem;">INT8/INT4 ì–‘ìí™”ëŠ” ì†ë„ë¥¼ ë†’ì´ì§€ë§Œ í’ˆì§ˆ ì €í•˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ìœ¼ë¡œ í’ˆì§ˆì„ ê²€ì¦í•˜ì„¸ìš”.</p>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ -->
        <section class="term-section">
            <h2>ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="related-tags">
                <a href="../TensorFlow/" class="related-tag">TensorFlow</a>
                <a href="../vLLM/" class="related-tag">vLLM</a>
                <a href="../LLM/" class="related-tag">LLM</a>
                <a href="../Quantization/" class="related-tag">Quantization</a>
                <a href="../Inference/" class="related-tag">Inference</a>
                <a href="../GPU/" class="related-tag">GPU</a>
                <a href="../CUDA/" class="related-tag">CUDA</a>
                <a href="../Triton%20Inference%20Server/" class="related-tag">Triton Inference Server</a>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° -->
        <section class="term-section">
            <h2>ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="resource-list">
                <a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener" class="resource-item">
                    <span>ğŸ’»</span>
                    <span>TensorRT-LLM GitHub ì €ì¥ì†Œ</span>
                </a>
                <a href="https://nvidia.github.io/TensorRT-LLM/" target="_blank" rel="noopener" class="resource-item">
                    <span>ğŸ“–</span>
                    <span>TensorRT-LLM ê³µì‹ ë¬¸ì„œ</span>
                </a>
                <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="noopener" class="resource-item">
                    <span>ğŸ”—</span>
                    <span>NVIDIA TensorRT ê°œë°œì í˜ì´ì§€</span>
                </a>
                <a href="https://github.com/triton-inference-server/server" target="_blank" rel="noopener" class="resource-item">
                    <span>ğŸ“š</span>
                    <span>Triton Inference Server</span>
                </a>
                <a href="https://developer.nvidia.com/blog/optimizing-inference-on-llms-with-tensorrt-llm-now-publicly-available/" target="_blank" rel="noopener" class="resource-item">
                    <span>ğŸ“°</span>
                    <span>NVIDIA ê³µì‹ ë¸”ë¡œê·¸ - TensorRT-LLM ìµœì í™”</span>
                </a>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }
    </script>
<script src="/glossary/js/term-sections.js"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js?v=20260130002"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>