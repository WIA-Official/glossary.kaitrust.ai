<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BERT (Bidirectional Encoder Representations from Transformers) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="Googleì˜ ì–‘ë°©í–¥ ì–¸ì–´ ëª¨ë¸. ë¬¸ë§¥ ì´í•´ì— íƒì›”. NLP ë²¤ì¹˜ë§ˆí¬ í˜ì‹ . GPTì™€ í•¨ê»˜ í˜„ëŒ€ LLMì˜ ì„ êµ¬ì.">
    <meta name="keywords" content="BERT, Bidirectional Encoder Representations from Transformers, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/BERT/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/BERT/">
    <meta property="og:title" content="BERT (Bidirectional Encoder Representations from Transformers) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="Googleì˜ ì–‘ë°©í–¥ ì–¸ì–´ ëª¨ë¸. ë¬¸ë§¥ ì´í•´ì— íƒì›”. NLP ë²¤ì¹˜ë§ˆí¬ í˜ì‹ . GPTì™€ í•¨ê»˜ í˜„ëŒ€ LLMì˜ ì„ êµ¬ì.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="BERT (Bidirectional Encoder Representations from Transformers) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="Googleì˜ ì–‘ë°©í–¥ ì–¸ì–´ ëª¨ë¸. ë¬¸ë§¥ ì´í•´ì— íƒì›”. NLP ë²¤ì¹˜ë§ˆí¬ í˜ì‹ . GPTì™€ í•¨ê»˜ í˜„ëŒ€ LLMì˜ ì„ êµ¬ì.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "BERT",
        "description": "Googleì˜ ì–‘ë°©í–¥ ì–¸ì–´ ëª¨ë¸. ë¬¸ë§¥ ì´í•´ì— íƒì›”. NLP ë²¤ì¹˜ë§ˆí¬ í˜ì‹ . GPTì™€ í•¨ê»˜ í˜„ëŒ€ LLMì˜ ì„ êµ¬ì.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }

        /* ê³ ë„í™” ì„¹ì…˜ ìŠ¤íƒ€ì¼ */
        .term-section {
            background: rgba(15, 23, 42, 0.6);
            border: 1px solid rgba(168, 85, 247, 0.1);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 1.5rem;
        }
        .section-title {
            font-size: 1.4rem;
            font-weight: 600;
            color: #f1f5f9;
            margin-bottom: 1.5rem;
            padding-bottom: 0.75rem;
            border-bottom: 1px solid rgba(168, 85, 247, 0.2);
        }
        .section-content p {
            color: #cbd5e1;
            line-height: 1.8;
            margin-bottom: 1rem;
        }
        .section-content p:last-child { margin-bottom: 0; }

        /* ì½”ë“œ ë¸”ë¡ */
        .code-tabs {
            display: flex;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }
        .code-tab {
            padding: 0.5rem 1rem;
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 8px;
            color: #94a3b8;
            cursor: pointer;
            transition: all 0.2s;
        }
        .code-tab.active {
            background: rgba(168, 85, 247, 0.2);
            border-color: #a855f7;
            color: #a855f7;
        }
        .code-block {
            position: relative;
            background: #0f172a;
            border-radius: 12px;
            overflow: hidden;
        }
        .code-block pre {
            padding: 1.5rem;
            margin: 0;
            overflow-x: auto;
        }
        .code-block code {
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            color: #e2e8f0;
            line-height: 1.6;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.3);
            border: none;
            border-radius: 6px;
            color: #e2e8f0;
            cursor: pointer;
            font-size: 0.85rem;
            transition: all 0.2s;
        }
        .copy-btn:hover { background: rgba(168, 85, 247, 0.5); }

        /* ëŒ€í™” ì˜ˆì‹œ */
        .conversation-examples { display: flex; flex-direction: column; gap: 1.5rem; }
        .conv-item {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 12px;
            padding: 1.25rem;
        }
        .conv-context {
            font-size: 0.9rem;
            color: #a855f7;
            font-weight: 500;
            margin-bottom: 0.75rem;
        }
        .conv-quote {
            color: #e2e8f0;
            font-style: italic;
            line-height: 1.7;
            margin: 0;
            padding-left: 1rem;
            border-left: 3px solid #a855f7;
        }

        /* ì£¼ì˜ì‚¬í•­ */
        .warning-list { display: flex; flex-direction: column; gap: 1rem; }
        .warning-item {
            display: flex;
            gap: 1rem;
            padding: 1rem;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
        }
        .warning-icon { font-size: 1.5rem; }
        .warning-item strong { color: #f1f5f9; display: block; margin-bottom: 0.25rem; }
        .warning-item p { color: #94a3b8; margin: 0; font-size: 0.95rem; }

        /* ê´€ë ¨ ìš©ì–´ */
        .related-terms { display: flex; flex-wrap: wrap; gap: 0.75rem; }
        .related-term-link {
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.1);
            border: 1px solid rgba(168, 85, 247, 0.3);
            border-radius: 20px;
            color: #a855f7;
            text-decoration: none;
            font-size: 0.9rem;
            transition: all 0.2s;
        }
        .related-term-link:hover {
            background: rgba(168, 85, 247, 0.2);
            transform: translateY(-2px);
        }

        /* ë” ë°°ìš°ê¸° */
        .learn-more { display: flex; flex-direction: column; gap: 0.75rem; }
        .learn-link {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            padding: 1rem;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            color: #00f5ff;
            text-decoration: none;
            transition: all 0.2s;
        }
        .learn-link:hover { background: rgba(0, 0, 0, 0.3); transform: translateX(5px); }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css?v=20260130002423">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">BERT</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">BERT</h1>
            <p class="term-english">Bidirectional Encoder Representations from Transformers</p>
            <div class="term-description">
                <p>Googleì˜ ì–‘ë°©í–¥ ì–¸ì–´ ëª¨ë¸. ë¬¸ë§¥ ì´í•´ì— íƒì›”. NLP ë²¤ì¹˜ë§ˆí¬ í˜ì‹ . GPTì™€ í•¨ê»˜ í˜„ëŒ€ LLMì˜ ì„ êµ¬ì.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ìƒì„¸ ì„¤ëª… ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p>BERT(Bidirectional Encoder Representations from Transformers)ëŠ” 2018ë…„ Googleì´ ë°œí‘œí•œ ì‚¬ì „í•™ìŠµ ì–¸ì–´ ëª¨ë¸ë¡œ, ì–‘ë°©í–¥ ë¬¸ë§¥ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¨ë°©í–¥ ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë¬¸ì¥ì˜ ì•ë’¤ ë§¥ë½ì„ ëª¨ë‘ í™œìš©í•´ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.</p>
                <p>BERTëŠ” 2018ë…„ 10ì›” ê³µê°œ ì§í›„ 11ê°œì˜ NLP ë²¤ì¹˜ë§ˆí¬ì—ì„œ SOTAë¥¼ ë‹¬ì„±í•˜ë©° NLP ë¶„ì•¼ì— íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì„ ì¼ìœ¼ì¼°ìŠµë‹ˆë‹¤. ì´í›„ RoBERTa, ALBERT, DistilBERT ë“± ìˆ˜ë§ì€ ë³€í˜•ì´ ë“±ì¥í–ˆê³ , í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ì¸ KoBERT, KoELECTRAë„ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.</p>
                <p>í•µì‹¬ ì›ë¦¬ëŠ” Masked Language Model(MLM)ê³¼ Next Sentence Prediction(NSP) ë‘ ê°€ì§€ ì‚¬ì „í•™ìŠµ íƒœìŠ¤í¬ì…ë‹ˆë‹¤. MLMì€ ì…ë ¥ í† í°ì˜ 15%ë¥¼ [MASK]ë¡œ ê°€ë¦¬ê³  ì˜ˆì¸¡í•˜ê²Œ í•˜ì—¬ ì–‘ë°©í–¥ ë¬¸ë§¥ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. NSPëŠ” ë‘ ë¬¸ì¥ì´ ì—°ì†ì¸ì§€ íŒë³„í•˜ì—¬ ë¬¸ì¥ ê°„ ê´€ê³„ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.</p>
                <p>ì‹¤ë¬´ì—ì„œ BERTëŠ” í…ìŠ¤íŠ¸ ë¶„ë¥˜, ê°œì²´ëª… ì¸ì‹(NER), ì§ˆì˜ì‘ë‹µ(QA), ë¬¸ì¥ ìœ ì‚¬ë„ ì¸¡ì • ë“± NLU(ìì—°ì–´ ì´í•´) íƒœìŠ¤í¬ì— ì£¼ë¡œ í™œìš©ë©ë‹ˆë‹¤. ì‚¬ì „í•™ìŠµëœ BERTë¥¼ íŠ¹ì • íƒœìŠ¤í¬ì— ë§ê²Œ fine-tuningí•˜ë©´ ì ì€ ë°ì´í„°ë¡œë„ ë†’ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆì–´, ì‚°ì—… í˜„ì¥ì—ì„œ í‘œì¤€ ì ‘ê·¼ë²•ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
            </div>
        </section>

        <!-- ì½”ë“œ ì˜ˆì œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="code-tabs">
                <button class="code-tab active" data-lang="python">Python</button>
            </div>
            <div class="code-block" data-lang="python">
                <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
                <pre><code># BERTë¥¼ í™œìš©í•œ ê°ì • ë¶„ë¥˜ Fine-tuning ì˜ˆì œ
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import Trainer, TrainingArguments
from datasets import load_dataset
import torch

# 1. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(
    model_name,
    num_labels=2  # ê¸ì •/ë¶€ì • ì´ì§„ ë¶„ë¥˜
)

# 2. ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬
dataset = load_dataset("imdb")

def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=512
    )

tokenized_datasets = dataset.map(tokenize_function, batched=True)

# 3. í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./bert-imdb",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=16,
    warmup_steps=500,
    learning_rate=2e-5,  # BERT ê¶Œì¥ í•™ìŠµë¥ 
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True
)

# 4. Trainerë¡œ Fine-tuning
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"]
)

trainer.train()

# 5. ì¶”ë¡  ì˜ˆì œ
def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    probs = torch.softmax(outputs.logits, dim=-1)
    return "ê¸ì •" if probs[0][1] > 0.5 else "ë¶€ì •"</code></pre>
            </div>
        </section>

        <!-- ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ</h2>
            <div class="conversation-examples">
                <div class="conv-item">
                    <div class="conv-context">NLP í”„ë¡œì íŠ¸ ëª¨ë¸ ì„ ì • íšŒì˜ì—ì„œ</div>
                    <p class="conv-quote">"ê°ì • ë¶„ë¥˜ëŠ” ë¬¸ë§¥ ì´í•´ê°€ í•µì‹¬ì´ë‹ˆê¹Œ BERT ê³„ì—´ì´ ì í•©í•©ë‹ˆë‹¤. í•œêµ­ì–´ë‹ˆê¹Œ KoBERTë‚˜ KoELECTRAë¡œ ì‹œì‘í•˜ê³ , ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ RoBERTa-largeë¡œ ìŠ¤ì¼€ì¼ì—…í•˜ëŠ” ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. GPTëŠ” ìƒì„± íƒœìŠ¤í¬ì— ë” ì í•©í•´ìš”."</p>
                </div>
                <div class="conv-item">
                    <div class="conv-context">Fine-tuning ì„±ëŠ¥ ì´ìŠˆ ë…¼ì˜ ì¤‘</div>
                    <p class="conv-quote">"BERT fine-tuningì—ì„œ learning rateê°€ ë„ˆë¬´ í¬ë©´ catastrophic forgettingì´ ë°œìƒí•´ìš”. 2e-5ì—ì„œ 5e-5 ì‚¬ì´ë¡œ ìœ ì§€í•˜ê³ , warmupì„ ì „ì²´ ìŠ¤í…ì˜ 10% ì •ë„ ì£¼ëŠ” ê²Œ ì•ˆì „í•©ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì´ 1e-4ë©´ ë„ˆë¬´ ë†’ì•„ìš”."</p>
                </div>
                <div class="conv-item">
                    <div class="conv-context">ê¸°ìˆ  ë©´ì ‘ì—ì„œ</div>
                    <p class="conv-quote">"BERTì˜ MLMì´ ì–‘ë°©í–¥ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì´ìœ ëŠ” ë§ˆìŠ¤í‚¹ëœ í† í°ì„ ì˜ˆì¸¡í•  ë•Œ ì™¼ìª½ê³¼ ì˜¤ë¥¸ìª½ ë¬¸ë§¥ì„ ëª¨ë‘ ë³¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. GPTì²˜ëŸ¼ ë‹¤ìŒ í† í° ì˜ˆì¸¡ì´ë©´ ì˜¤ë¥¸ìª½ì„ ë³¼ ìˆ˜ ì—†ì–´ì„œ ë‹¨ë°©í–¥ì´ ë˜ì£ . ì´ ì°¨ì´ê°€ BERTê°€ NLUì— ê°•í•œ ê·¼ë³¸ì ì¸ ì´ìœ ì…ë‹ˆë‹¤."</p>
                </div>
            </div>
        </section>

        <!-- ëª¨ë¸ ìŠ¤í™ ë¹„êµ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“Š BERT ëª¨ë¸ ìŠ¤í™ ë¹„êµ</h2>
            <div class="section-content">
                <table style="width:100%; border-collapse: collapse; margin: 1rem 0;">
                    <thead>
                        <tr style="border-bottom: 2px solid rgba(168, 85, 247, 0.3);">
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">ëª¨ë¸</th>
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">íŒŒë¼ë¯¸í„°</th>
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">ë ˆì´ì–´</th>
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">Hidden</th>
                            <th style="padding: 0.75rem; text-align: left; color: #a855f7;">ìš©ë„</th>
                        </tr>
                    </thead>
                    <tbody style="color: #cbd5e1;">
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 0.75rem;"><strong>BERT-base</strong></td>
                            <td style="padding: 0.75rem;">110M</td>
                            <td style="padding: 0.75rem;">12</td>
                            <td style="padding: 0.75rem;">768</td>
                            <td style="padding: 0.75rem;">ğŸ† ì¼ë°˜ ì‚¬ìš© (ê¶Œì¥)</td>
                        </tr>
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 0.75rem;">BERT-large</td>
                            <td style="padding: 0.75rem;">340M</td>
                            <td style="padding: 0.75rem;">24</td>
                            <td style="padding: 0.75rem;">1024</td>
                            <td style="padding: 0.75rem;">ë†’ì€ ì •í™•ë„ í•„ìš”ì‹œ</td>
                        </tr>
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 0.75rem;">DistilBERT</td>
                            <td style="padding: 0.75rem;">66M</td>
                            <td style="padding: 0.75rem;">6</td>
                            <td style="padding: 0.75rem;">768</td>
                            <td style="padding: 0.75rem;">ğŸ’¨ ë¹ ë¥¸ ì¶”ë¡  (40% ê²½ëŸ‰í™”)</td>
                        </tr>
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 0.75rem;">KoBERT</td>
                            <td style="padding: 0.75rem;">92M</td>
                            <td style="padding: 0.75rem;">12</td>
                            <td style="padding: 0.75rem;">768</td>
                            <td style="padding: 0.75rem;">ğŸ‡°ğŸ‡· í•œêµ­ì–´ íŠ¹í™”</td>
                        </tr>
                    </tbody>
                </table>
                <p style="font-size: 0.9rem; color: #94a3b8;">
                    ğŸ’¡ <strong>ì‹¤ë¬´ íŒ:</strong> ëŒ€ë¶€ë¶„ BERT-baseë¡œ ì¶©ë¶„.
                    í”„ë¡œë•ì…˜ ì†ë„ ì¤‘ìš”ì‹œ DistilBERT ì‚¬ìš©.
                    í•œêµ­ì–´ëŠ” KoBERT ë˜ëŠ” KoELECTRA ê¶Œì¥.
                    Fine-tuningì‹œ GPU ë©”ëª¨ë¦¬: base 8GB, large 16GB ì´ìƒ í•„ìš”.
                </p>
            </div>
        </section>

        <!-- ì£¼ì˜ì‚¬í•­ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ ì£¼ì˜ì‚¬í•­</h2>
            <div class="warning-list">
                <div class="warning-item">
                    <span class="warning-icon">1</span>
                    <div>
                        <strong>512 í† í° ì œí•œ</strong>
                        <p>BERT-baseëŠ” ìµœëŒ€ 512 í† í°ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸´ ë¬¸ì„œëŠ” chunkingí•˜ê±°ë‚˜ Longformer, BigBird ê°™ì€ long-context ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”. ë‹¨ìˆœ truncationì€ ì¤‘ìš” ì •ë³´ ì†ì‹¤ì„ ìœ ë°œí•©ë‹ˆë‹¤.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">2</span>
                    <div>
                        <strong>ìƒì„± íƒœìŠ¤í¬ ë¶€ì í•©</strong>
                        <p>BERTëŠ” ì¸ì½”ë” ì „ìš© ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìš”ì•½, ë²ˆì—­, ëŒ€í™” ìƒì„± ë“±ì—ëŠ” GPT ê³„ì—´ì´ë‚˜ T5 ê°™ì€ ì¸ì½”ë”-ë””ì½”ë” ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">3</span>
                    <div>
                        <strong>ë„ë©”ì¸ ë¶ˆì¼ì¹˜</strong>
                        <p>ì¼ë°˜ ë„ë©”ì¸ìœ¼ë¡œ ì‚¬ì „í•™ìŠµëœ BERTë¥¼ ì˜ë£Œ, ë²•ë¥  ë“± ì „ë¬¸ ë„ë©”ì¸ì— ë°”ë¡œ ì ìš©í•˜ë©´ ì„±ëŠ¥ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤. BioBERT, LegalBERT ë“± ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ë„ë©”ì¸ ë°ì´í„°ë¡œ ì¶”ê°€ ì‚¬ì „í•™ìŠµí•˜ì„¸ìš”.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- ê´€ë ¨ ìš©ì–´ ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="related-terms">
                <a href="/ko/term/Transformer/" class="related-term-link">Transformer</a>
                <a href="/ko/term/GPT/" class="related-term-link">GPT</a>
                <a href="/ko/term/Fine-tuning/" class="related-term-link">Fine-tuning</a>
                <a href="/ko/term/Pre-training/" class="related-term-link">Pre-training</a>
                <a href="/ko/term/Attention/" class="related-term-link">Attention</a>
            </div>
        </section>

        <!-- ë” ë°°ìš°ê¸° ì„¹ì…˜ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="learn-more">
                <a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener" class="learn-link">
                    <span>BERT: Pre-training of Deep Bidirectional Transformers - ì›ë…¼ë¬¸</span>
                </a>
                <a href="https://huggingface.co/docs/transformers/model_doc/bert" target="_blank" rel="noopener" class="learn-link">
                    <span>Hugging Face - BERT ê³µì‹ ë¬¸ì„œ</span>
                </a>
                <a href="https://jalammar.github.io/illustrated-bert/" target="_blank" rel="noopener" class="learn-link">
                    <span>The Illustrated BERT - ì‹œê°ì  ì„¤ëª…</span>
                </a>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    // ì½”ë“œ ë³µì‚¬ ê¸°ëŠ¥
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }

    // ì½”ë“œ íƒ­ ì „í™˜
    document.querySelectorAll('.code-tab').forEach(tab => {
        tab.addEventListener('click', function() {
            const lang = this.dataset.lang;
            const section = this.closest('.term-section');

            section.querySelectorAll('.code-tab').forEach(t => t.classList.remove('active'));
            this.classList.add('active');

            section.querySelectorAll('.code-block').forEach(block => {
                block.style.display = block.dataset.lang === lang ? 'block' : 'none';
            });
        });
    });
    </script>
<script src="/glossary/js/term-sections.js?v=20260130002423"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>