<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multimodal (ë©€í‹°ëª¨ë‹¬) | KAITRUST AI ë°±ê³¼ì‚¬ì „</title>
    <meta name="description" content="í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“± ì—¬ëŸ¬ í˜•íƒœ ë°ì´í„° ì²˜ë¦¬. GPT-4V, Gemini.">
    <meta name="keywords" content="Multimodal, ë©€í‹°ëª¨ë‹¬, AI ìš©ì–´, KAITRUST, AI ë°±ê³¼ì‚¬ì „, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/Multimodal/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/Multimodal/">
    <meta property="og:title" content="Multimodal (ë©€í‹°ëª¨ë‹¬) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta property="og:description" content="í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“± ì—¬ëŸ¬ í˜•íƒœ ë°ì´í„° ì²˜ë¦¬. GPT-4V, Gemini.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI ë°±ê³¼ì‚¬ì „">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Multimodal (ë©€í‹°ëª¨ë‹¬) | KAITRUST AI ë°±ê³¼ì‚¬ì „">
    <meta name="twitter:description" content="í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“± ì—¬ëŸ¬ í˜•íƒœ ë°ì´í„° ì²˜ë¦¬. GPT-4V, Gemini.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "Multimodal",
        "description": "í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“± ì—¬ëŸ¬ í˜•íƒœ ë°ì´í„° ì²˜ë¦¬. GPT-4V, Gemini.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI ë°±ê³¼ì‚¬ì „",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .related-section {
            margin-top: 3rem;
        }
        .related-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
        }

        /* ê³ ë„í™” ì„¹ì…˜ ìŠ¤íƒ€ì¼ */
        .term-section { background: rgba(15, 23, 42, 0.6); border: 1px solid rgba(168, 85, 247, 0.1); border-radius: 16px; padding: 2rem; margin-bottom: 1.5rem; }
        .section-title { font-size: 1.4rem; font-weight: 600; color: #f1f5f9; margin-bottom: 1.5rem; padding-bottom: 0.75rem; border-bottom: 1px solid rgba(168, 85, 247, 0.2); }
        .section-content p { color: #cbd5e1; line-height: 1.8; margin-bottom: 1rem; }
        .code-tabs { display: flex; gap: 0.5rem; margin-bottom: 1rem; }
        .code-tab { padding: 0.5rem 1rem; background: rgba(255,255,255,0.05); border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; color: #94a3b8; cursor: pointer; }
        .code-tab.active { background: rgba(168,85,247,0.2); border-color: #a855f7; color: #a855f7; }
        .code-block { position: relative; background: #0f172a; border-radius: 12px; overflow: hidden; }
        .code-block pre { padding: 1.5rem; margin: 0; overflow-x: auto; }
        .code-block code { font-family: 'JetBrains Mono', monospace; font-size: 0.9rem; color: #e2e8f0; }
        .copy-btn { position: absolute; top: 0.75rem; right: 0.75rem; padding: 0.5rem 1rem; background: rgba(168,85,247,0.3); border: none; border-radius: 6px; color: #e2e8f0; cursor: pointer; }
        .conversation-examples { display: flex; flex-direction: column; gap: 1.5rem; }
        .conv-item { background: rgba(0,0,0,0.2); border-radius: 12px; padding: 1.25rem; }
        .conv-context { font-size: 0.9rem; color: #a855f7; font-weight: 500; margin-bottom: 0.75rem; }
        .conv-quote { color: #e2e8f0; font-style: italic; line-height: 1.7; margin: 0; padding-left: 1rem; border-left: 3px solid #a855f7; }
        .warning-list { display: flex; flex-direction: column; gap: 1rem; }
        .warning-item { display: flex; gap: 1rem; padding: 1rem; background: rgba(0,0,0,0.2); border-radius: 10px; }
        .warning-icon { font-size: 1.5rem; }
        .warning-item strong { color: #f1f5f9; display: block; margin-bottom: 0.25rem; }
        .warning-item p { color: #94a3b8; margin: 0; }
        .related-terms { display: flex; flex-wrap: wrap; gap: 0.75rem; }
        .related-term-link { padding: 0.5rem 1rem; background: rgba(168,85,247,0.1); border: 1px solid rgba(168,85,247,0.3); border-radius: 20px; color: #a855f7; text-decoration: none; }
        .learn-more { display: flex; flex-direction: column; gap: 0.75rem; }
        .learn-link { display: flex; align-items: center; gap: 0.75rem; padding: 1rem; background: rgba(0,0,0,0.2); border-radius: 10px; color: #00f5ff; text-decoration: none; }
        .spec-table { width: 100%; border-collapse: collapse; margin-top: 1rem; }
        .spec-table th, .spec-table td { padding: 0.75rem; text-align: left; border-bottom: 1px solid rgba(168,85,247,0.1); }
        .spec-table th { color: #a855f7; font-weight: 500; }
        .spec-table td { color: #cbd5e1; }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css?v=20260129234454">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">í™ˆ</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai">AI ë°±ê³¼ì‚¬ì „</a>
            <span>â€º</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>â€º</span>
            <span class="current">Multimodal</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>ğŸ¤–</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">Multimodal</h1>
            <p class="term-english">ë©€í‹°ëª¨ë‹¬ / Multi-modal AI</p>
            <div class="term-description">
                <p>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ë“± ì—¬ëŸ¬ í˜•íƒœì˜ ë°ì´í„°ë¥¼ í†µí•© ì²˜ë¦¬í•˜ëŠ” AI. GPT-4o, Gemini 2, Claude 3.5ê°€ ëŒ€í‘œì ì¸ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    ğŸ“š ì „ì²´ ìš©ì–´ ë³´ê¸°
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    ğŸ¤– AI/ML ë”ë³´ê¸°
                </a>
            </div>
        </article>

        <!-- ğŸ“– ìƒì„¸ ì„¤ëª… -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“– ìƒì„¸ ì„¤ëª…</h2>
            <div class="section-content">
                <p>Multimodal(ë©€í‹°ëª¨ë‹¬) AIëŠ” í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ë“± ì—¬ëŸ¬ í˜•íƒœ(modality)ì˜ ë°ì´í„°ë¥¼ ë™ì‹œì— ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¸ê³µì§€ëŠ¥ì…ë‹ˆë‹¤. ì¸ê°„ì²˜ëŸ¼ ë‹¤ì–‘í•œ ê°ê° ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ íŒë‹¨í•˜ê³  ì‘ë‹µí•  ìˆ˜ ìˆì–´, ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° AIë³´ë‹¤ í›¨ì”¬ ê°•ë ¥í•œ ì´í•´ë ¥ê³¼ í‘œí˜„ë ¥ì„ ê°–ìŠµë‹ˆë‹¤.</p>
                <p>ë©€í‹°ëª¨ë‹¬ AIì˜ ë°œì „ì€ Vision Transformer(ViT)ì™€ CLIPì˜ ë“±ì¥ìœ¼ë¡œ ê°€ì†í™”ë˜ì—ˆìŠµë‹ˆë‹¤. CLIPì€ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìŒì„ ëŒ€ì¡° í•™ìŠµí•˜ì—¬ ë‘ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ë™ì¼í•œ ì„ë² ë”© ê³µê°„ì— ë§¤í•‘í–ˆê³ , ì´ ì ‘ê·¼ë²•ì´ GPT-4V, Gemini, Claude ë“± í˜„ëŒ€ ë©€í‹°ëª¨ë‹¬ LLMì˜ ê¸°ë°˜ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
                <p>ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ í•µì‹¬ ì•„í‚¤í…ì²˜ëŠ” ê° ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¸ì½”ë”ì™€ ì´ë¥¼ í†µí•©í•˜ëŠ” í“¨ì „ ë ˆì´ì–´ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” Vision Encoder(ViT ê¸°ë°˜)ë¡œ, ì˜¤ë””ì˜¤ëŠ” Whisper ê°™ì€ ì˜¤ë””ì˜¤ ì¸ì½”ë”ë¡œ ì²˜ë¦¬í•œ í›„, LLMê³¼ ê²°í•©í•˜ì—¬ êµì°¨ ëª¨ë‹¬ ì¶”ë¡ (cross-modal reasoning)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ë„¤ì´í‹°ë¸Œ ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ê°€ ë“±ì¥í•˜ì—¬ ì²˜ìŒë¶€í„° ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í•¨ê»˜ í•™ìŠµí•©ë‹ˆë‹¤.</p>
                <p>ì‹¤ë¬´ì—ì„œ ë©€í‹°ëª¨ë‹¬ AIëŠ” ë¬¸ì„œ ì´í•´(OCR+í…ìŠ¤íŠ¸ ë¶„ì„), ë¹„ë””ì˜¤ ë¶„ì„, ë¡œë´‡ ì œì–´, ì˜ë£Œ ì˜ìƒ ì§„ë‹¨, ì „ììƒê±°ë˜ ìƒí’ˆ ì„¤ëª… ìƒì„± ë“±ì— í™œìš©ë©ë‹ˆë‹¤. 2025ë…„ í˜„ì¬ GPT-4oëŠ” í…ìŠ¤íŠ¸+ì´ë¯¸ì§€+ì˜¤ë””ì˜¤ ì‹¤ì‹œê°„ ì…ì¶œë ¥ì„, Gemini 2ëŠ” 100ë§Œ í† í° ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ì„ ì§€ì›í•©ë‹ˆë‹¤.</p>
            </div>
            <table class="spec-table">
                <tr><th>ëª¨ë¸</th><th>ì…ë ¥ ëª¨ë‹¬ë¦¬í‹°</th><th>ì¶œë ¥ ëª¨ë‹¬ë¦¬í‹°</th><th>íŠ¹ì§•</th></tr>
                <tr><td>GPT-4o</td><td>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤</td><td>í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤</td><td>ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”, ê°ì • ì¸ì‹</td></tr>
                <tr><td>Gemini 2</td><td>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤</td><td>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€</td><td>100ë§Œ í† í° ì»¨í…ìŠ¤íŠ¸</td></tr>
                <tr><td>Claude 3.5</td><td>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€</td><td>í…ìŠ¤íŠ¸</td><td>200K ì»¨í…ìŠ¤íŠ¸, ë¬¸ì„œ ë¶„ì„ ê°•ì </td></tr>
                <tr><td>Mistral Large 3</td><td>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€</td><td>í…ìŠ¤íŠ¸</td><td>ì˜¤í”ˆì†ŒìŠ¤ ë©€í‹°ëª¨ë‹¬ LLM</td></tr>
                <tr><td>Qwen-VL / LLaVA</td><td>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€</td><td>í…ìŠ¤íŠ¸</td><td>ì˜¤í”ˆì†ŒìŠ¤, ì…€í”„í˜¸ìŠ¤íŒ… ê°€ëŠ¥</td></tr>
            </table>
        </section>

        <!-- ğŸ’» ì½”ë“œ ì˜ˆì œ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ’» ì½”ë“œ ì˜ˆì œ</h2>
            <div class="code-tabs">
                <button class="code-tab active" data-lang="python">Python</button>
            </div>
            <div class="code-block" data-lang="python">
                
                <pre><code class="language-python"># ë©€í‹°ëª¨ë‹¬ AI API ì‚¬ìš© ì˜ˆì œ
import openai
import anthropic
import base64
from pathlib import Path

# 1. OpenAI GPT-4o ë©€í‹°ëª¨ë‹¬ (ì´ë¯¸ì§€ ë¶„ì„)
client = openai.OpenAI()

def analyze_image_gpt4o(image_path: str, question: str):
    """GPT-4oë¡œ ì´ë¯¸ì§€ ë¶„ì„"""
    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode("utf-8")

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": question},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "high"  # low, high, auto
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )
    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
result = analyze_image_gpt4o(
    "chart.png",
    "ì´ ì°¨íŠ¸ì—ì„œ 2024ë…„ ë§¤ì¶œ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."
)
print(result)


# 2. Claude 3.5 ë©€í‹°ëª¨ë‹¬ (ë¬¸ì„œ ë¶„ì„)
claude_client = anthropic.Anthropic()

def analyze_document_claude(image_path: str, instruction: str):
    """Claudeë¡œ ë¬¸ì„œ/ì´ë¯¸ì§€ ë¶„ì„"""
    with open(image_path, "rb") as f:
        image_data = base64.standard_b64encode(f.read()).decode("utf-8")

    # ì´ë¯¸ì§€ íƒ€ì… ê°ì§€
    suffix = Path(image_path).suffix.lower()
    media_types = {".png": "image/png", ".jpg": "image/jpeg", ".gif": "image/gif"}
    media_type = media_types.get(suffix, "image/jpeg")

    response = claude_client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=2048,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": media_type,
                            "data": image_data
                        }
                    },
                    {"type": "text", "text": instruction}
                ]
            }
        ]
    )
    return response.content[0].text


# 3. ì—¬ëŸ¬ ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„
def compare_images(image_paths: list[str], question: str):
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ë¶„ì„"""
    content = [{"type": "text", "text": question}]

    for path in image_paths:
        with open(path, "rb") as f:
            image_data = base64.b64encode(f.read()).decode("utf-8")
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
        })

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": content}],
        max_tokens=2048
    )
    return response.choices[0].message.content


# 4. ì˜¤í”ˆì†ŒìŠ¤ ë©€í‹°ëª¨ë‹¬ (LLaVA / Qwen-VL)
# pip install transformers accelerate
from transformers import AutoProcessor, LlavaForConditionalGeneration
from PIL import Image

def analyze_with_llava(image_path: str, prompt: str):
    """LLaVAë¡œ ë¡œì»¬ ì´ë¯¸ì§€ ë¶„ì„"""
    model_id = "llava-hf/llava-1.5-7b-hf"

    processor = AutoProcessor.from_pretrained(model_id)
    model = LlavaForConditionalGeneration.from_pretrained(
        model_id,
        torch_dtype="auto",
        device_map="auto"
    )

    image = Image.open(image_path)
    conversation = [
        {"role": "user", "content": [
            {"type": "image"},
            {"type": "text", "text": prompt}
        ]}
    ]

    text = processor.apply_chat_template(conversation, add_generation_prompt=True)
    inputs = processor(images=image, text=text, return_tensors="pt").to(model.device)

    output = model.generate(**inputs, max_new_tokens=512)
    return processor.decode(output[0], skip_special_tokens=True)

print("=== ë©€í‹°ëª¨ë‹¬ AI ì˜ˆì œ ì‹¤í–‰ ì™„ë£Œ ===")</code></pre>
                <button class="copy-btn" onclick="copyCode(this)">ğŸ“‹ ë³µì‚¬</button>
            </div>
        </section>

        <!-- ğŸ—£ï¸ ì‹¤ë¬´ ëŒ€í™” ì˜ˆì‹œ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ—£ï¸ ì‹¤ë¬´ì—ì„œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”</h2>
            <div class="conversation-examples">
                <div class="conv-item">
                    <div class="conv-context">ğŸ’¬ ì œí’ˆ ê¸°íš íšŒì˜ì—ì„œ</div>
                    <blockquote class="conv-quote">"ê³ ê° ì§€ì›ì— ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ ì¶”ê°€í•˜ë©´ ì¢‹ê² ì–´ìš”. ì‚¬ìš©ìê°€ ì—ëŸ¬ ìŠ¤í¬ë¦°ìƒ· ì˜¬ë¦¬ë©´ GPT-4oê°€ ì´ë¯¸ì§€ ë¶„ì„í•´ì„œ ë¬¸ì œ ì›ì¸ê³¼ í•´ê²°ì±…ì„ ë°”ë¡œ ì•Œë ¤ì£¼ëŠ” ê±°ì£ . í…ìŠ¤íŠ¸ë§Œ ë°›ì„ ë•Œë³´ë‹¤ í•´ê²°ë¥ ì´ 30% ì´ìƒ ì˜¬ë¼ê°ˆ ê²ë‹ˆë‹¤."</blockquote>
                </div>
                <div class="conv-item">
                    <div class="conv-context">ğŸ’¬ ë©´ì ‘ì—ì„œ</div>
                    <blockquote class="conv-quote">"ë©€í‹°ëª¨ë‹¬ AIëŠ” ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í†µí•© ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. Vision Encoderë¡œ ì´ë¯¸ì§€ë¥¼ ì„ë² ë”©í•˜ê³  LLMê³¼ ê²°í•©í•˜ì—¬ êµì°¨ ëª¨ë‹¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. GPT-4oëŠ” í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ë¥¼ ë„¤ì´í‹°ë¸Œë¡œ ì²˜ë¦¬í•˜ê³ , ì‹¤ë¬´ì—ì„œëŠ” ë¬¸ì„œ ì´í•´, ìƒí’ˆ ì„¤ëª… ìƒì„±, ë¹„ë””ì˜¤ ìš”ì•½ ë“±ì— í™œìš©ë©ë‹ˆë‹¤."</blockquote>
                </div>
                <div class="conv-item">
                    <div class="conv-context">ğŸ’¬ ê¸°ìˆ  í† ë¡ ì—ì„œ</div>
                    <blockquote class="conv-quote">"LLaVAë‚˜ Qwen-VL ê°™ì€ ì˜¤í”ˆì†ŒìŠ¤ ë©€í‹°ëª¨ë‹¬ë„ GPT-4Vê¸‰ ì„±ëŠ¥ì— ê·¼ì ‘í–ˆì–´ìš”. ë¯¼ê° ë°ì´í„°ë¼ API ëª» ì“°ë©´ ì…€í”„í˜¸ìŠ¤íŒ…ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨, Vision Encoder ë•Œë¬¸ì— VRAMì´ ë§ì´ í•„ìš”í•˜ë‹ˆ A100 ê¸°ì¤€ìœ¼ë¡œ ì¡ì•„ì•¼ í•´ìš”."</blockquote>
                </div>
            </div>
        </section>

        <!-- âš ï¸ ì£¼ì˜ì‚¬í•­ -->
        <section class="term-section">
            <h2 class="section-title">âš ï¸ í”í•œ ì‹¤ìˆ˜ & ì£¼ì˜ì‚¬í•­</h2>
            <div class="warning-list">
                <div class="warning-item">
                    <span class="warning-icon">âŒ</span>
                    <div>
                        <strong>ì´ë¯¸ì§€ í•´ìƒë„ ë¬´ì‹œ</strong>
                        <p>ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ëŠ” ë¶„ì„ í’ˆì§ˆì´ ë–¨ì–´ì§€ê³ , ë„ˆë¬´ í° ì´ë¯¸ì§€ëŠ” í† í° ë¹„ìš©ì´ ê¸‰ì¦í•©ë‹ˆë‹¤. GPT-4oëŠ” detail: low/high ì˜µì…˜ìœ¼ë¡œ ë¹„ìš© ëŒ€ë¹„ í’ˆì§ˆì„ ì¡°ì ˆí•˜ì„¸ìš”.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">âŒ</span>
                    <div>
                        <strong>ë¯¼ê° ì •ë³´ ì´ë¯¸ì§€ ì „ì†¡</strong>
                        <p>ì´ë¯¸ì§€ì— í¬í•¨ëœ ê°œì¸ì •ë³´, ê¸°ì—… ë¹„ë°€ì´ í´ë¼ìš°ë“œ APIë¡œ ì „ì†¡ë©ë‹ˆë‹¤. ë¯¼ê° ë°ì´í„°ëŠ” ì˜¨í”„ë ˆë¯¸ìŠ¤ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(LLaVA, Qwen-VL)ì„ ì‚¬ìš©í•˜ì„¸ìš”.</p>
                    </div>
                </div>
                <div class="warning-item">
                    <span class="warning-icon">âœ…</span>
                    <div>
                        <strong>ì˜¬ë°”ë¥¸ ì ‘ê·¼: ëª¨ë‹¬ë¦¬í‹°ë³„ ìµœì í™”</strong>
                        <p>ë¬¸ì„œ OCRì€ Claude 3.5ê°€, ì‹¤ì‹œê°„ ëŒ€í™”ëŠ” GPT-4oê°€ ê°•í•©ë‹ˆë‹¤. ë¹„ë””ì˜¤ ë¶„ì„ì€ Geminiê°€ ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ìš©ë„ì— ë§ëŠ” ëª¨ë¸ì„ ì„ íƒí•˜ê³ , ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¡œ ë¹„ìš©ì„ ìµœì í™”í•˜ì„¸ìš”.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- ğŸ”— ê´€ë ¨ ìš©ì–´ -->
        <section class="term-section">
            <h2 class="section-title">ğŸ”— ê´€ë ¨ ìš©ì–´</h2>
            <div class="related-terms">
                <a href="/ko/term/LLM/" class="related-term-link">LLM</a>
                <a href="/ko/term/Vision%20Transformer/" class="related-term-link">Vision Transformer</a>
                <a href="/ko/term/CLIP/" class="related-term-link">CLIP</a>
                <a href="/ko/term/GPT/" class="related-term-link">GPT</a>
                <a href="/ko/term/Gemini/" class="related-term-link">Gemini</a>
                <a href="/ko/term/Embedding/" class="related-term-link">Embedding</a>
            </div>
        </section>

        <!-- ğŸ“š ë” ë°°ìš°ê¸° -->
        <section class="term-section">
            <h2 class="section-title">ğŸ“š ë” ë°°ìš°ê¸°</h2>
            <div class="learn-more">
                <a href="https://platform.openai.com/docs/guides/vision" target="_blank" class="learn-link">ğŸ“„ OpenAI Vision API ê°€ì´ë“œ</a>
                <a href="https://docs.anthropic.com/en/docs/build-with-claude/vision" target="_blank" class="learn-link">ğŸ“ Claude Vision ë¬¸ì„œ</a>
                <a href="https://huggingface.co/docs/transformers/model_doc/llava" target="_blank" class="learn-link">ğŸ’» LLaVA - ì˜¤í”ˆì†ŒìŠ¤ ë©€í‹°ëª¨ë‹¬</a>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    function copyCode(btn) {
        const codeBlock = btn.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            btn.textContent = 'âœ… ë³µì‚¬ë¨!';
            setTimeout(() => btn.textContent = 'ğŸ“‹ ë³µì‚¬', 2000);
        });
    }
    </script>
<script src="/glossary/js/term-sections.js?v=20260129233538"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>