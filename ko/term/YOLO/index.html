<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLO (You Only Look Once) | KAITRUST AI 백과사전</title>
    <meta name="description" content="실시간 객체 탐지 알고리즘. 한 번의 순전파로 객체 검출.">
    <meta name="keywords" content="YOLO, You Only Look Once, AI 용어, KAITRUST, AI 백과사전, AI/ML">
    <link rel="canonical" href="https://glossary.kaitrust.ai/ko/term/YOLO/">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://glossary.kaitrust.ai/ko/term/YOLO/">
    <meta property="og:title" content="YOLO (You Only Look Once) | KAITRUST AI 백과사전">
    <meta property="og:description" content="실시간 객체 탐지 알고리즘. 한 번의 순전파로 객체 검출.">
    <meta property="og:image" content="https://kaitrust.ai/images/og-glossary.png">
    <meta property="og:locale" content="ko_KR">
    <meta property="og:site_name" content="KAITRUST AI 백과사전">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="YOLO (You Only Look Once) | KAITRUST AI 백과사전">
    <meta name="twitter:description" content="실시간 객체 탐지 알고리즘. 한 번의 순전파로 객체 검출.">
    <meta name="twitter:image" content="https://kaitrust.ai/images/og-glossary.png">

    <!-- Structured Data (JSON-LD) -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "DefinedTerm",
        "name": "YOLO",
        "description": "실시간 객체 탐지 알고리즘. 한 번의 순전파로 객체 검출.",
        "inDefinedTermSet": {
            "@type": "DefinedTermSet",
            "name": "KAITRUST AI 백과사전",
            "url": "https://glossary.kaitrust.ai/"
        }
    }
    </script>

    <link rel="icon" type="image/png" href="https://kaitrust.ai/favicon.png">
    <link rel="apple-touch-icon" href="https://kaitrust.ai/favicon.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700;900&family=Noto+Sans+KR:wght@300;400;500;700;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/kaitrust-common.css">
    <link rel="stylesheet" href="/css/light-mode.css">
    <link rel="stylesheet" href="/components/ask-ai/kaitrust-ai-modal.css">

    <style>
        .term-detail-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 120px 2rem 4rem;
            position: relative;
            z-index: 1;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            font-size: 0.9rem;
            flex-wrap: wrap;
        }
        .breadcrumb a {
            color: #64748b;
            text-decoration: none;
            transition: color 0.2s;
        }
        .breadcrumb a:hover { color: var(--primary); }
        .breadcrumb span { color: #64748b; }
        .breadcrumb .current { color: var(--accent); font-weight: 500; }
        .term-detail-header {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 3rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
        }
        .term-category-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #a855f7;
            margin-bottom: 1rem;
        }
        .term-title {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #ffffff, #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .term-english {
            font-size: 1.2rem;
            color: #94a3b8;
            margin-bottom: 1.5rem;
        }
        .term-description {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #e2e8f0;
        }
        .term-actions {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }
        .term-action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all 0.3s;
        }
        .btn-primary {
            background: linear-gradient(135deg, #a855f7, #6366f1);
            color: white;
        }
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(168, 85, 247, 0.3);
        }
        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        .content-section {
            background: linear-gradient(145deg, rgba(15, 23, 42, 0.9), rgba(30, 41, 59, 0.6));
            border: 1px solid rgba(168, 85, 247, 0.2);
            border-radius: 24px;
            padding: 2rem;
            margin-bottom: 2rem;
        }
        .content-section h2 {
            font-size: 1.4rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: #f1f5f9;
        }
        .content-section p {
            color: #cbd5e1;
            line-height: 1.8;
            margin-bottom: 1rem;
        }
        .code-block {
            background: #0f172a;
            border-radius: 12px;
            padding: 1.5rem;
            overflow-x: auto;
            position: relative;
        }
        .code-block pre {
            margin: 0;
            color: #e2e8f0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.3);
            border: 1px solid rgba(168, 85, 247, 0.5);
            border-radius: 8px;
            color: #e2e8f0;
            cursor: pointer;
            font-size: 0.8rem;
            display: flex;
            align-items: center;
            gap: 0.3rem;
            transition: all 0.2s;
        }
        .copy-btn:hover {
            background: rgba(168, 85, 247, 0.5);
        }
        .conversation-list {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        .conversation-item {
            background: rgba(30, 41, 59, 0.5);
            border-radius: 12px;
            padding: 1rem 1.5rem;
            border-left: 3px solid #a855f7;
        }
        .mistake-list {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        .mistake-item {
            background: rgba(239, 68, 68, 0.1);
            border-radius: 12px;
            padding: 1rem 1.5rem;
            border-left: 3px solid #ef4444;
        }
        .mistake-item.correct {
            background: rgba(34, 197, 94, 0.1);
            border-left-color: #22c55e;
        }
        .related-terms {
            display: flex;
            flex-wrap: wrap;
            gap: 0.75rem;
        }
        .related-term-link {
            padding: 0.5rem 1rem;
            background: rgba(168, 85, 247, 0.2);
            border-radius: 20px;
            color: #a855f7;
            text-decoration: none;
            font-size: 0.9rem;
            transition: all 0.2s;
        }
        .related-term-link:hover {
            background: rgba(168, 85, 247, 0.4);
        }
        .resource-list {
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
        }
        .resource-link {
            color: #60a5fa;
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .resource-link:hover {
            text-decoration: underline;
        }
        .cost-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 1rem;
        }
        .cost-table th, .cost-table td {
            padding: 0.75rem 1rem;
            text-align: left;
            border-bottom: 1px solid rgba(148, 163, 184, 0.2);
            color: #cbd5e1;
        }
        .cost-table th {
            color: #f1f5f9;
            font-weight: 600;
        }
        .version-highlight {
            background: rgba(34, 197, 94, 0.2);
            color: #4ade80;
        }
        @media (max-width: 768px) {
            .term-detail-container { padding: 100px 1rem 2rem; }
            .term-detail-header { padding: 2rem 1.5rem; }
            .term-title { font-size: 1.8rem; }
            .content-section { padding: 1.5rem; }
            .cost-table { font-size: 0.85rem; }
            .cost-table th, .cost-table td { padding: 0.5rem; }
        }
    </style>
    <link rel="stylesheet" href="/glossary/css/term-sections.css">

</head>
<body>
    <!-- Particle Background -->
    <div class="particle-container" id="particles"></div>

    <!-- Header -->
        <div id="kaitrust-header"></div>

    <main class="term-detail-container">
        <!-- Breadcrumb -->
        <nav class="breadcrumb" aria-label="Breadcrumb">
            <a href="https://kaitrust.ai">홈</a>
            <span>&#8250;</span>
            <a href="https://glossary.kaitrust.ai">AI 백과사전</a>
            <span>&#8250;</span>
            <a href="https://glossary.kaitrust.ai/#ai">AI/ML</a>
            <span>&#8250;</span>
            <span class="current">YOLO</span>
        </nav>

        <!-- Term Header -->
        <article class="term-detail-header">
            <div class="term-category-badge">
                <span>&#129302;</span>
                <span>AI/ML</span>
            </div>
            <h1 class="term-title">YOLO</h1>
            <p class="term-english">You Only Look Once</p>
            <div class="term-description">
                <p>실시간 객체 탐지 알고리즘. 한 번의 순전파로 객체 검출.</p>
            </div>
            <div class="term-actions">
                <a href="https://glossary.kaitrust.ai" class="term-action-btn btn-primary">
                    &#128218; 전체 용어 보기
                </a>
                <a href="https://glossary.kaitrust.ai/#ai" class="term-action-btn btn-secondary">
                    &#129302; AI/ML 더보기
                </a>
            </div>
        </article>

        <!-- Detailed Explanation -->
        <section class="content-section">
            <h2>&#128214; 상세 설명</h2>
            <p>YOLO(You Only Look Once)는 2015년 Joseph Redmon이 제안한 실시간 객체 탐지(Object Detection) 알고리즘입니다. 기존의 R-CNN 계열이 영역 제안(Region Proposal)과 분류를 두 단계로 수행했던 것과 달리, YOLO는 전체 이미지를 한 번의 신경망 순전파로 처리하여 바운딩 박스와 클래스 확률을 동시에 예측합니다. 이러한 단일 단계(Single-stage) 접근법 덕분에 실시간 처리가 가능해졌습니다.</p>
            <p>YOLO의 핵심 아이디어는 이미지를 S x S 그리드로 나누고, 각 그리드 셀이 B개의 바운딩 박스와 C개의 클래스 확률을 예측하는 것입니다. 각 바운딩 박스는 (x, y, w, h, confidence) 5개의 값을 가지며, confidence는 박스 내 객체 존재 확률과 IoU(Intersection over Union)의 곱입니다. 이 회귀 문제로 변환된 탐지 작업은 GPU에서 매우 빠르게 처리됩니다.</p>
            <p>YOLO는 다양한 버전으로 발전해왔습니다. YOLOv1(2015)에서 YOLOv3(2018, Darknet-53 백본)까지 원저자가 개발했고, 이후 커뮤니티 주도로 YOLOv4, YOLOv5가 등장했습니다. Ultralytics가 개발한 YOLOv8(2023)은 Anchor-free 방식과 분리된 Head 구조로 정확도와 속도를 개선했습니다. YOLOv9(2024)은 PGI(Programmable Gradient Information)와 GELAN 아키텍처로 정보 손실 문제를 해결했고, YOLO11(2024)은 22% 적은 파라미터로 더 높은 정확도를 달성했습니다.</p>
            <p>YOLO는 자율주행 차량, CCTV 분석, 드론 영상 처리, 스포츠 분석, 제조업 품질 검사 등 실시간 객체 탐지가 필요한 분야에서 널리 사용됩니다. 탐지(Detection) 외에도 세그멘테이션(Segmentation), 포즈 추정(Pose Estimation), 추적(Tracking) 등 다양한 컴퓨터 비전 태스크를 지원합니다. 엣지 디바이스 배포를 위한 TensorRT, ONNX, CoreML 등 다양한 포맷으로 내보내기가 가능합니다.</p>
        </section>

        <!-- Code Example -->
        <section class="content-section">
            <h2>&#128187; 코드 예제</h2>
            <div class="code-block">
                <button class="copy-btn" onclick="copyCode(this)">&#128203; 복사</button>
                <pre><code># YOLO11 객체 탐지 예제 (Ultralytics)
from ultralytics import YOLO
import cv2

# ============================================
# 1. 모델 로드 및 추론
# ============================================
# 사전 학습된 YOLO11 모델 로드 (n, s, m, l, x 크기)
model = YOLO("yolo11n.pt")  # nano 버전 (가장 빠름)
# model = YOLO("yolo11s.pt")  # small
# model = YOLO("yolo11m.pt")  # medium
# model = YOLO("yolo11l.pt")  # large (정확도 최대)

# 이미지 추론
results = model("image.jpg")

# 결과 확인
for result in results:
    boxes = result.boxes  # 바운딩 박스
    print(f"탐지된 객체 수: {len(boxes)}")

    for box in boxes:
        # 좌표, 클래스, 신뢰도
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        conf = box.conf[0].item()
        cls_id = int(box.cls[0].item())
        cls_name = model.names[cls_id]
        print(f"  - {cls_name}: {conf:.2f} at ({x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f})")

# 결과 시각화 및 저장
result.save("result.jpg")

# ============================================
# 2. 비디오/웹캠 실시간 추론
# ============================================
# 웹캠 실시간 탐지
results = model.predict(source=0, show=True, stream=True)
for r in results:
    pass  # 실시간 화면 표시

# 비디오 파일 처리
results = model.predict(
    source="video.mp4",
    save=True,            # 결과 저장
    conf=0.5,             # 신뢰도 임계값
    iou=0.45,             # NMS IoU 임계값
    device="cuda:0"       # GPU 사용
)

# ============================================
# 3. 커스텀 데이터셋 학습
# ============================================
# YAML 형식의 데이터셋 설정 필요
# data.yaml 예시:
# train: ./train/images
# val: ./val/images
# nc: 3  # 클래스 수
# names: ['cat', 'dog', 'bird']

model = YOLO("yolo11n.pt")  # 사전 학습 가중치로 시작

# 학습 시작
results = model.train(
    data="data.yaml",
    epochs=100,
    imgsz=640,
    batch=16,
    device="cuda:0",
    patience=20,          # Early stopping
    save=True,
    project="runs/detect",
    name="my_model"
)

# ============================================
# 4. 모델 내보내기 (배포용)
# ============================================
# ONNX 포맷 (범용)
model.export(format="onnx", simplify=True)

# TensorRT (NVIDIA GPU 최적화)
model.export(format="engine", device=0)

# CoreML (Apple 디바이스)
model.export(format="coreml")

# TFLite (모바일/엣지)
model.export(format="tflite")

# ============================================
# 5. 다양한 태스크
# ============================================
# 인스턴스 세그멘테이션
seg_model = YOLO("yolo11n-seg.pt")
seg_results = seg_model("image.jpg")

# 포즈 추정
pose_model = YOLO("yolo11n-pose.pt")
pose_results = pose_model("image.jpg")

# 이미지 분류
cls_model = YOLO("yolo11n-cls.pt")
cls_results = cls_model("image.jpg")

# 객체 추적 (BoT-SORT, ByteTrack)
track_results = model.track(
    source="video.mp4",
    tracker="botsort.yaml",  # 또는 "bytetrack.yaml"
    persist=True
)</code></pre>
            </div>
        </section>

        <!-- Performance & Cost (Version Comparison) -->
        <section class="content-section">
            <h2>&#128202; 성능 & 비용: 버전별 비교 (YOLOv8, YOLOv9, YOLO11)</h2>
            <p style="margin-bottom: 1rem;"><strong>COCO val2017 벤치마크 (640x640 해상도, NVIDIA T4 GPU 기준)</strong></p>
            <table class="cost-table">
                <thead>
                    <tr>
                        <th>모델</th>
                        <th>mAP@50-95</th>
                        <th>파라미터</th>
                        <th>FLOPs</th>
                        <th>추론 속도</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>YOLOv8n</td>
                        <td>37.3%</td>
                        <td>3.2M</td>
                        <td>8.7G</td>
                        <td>~16ms (~61 FPS)</td>
                    </tr>
                    <tr>
                        <td>YOLOv8s</td>
                        <td>44.9%</td>
                        <td>11.2M</td>
                        <td>28.6G</td>
                        <td>~21ms (~48 FPS)</td>
                    </tr>
                    <tr>
                        <td>YOLOv8m</td>
                        <td>50.2%</td>
                        <td>25.9M</td>
                        <td>78.9G</td>
                        <td>~33ms (~30 FPS)</td>
                    </tr>
                    <tr>
                        <td>YOLOv9t</td>
                        <td>38.3%</td>
                        <td>2.0M</td>
                        <td>7.7G</td>
                        <td>~15ms (~67 FPS)</td>
                    </tr>
                    <tr>
                        <td>YOLOv9s</td>
                        <td>46.8%</td>
                        <td>7.2M</td>
                        <td>26.7G</td>
                        <td>~18ms (~56 FPS)</td>
                    </tr>
                    <tr>
                        <td>YOLOv9c</td>
                        <td>53.0%</td>
                        <td>25.5M</td>
                        <td>102.8G</td>
                        <td>~28ms (~36 FPS)</td>
                    </tr>
                    <tr class="version-highlight">
                        <td><strong>YOLO11n</strong></td>
                        <td><strong>39.5%</strong></td>
                        <td><strong>2.6M</strong></td>
                        <td><strong>6.5G</strong></td>
                        <td><strong>~17ms (~57 FPS)</strong></td>
                    </tr>
                    <tr class="version-highlight">
                        <td><strong>YOLO11s</strong></td>
                        <td><strong>47.0%</strong></td>
                        <td><strong>9.4M</strong></td>
                        <td><strong>21.5G</strong></td>
                        <td><strong>~24ms (~42 FPS)</strong></td>
                    </tr>
                    <tr class="version-highlight">
                        <td><strong>YOLO11m</strong></td>
                        <td><strong>51.5%</strong></td>
                        <td><strong>20.1M</strong></td>
                        <td><strong>68.0G</strong></td>
                        <td><strong>~27ms (~37 FPS)</strong></td>
                    </tr>
                    <tr class="version-highlight">
                        <td><strong>YOLO11l</strong></td>
                        <td><strong>53.4%</strong></td>
                        <td><strong>25.3M</strong></td>
                        <td><strong>86.9G</strong></td>
                        <td><strong>~33ms (~30 FPS)</strong></td>
                    </tr>
                </tbody>
            </table>
            <p style="margin-top: 1.5rem;"><strong>버전별 주요 특징:</strong></p>
            <ul style="color: #cbd5e1; margin-top: 0.5rem; line-height: 1.8;">
                <li><strong>YOLOv8 (2023.01):</strong> Anchor-free 방식, 분리된 Head, 가장 널리 사용되는 안정적인 버전</li>
                <li><strong>YOLOv9 (2024.02):</strong> PGI(Programmable Gradient Information), GELAN 아키텍처로 정보 손실 최소화</li>
                <li><strong>YOLO11 (2024.10):</strong> YOLOv8 대비 22% 적은 파라미터로 더 높은 mAP 달성, 최신 권장 버전</li>
            </ul>
            <p style="margin-top: 1rem;"><strong>권장 선택:</strong></p>
            <ul style="color: #cbd5e1; margin-top: 0.5rem; line-height: 1.8;">
                <li>실시간 속도 우선: <strong>YOLO11n</strong> (57 FPS, 엣지 디바이스에 적합)</li>
                <li>속도-정확도 균형: <strong>YOLO11s</strong> 또는 <strong>YOLO11m</strong></li>
                <li>최고 정확도: <strong>YOLO11l</strong> (약간의 속도 손실 감수)</li>
                <li>검증된 안정성: <strong>YOLOv8</strong> (프로덕션 환경에서 충분히 검증됨)</li>
            </ul>
            <p style="margin-top: 1rem; color: #94a3b8; font-size: 0.9rem;">
                * 비용: Ultralytics YOLO는 AGPL-3.0 오픈소스 (무료). 상업용 라이선스는 Ultralytics Enterprise 문의 필요.
            </p>
        </section>

        <!-- Practical Usage -->
        <section class="content-section">
            <h2>&#128483; 실무에서 이렇게 말하세요</h2>
            <div class="conversation-list">
                <div class="conversation-item">
                    <p><strong>"실시간 탐지가 필요하면 YOLO11n으로 해보고, 정확도가 부족하면 s나 m으로 올려요."</strong></p>
                    <p style="color: #94a3b8; margin-top: 0.5rem;">-> 모델 크기 선택 논의 시</p>
                </div>
                <div class="conversation-item">
                    <p><strong>"TensorRT로 변환해서 배포하면 추론 속도가 2-3배 빨라져요."</strong></p>
                    <p style="color: #94a3b8; margin-top: 0.5rem;">-> 프로덕션 배포 최적화 시</p>
                </div>
                <div class="conversation-item">
                    <p><strong>"커스텀 데이터로 fine-tuning할 때 pretrained weight에서 시작하세요."</strong></p>
                    <p style="color: #94a3b8; margin-top: 0.5rem;">-> 커스텀 학습 가이드 시</p>
                </div>
                <div class="conversation-item">
                    <p><strong>"YOLO11이 파라미터 대비 성능이 제일 좋아서 새 프로젝트는 이걸로 시작해요."</strong></p>
                    <p style="color: #94a3b8; margin-top: 0.5rem;">-> 버전 선택 조언 시</p>
                </div>
            </div>
        </section>

        <!-- Common Mistakes -->
        <section class="content-section">
            <h2>&#9888; 흔한 실수 & 주의사항</h2>
            <div class="mistake-list">
                <div class="mistake-item">
                    <p><strong>입력 이미지 크기 불일치</strong></p>
                    <p style="color: #f87171; margin-top: 0.5rem;">학습 시 640x640으로 했는데 추론 시 다른 크기를 쓰면 성능이 떨어집니다. imgsz 파라미터를 일치시키세요.</p>
                </div>
                <div class="mistake-item">
                    <p><strong>conf 임계값을 너무 낮게 설정</strong></p>
                    <p style="color: #f87171; margin-top: 0.5rem;">conf=0.1처럼 낮으면 오탐(False Positive)이 급증합니다. 보통 0.25~0.5 사이에서 시작하세요.</p>
                </div>
                <div class="mistake-item">
                    <p><strong>데이터 증강 과다</strong></p>
                    <p style="color: #f87171; margin-top: 0.5rem;">mosaic, mixup 등 과도한 증강은 작은 객체 탐지에 오히려 해롭습니다. 마지막 10 에폭은 증강을 끄세요 (close_mosaic 옵션).</p>
                </div>
                <div class="mistake-item correct">
                    <p><strong>올바른 접근: 점진적 최적화</strong></p>
                    <p style="color: #4ade80; margin-top: 0.5rem;">1) 기본 설정으로 baseline 확립 2) conf/iou 임계값 조정 3) 모델 크기 변경 4) 하이퍼파라미터 fine-tuning 5) 배포 포맷 최적화 (ONNX/TensorRT)</p>
                </div>
            </div>
        </section>

        <!-- Related Terms -->
        <section class="content-section">
            <h2>&#128279; 관련 용어</h2>
            <div class="related-terms">
                <a href="../Object%20Detection/" class="related-term-link">Object Detection</a>
                <a href="../CNN/" class="related-term-link">CNN</a>
                <a href="../Anchor%20Box/" class="related-term-link">Anchor Box</a>
                <a href="../IoU/" class="related-term-link">IoU</a>
                <a href="../NMS/" class="related-term-link">NMS</a>
                <a href="../Transfer%20Learning/" class="related-term-link">Transfer Learning</a>
                <a href="../Computer%20Vision/" class="related-term-link">Computer Vision</a>
            </div>
        </section>

        <!-- Learn More -->
        <section class="content-section">
            <h2>&#128218; 더 배우기</h2>
            <div class="resource-list">
                <a href="https://docs.ultralytics.com/" class="resource-link" target="_blank" rel="noopener">
                    &#128279; Ultralytics YOLO 공식 문서
                </a>
                <a href="https://github.com/ultralytics/ultralytics" class="resource-link" target="_blank" rel="noopener">
                    &#128279; Ultralytics GitHub
                </a>
                <a href="https://docs.ultralytics.com/compare/yolo11-vs-yolov8/" class="resource-link" target="_blank" rel="noopener">
                    &#128279; YOLO11 vs YOLOv8 비교 (공식)
                </a>
                <a href="https://arxiv.org/abs/1506.02640" class="resource-link" target="_blank" rel="noopener">
                    &#128279; YOLO 원본 논문 (Redmon et al., 2015)
                </a>
                <a href="https://arxiv.org/abs/2402.13616" class="resource-link" target="_blank" rel="noopener">
                    &#128279; YOLOv9 논문 (Wang et al., 2024)
                </a>
            </div>
        </section>
    </main>

    <!-- Footer -->
        <div id="kaitrust-footer"></div>

    <!-- Scripts -->
    <script>document.getElementById('currentYear').textContent = new Date().getFullYear();</script>
    <script>window.WIA_A11Y_CONFIG = { fabBottom: "38px", fabRight: "30px" };</script>
    <script src="https://wia.live/wia-a11y-toolkit/wia-a11y-toolkit.min.js"></script>
    <script src="/components/ask-ai/kaitrust-ai-modal.js"></script>
    <script src="/components/language-modal/wia-language-modal-211.js"></script>
    <script>
    function copyCode(button) {
        const codeBlock = button.parentElement.querySelector('code');
        navigator.clipboard.writeText(codeBlock.textContent).then(() => {
            const originalText = button.innerHTML;
            button.innerHTML = '&#10003; 복사됨';
            setTimeout(() => { button.innerHTML = originalText; }, 2000);
        });
    }
    </script>
<script src="/glossary/js/term-sections.js"></script>
    <script src="https://kaitrust.ai/components/site-kit/kaitrust-site-kit.js?v=20260130002"></script>
    <script src="/kaitrust-i18n.js?v=20260129"></script>
</body>
</html>
